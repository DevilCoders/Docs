# Автомьюты

## Введение

Упрощенно, идея автомьютов заключается в следующем:

- собираем статистику прогонов всех тестов во всех dev-сборках (почему только в dev-сборках? – потому что только так мы можем быть уверены, что на результат прогона тестов не влияют изменения, сделанные разработчиком);

- **при падении** теста смотрим на его статистику – если тест согласно статистике нестабилен, то мы **игнорируем его падение**, помечая тест как «заскипанный» *(почему в кавычках? – потому что мы скипаем тест только в этом прогоне, а не навсегда).*

**Почему бы не скипать тест насовсем, как только мы видим, что он – нестабильный?**

Потому что, если мы заскипаем тест насовсем, ручным тестировщикам придется проверять этот тест вручную во всех релизах. А это стоит денег. Если тест падает в 100% случаев, то да – такой тест прогонять в дальнейшем смысла нет – его нужно скипать. В остальных же случаях, при успешных прогонах, мы избавляемся от необходимости прогонять тест вручную.

Кроме этого, тест может стать нестабильным из-за проблем с внешним окружением (часто это актуально для hermione-e2e-тестов). В таких случаях временный мьют теста помогает пережить период нестабильности, без каких-либо ручных действий со стороны разработчиков или дежурных: как только внешнее окружение стабилизируется, тест будет снова успешно проходить. 

## Каким образом вычисляется нестабильность теста?

У алгоритма, определяющего нестабильность теста, есть 2 механизма.

### 1. Определение нестабильности через *success rate* теста

#### Как это работает?

Система сохраняет в базу данных все прогоны теста во всех dev-сборках, включая все ретраи теста. Из [тесткоп-конфига][testcop-config] проекта берется количество сборок *(builds),* по которому система должна вычислять коэффициент успешности *(success rate)* для теста, и требуемый минимальный *success rate* для того, чтобы тест считался стабильным.

Если при падении теста его *success rate* согласно статистике меньше требуемого значения *(rate),* то тест мьютится и его падение не влияет на итоговый результат прогона тестов. В отчете такой тест будет раскрашен серым цветом и помечен тегом *skipped*, а в качестве причины заскипа будет указан *success rate* теста.

![скриншот: тест заскипан из-за низкого success rate](https://jing.yandex-team.ru/files/robot-testcop/testcop.doc.user.auto-mutes.test-was-muted-by-success-rate.png)

#### Что такое *success rate?*

Это отношение числа успешных попыток выполнения теста к общему числу попыток в заданных сборках.

Возьмем для примера прогон теста *«Hotels / Карусель / Отель в попапе Основные проверки»* в трех dev-сборках в браузере *firefox* и посчитаем *success rate* этого теста на трех сборках.

![скриншот: прогон 1 в деве](https://jing.yandex-team.ru/files/robot-testcop/testcop.doc.user.auto-mutes.task-tries-dev-1.png)

![скриншот: прогон 2 в деве](https://jing.yandex-team.ru/files/robot-testcop/testcop.doc.user.auto-mutes.task-tries-dev-2.png)

![скриншот: прогон 3 в деве](https://jing.yandex-team.ru/files/robot-testcop/testcop.doc.user.auto-mutes.task-tries-dev-3.png)

*неуспешные попытки = 4 + 1 + 4 = 9*

*успешные попытки = 1 + 1 + 1 = 3*

*всего попыток = 9 + 3 = 12*

*success rate = число успешных попыток / всего попыток = 3 / 12 = 0,25 (или 25%)*

#### Как задаются настройки для этого механизма?

Для примера посмотрим на соответствующую часть конфига проекта *web4* для hermione-тестов в [тесткоп-конфиге][testcop-config].

```javascript
    web4: {
        ...
        autoMute: {
            hermione: {
                enabled: true,
                stat: {
                    minimalSuccessRates: [
                        { rate: 0, builds: 2 },
                        { rate: .7, builds: 20 }
                    ]
                }
            },
            ...
        },
        ...
    }
```

В секции `minimalSuccessRates` задаются выборки, по которым система решает стабилен тест или нет.

**Если хотя бы в одной выборке тест будет определен как нестабильный, финальный вердикт будет – тест нестабильный.**

_**Посмотрим, на первую выборку: { rate: 0, builds: 2 }**_

Что она означает? Что если тест упадет в 2 dev-сборках подряд *(builds: 2)*, то этот тест будет признан нестабильным. Обратите внимание, что падение теста в сборке означает, что нет ни одного успешного ретрая.

![скриншот: все попытки в тесте упали](https://jing.yandex-team.ru/files/robot-testcop/testcop.doc.user.auto-mutes.all-tries-failed.png)

То есть для двух dev-сборок формула вычисления коэффициента успешности теста будет выглядеть так:

*success rate = число успешных попыток / всего попыток = 0 / ( 8 + 8 ) = 0 (или 0%)*

*Это правило было введено контуром тестов как признак сломанного теста.*

_**Теперь, посмотрим на вторую выборку: { rate: .7, builds: 20 }**_

Если в 20 сборках подряд соотношение всех успешных попыток выполнения теста к общему числу попыток (успешных + неуспешных) окажется меньше 0.7 (70%), то тест будет признан нестабильным.

Во всех случаях берутся последние N сборок на деве к моменту запуска тестов.

_**Важное замечание:** в реальности здесь может быть небольшой лаг (порядка 10-20 минут). Например, перед запуском гермионы в ревью-реквесте разработчика у нас уже есть прогон гермионы в последней dev-сборке, но данные прогона еще не успели попасть в базу данных. Поэтому при определении стабильности тестов, будут использоваться данные по 20 dev-сборкам, начиная с предпоследней dev-сборки, а не с последней, которую мы уже видим в Sandbox'е._

#### В чем недостатки такого механизма?

**Во-первых**, в том, что мы никак не отличаем между собой падения теста в различных попытках: мы смотрим лишь на общую нестабильность теста. Например, тест мог падать первые 2 раза из-за невозможности получить сессию *(проблемы с гридом)*, потом несколько раз – при переходе на внешний сайт *(из-за проблем с сетью),* и потом в финале упасть с диффом в скриншоте *(проблемы с эталоном, браузером или версткой)*. В рамках этого механизма все эти попытки будут равноценны. Упал N раз – значит упал N раз. И неважно почему.

Чтобы нивелировать эту проблему, мы вычисляем *success rate* для теста на основе большого количества сборок. Однако, если в настройках указать слишком большое число сборок, которое необходимо для вычисления коэффициента успешности теста, то мы увеличим время реакции – время, по прошествии которого тест будет признаваться нестабильным. Поэтому подбор этого значения происходит эмпирически. [Иногда](https://st.yandex-team.ru/FEI-20980) мы это значение корректируем: например, если в проекте уменьшается количество влитий в *dev* за сутки.

**Во-вторых**, при наличии глобальных проблем, мы можем ошибочно замьютить слишком много тестов.

Чтобы избежать этого, мы добавили возможность ограничивать количество замьюченных тестов в рамках одного прогона гермионы. Для этого надо настроить опцию *[maxMutesPerRun](https://a.yandex-team.ru/arc/trunk/arcadia/frontend/projects/infratest/packages/hermione-muted-tests/lib/config/defaults.js?rev=r6863250#L12)* в разделе `testcopStats` в конфиге плагина *[hermione-muted-tests][hermione-muted-tests]*.

**В-третьих**, тест может падать валидно из-за изменений, внесенных разработчиком, а мы замьютим этот тест, потому что предыдущая статистика покажет нам, что он был ранее нестабилен в dev-сборках.

Чтобы избежать этого для тех случаев, когда разработчик неудачно переснял скриншоты, мы добавили в *[hermione-muted-tests][hermione-muted-tests]* специальную [проверку](https://a.yandex-team.ru/arc/trunk/arcadia/frontend/projects/infratest/packages/hermione-muted-tests/index.js?rev=r7070207#L166), в которой смотрим, не менял ли разработчик для падающего теста скриншоты. Если скриншоты менялись, тест мьютиться не будет. Однако, в остальных случаях эта проверка не спасает: например, при изменении дампов.

### 2. Определение нестабильности по паттерну ошибки

Чтобы определить нестабильность теста по коэффициенту его успешности *(success rate)* нам нужно относительно большое количество прогонов этого теста, а значит, пройдет какое-то время, прежде чем наша система сможет вынести вердикт, что тест нестабильный. Поэтому мы добавили второй механизм определения нестабильности – **по паттерну ошибки**.

#### Как это работает?

Для каждого теста система вычисляет и запоминает в базе данных хэш-коды всех ошибок, с которыми тест падал в dev-сборках.

При падении теста в ревью-реквесте разработчика, система:

- отбирает из всех попыток запуска теста наиболее частую ошибку;

- отбрасывает ошибку, если её частота меньше 50%;

- проверяет, падал ли этот тест в *ближайшие* дни с такой же ошибкой *(должны совпасть хэш-коды ошибок);*

- игнорирует падение теста *(мьютит его),* если тест уже падал с такой ошибкой в одной из dev-сборок, и если число замьютов **по паттерну ошибки** в текущем прогоне не превысило максимально разрешенное значение *(см. опцию `maxPerRun` в [параметрах](https://a.yandex-team.ru/arc/trunk/arcadia/frontend/projects/infratest/packages/hermione-muted-tests#параметры) плагина hermione-muted-tests);*

- помечает замьюченный тест тегом `skipped` и прописывает в причине замьюта `Automatically muted`.

_**Что значит «в ближайшие дни»?**_

Количество дней, за которые просматриваются ошибки относительно текущего дня, задаются опцией `errorTimeThreshold` в [настройках][hermione-muted-tests-params] плагина *hermione-muted-tests*.

_**Как быть с вариативностью сообщений об ошибках?**_

Система может отформатировать вариативные части сообщений об ошибках, заменив их на плейсхолдеры вида `<replaced_by_hermione_muted_tests>` с помощью заданных регулярных выражений – см. опцию `excludeFromErrors` в описании [параметров][hermione-muted-tests-params] плагина *hermione-muted-tests*. Так можно обнаруживать одинаковые падения тестов при не принципиальных отличиях в сообщениях об ошибках.

_**Как вычисляется хэш-код ошибки?**_

Хэш-код ошибки представляет собой [md5][md5] от строки вида:

`сообщение-об-ошибке.тип-ошибки[.координаты-дифф-регионов-через-точку]`

Последняя часть строки актуальна только для падений тестов с диффом в скриншоте.

Например, если результатом выполнения команды `assertView` будет следующий набор дифф-регионов *(diff-bounds):*

```javascript
[10, 5, 100, 25] 
[250, 45, 306, 71]
```

то строка, по которой будет вычисляться *md5,* будет выглядеть следующим образом:

`image comparison failed.AssertViewError.10.5.100.25.250.45.306.71`

\* _`assertView` – [команда](https://github.com/gemini-testing/hermione#assertview) гермионы, которая снимает скриншот и сравнивает его с эталоном_

_**Что такое diff-регионы или diff-bounds?**_

Смотрите разъяснение на скриншоте:

![скриншот: дифф-регионы или diff-bounds](https://jing.yandex-team.ru/files/robot-testcop/testcop.doc.user.auto-mutes.diff-bounds.png)

_**В чем разница между maxMutesPerRun и maxPerRun?**_

В [настройках][hermione-muted-tests-params] плагина *hermione-muted-tests* есть 2 раздела: `testcopStats` и `autoMute`.

Параметр `maxMutesPerRun` в секции `testcopStats` определяет как много тестов на один прогон мы можем замьютить, опираясь на _**success rate**_ соответствующих тестов.

Параметр `maxPerRun` в секции `autoMute` ограничивает число замьютов на один прогон, которые происходят на основе анализа _**паттернов ошибок**_.

_**Где задаются параметры maxPerRun и errorTimeThreshold – я не вижу их в своем проекте?**_

Посмотрим, для примера на [конфиг](https://a.yandex-team.ru/arc/trunk/arcadia/frontend/projects/web4/hermione/config.common.js?rev=r8198317#L112) плагина *hermione-muted-tests* в проекте *web4:*

```javascript
    ...
    plugins: {
        ...
        '@yandex-int/hermione-muted-tests': {
            project: 'web4',
            stabilityIndex: {
                output: {
                    enabled: false
                },
                input: {
                    path: null
                }
            },
            autoMute: {
                enabled: false
            },
            sortTestsByStability: {
                enabled: false
            }
        },
        ...
    },
    ...
```

Здесь этих параметров, действительно, нет. К тому же автомьюты **на основе анализа паттерна ошибок** вообще отключены: *autoMute: { enabled: false }*. На самом деле, они отключены только для локального запуска гермионы. 

Для конвейера же настройки параметров `maxPerRun` и `errorTimeThreshold` можно [найти](https://a.yandex-team.ru/arc/trunk/arcadia/serp/genisys/sandbox-ci/sandbox_clients/config.yml?rev=r8098955#L461) в генезисе:

![скриншот: genisys](https://jing.yandex-team.ru/files/robot-testcop/testcop.doc.user.auto-mutes.genisys.png)

```
hermione_muted_tests_auto_mute_enabled: 'true'
hermione_muted_tests_auto_mute_error_time_threshold: 7
hermione_muted_tests_auto_mute_max_per_run: 3
```

#### Пример теста, замьюченного по паттерну ошибки

На скриншоте приведен пример теста, который упал 7 раз. Из 7 падений – 6 с диффом в скриншоте. Поэтому частота наиболее частой ошибки равна 86% (6 / 7 = 0,857), что больше, чем 50%.

_**Обратите внимание,**_ что все 6 падений с диффом считаются эквивалентными только в том случае, если в каждом падении – один и тот же набор дифф-регионов *(diff-bounds)*, иначе хэш-коды ошибок не совпадут.

![скриншот: тест автоматически замьючен](https://jing.yandex-team.ru/files/robot-testcop/testcop.doc.user.auto-mutes.automatically-muted.png)

### Какие недостатки у автомьютов?

С одной стороны, автомьюты избавляют разработчика от необходимости следить за стабильностью тестов: система сама следит за их стабильностью и (относительно) вовремя их мьютит, а разработчику нужно только писать свой код и править те тесты, которые он затрагивает своими изменениями.

Но с другой стороны, если какие-то тесты начинают плавать, а система все чаще и чаще их мьютит, то это означает, что соответствующая функциональность проекта остается без покрытия тестами. А значит существует вероятность, что эта функциональность рано или поздно окажется сломанной и никто этого не заметит. 

Поэтому контур тестов, в свое время, разработал [дашборд](https://datalens.yandex-team.ru/48s8gauaji680-plavayushie-hermione-testy) по плавающим тестам, на одной из вкладок которого отображается *топ мьютов:*

![скриншот: дашборд по мьютам](https://jing.yandex-team.ru/files/robot-testcop/testcop.doc.user.auto-mutes.dashboard-for-flaky-tests.png)

Далее в [инструкцию](https://wiki.yandex-team.ru/serp/duty/) дежурного был добавлен пункт _«следить за мьютами и вовремя их скипать»_. Что значит _«вовремя»?_ – Когда тест начинает мьютиться больше чем в 50% сборок (прогонах гермионы), или по-другому: когда _**mute rate**_ достигает 50%.

Недостаток такого решения заключается в том, что оно требует затрат времени дежурного и зависит от человеческого фактора.

Поэтому мы внедрили ещё один механизм – [механизм автозаскипов][auto-skips].

[testcop-config]: https://a.yandex-team.ru/arc/trunk/arcadia/frontend/projects/infratest/packages/testcop-config/index.js
[hermione-muted-tests]: https://doc.yandex-team.ru/si-infra/tests-stability/hermione-muted-tests.html
[hermione-muted-tests-params]: https://doc.yandex-team.ru/si-infra/tests-stability/hermione-muted-tests.html#parametry
[md5]: https://ru.wikipedia.org/wiki/MD5
[genisys-sandbox-clients]: https://genisys.yandex-team.ru/rules/sandbox-ci/sandbox_clients
[auto-skips]: https://doc.yandex-team.ru/si-infra/tests-stability/testcop/testcop-auto-skips.html
