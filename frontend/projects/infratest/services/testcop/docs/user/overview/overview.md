# Общая информация

## Видео-версия

<video src="https://streaming.video.yandex-team.ru/get/video-nda/m-49916-17beeca8d75-bd14390a2a04d8a6/720p.mp4" width="640" height="480" controls="controls"></td>Ваш браузер не поддерживает это видео. <a href="https://streaming.video.yandex-team.ru/get/video-nda/m-49916-17beeca8d75-bd14390a2a04d8a6/720p.mp4" target="_blank">Скачайте видео</a></video>

Доклад «Как мы справляемся с нестабильностью тестов» (эволюция подходов: от ретраев и заскипов в коде – до автомьютов и автозаскипов) от инфраструктуры на [пЯТЬнице по интерфейсам](https://wiki.yandex-team.ru/HR/gor/pyatnitsa/2021-09-10/) _(10 сентября 2021 года)._

## Введение

### CI/CD, непрерывное тестирование и нестабильность как препятствие

Когда в вашем проекте настроены процессы CI/CD, а значит и непрерывного тестирования, рано или поздно вы сталкиваетесь с проблемой нестабильности тестов.

В идеальном мире, если вы своими изменениями не затрагиваете тест, этот тест успешно проходит. Но в реальном мире тесты иногда падают и сами по себе. По совершенно разным причинам: временные гонки, нестабильность внешнего окружения, проблемы с инфраструктурой, сетью, и т. д. и т. п. 

Какие бы ни были причины, для разработчика это выглядит так, что *«я ничего не трогал, а оно упало и не дает мне влиться»*. Увеличивается время доставки фичи до продакшена, растет раздражение разработчика, вынужденного разбираться с падениями нерелевантных тестов, CSI падает.

А ещё дополнительно расходуются ресурсы инфраструктуры – квота в *Sandbox'е* *(процессорное время серверов, на которых выполняются тесты),* браузеры в гриде, и т. д. От чего начинают страдать и другие разработчики, чьи задачи стоят в очереди на получение доступа к соответствующим ресурсам.

### Требования к стабильности

Чтобы понять какими могут быть требования к стабильности тестов, возьмем для примера проект *web4*. Сейчас в *web4* за сутки вливается около 20 ревью-реквестов. В финальной сборке каждого ревью-реквеста, непосредственно перед влитием, должны успешно выполниться около 28 тысяч тестов. 

![скриншот: количество тестов в web4](https://jing.yandex-team.ru/files/robot-testcop/testcop.doc.user.overview.web4-total-tests-count.png)

Это 560 тысяч тестов за день. Или больше 1 миллиона за 2 дня. Если вы хотите, чтобы при влитии у вас падало не больше 5% сборок, то это означает не больше 2 упавших сборок на 40 сборок. То есть достаточно упасть 3 тестам из 1 000 000 – по одному на разные сборки – как ваша стабильность окажется за бортом 5%.

## Как улучшить стабильность?

### Ретраи

Самый простой способ побороть нестабильность – это ретраи. Тест упал? – что ж – запустим его ещё раз, и ещё раз, и ещё раз – и может быть, раза с пятого тест, наконец-то, пройдет. Но ретраи не всесильны, потому что нестабильность внешнего окружения может по времени длиться дольше наших попыток. А ещё тест может сломаться внезапно и навсегда из-за того, что он некорректно написан и есть неявная зависимость от какого-то внешнего события *(например, в нем незастабана дата и с наступлением нового года тесты начинают падать с диффом в скриншотах)*.

![скриншот: тест упал из-за нового года](https://jing.yandex-team.ru/files/robot-testcop/testcop.doc.user.overview.testcop-ticket-about-ny-diff-in-screenshots.png)

#### Какие недостатки у ретраев?

Слишком много ретраев увеличивают общее время прогона тестов, и если тест все равно упадет, то получится, что мы только зря потратили время разработчика, квоту в *Sandbox'е,* и впустую занимали браузер.

И самый худший случай – когда инфраструктурные проблемы приводят к массовому падению тестов и начинают ретраиться все тесты.

Поэтому чтобы избежать ненужных расходов, у [гермионы][hermione] есть специальный плагин [retry-limiter][retry-limiter]. Этот плагин следит за максимально допустимым количеством ретраев и не дает ретраить тесты, если лимит ретраев исчерпан.

А ещё есть плагин [hermione-retry-progressive], который позволяет при ретраях не учитывать инфраструктурные падения теста.

### Заскипы в коде

Допустим, тест упал и никакие ретраи ему не помогли. Разработчик видит, что падение теста никак не связано с его изменениями. Как тогда ему влиться? Снова перезапускать sandbox-задачу и надеяться, что в этот раз он проскочит? А если уже понятно *(например, по прогонам тестов в деве),* что этот тест нестабильный и шансов проскочить мало? Как отключить тест?

В свое время мы добавили в гермиону специальный хелпер [hermione.skip](https://github.com/gemini-testing/hermione#skip), с помощью которого можно пропустить (не запускать) тест в заданном браузере, указав причину заскипа – эту причину пользователь потом видит в итоговом html-отчете. В качестве причины заскипа обычно указывают тикет в Стартреке, в рамках которого разработчик или ответственная команда планируют в будущем чинить отключаемый тест.

#### Какие недостатки у заскипов в коде?

1. Чтобы отключить тест, нужно сделать ревью-реквест, внеся изменения в код теста.

2. Чтобы узнать какие тесты были отключены в проекте, нужно найти произвольный html-отчет с результатами прогона тестов в этом проекте и включить показ всех заскипанных тестов с помощью фильтра *Show skipped*.

3. Тест может быть отключен и никогда не починен, если разработчик забудет создать тикет или не укажет его в качестве причины заскипа.

4. После починки нестабильного теста, нужно не забыть удалить строку с `hermione.skip`.

В итоге, несмотря на то, что в гермионе все ещё есть этот хелпер, контур тестов [внедрил](https://st.yandex-team.ru/SERP-81146) во многие проекты линтер, который запрещает его использование из-за вышеописанных недостатков.

### Заскипы через Тесткоп

Когда стало понятно, что заскипы в коде – это сложно и неудобно, мы создали специальный сервис – [Тесткоп][testcop].

![скриншот: главная страница Тесткопа](https://jing.yandex-team.ru/files/robot-testcop/testcop.doc.user.overview.testcop-front.png)

С помощью этого сервиса можно быстро заскипать упавший тест, без каких-либо ревью-реквестов.

При этом Тесткоп автоматически создаст тикет заскипа в нужной очереди, на основе заданного шаблона, потребовав от разработчика минимум данных – название для тикета и дополнительные комментарии к описанию, если они требуются. Остальные данные – имена упавших тестов, браузеры, в которых упали тесты, стектрейсы ошибок и скриншоты *(expected / actual / diff)* Тесткоп добавит сам.

#### Что для этого нужно?

Во-первых, ваш проект должен быть подключен к Тесткопу, а в гермионе – добавлены плагины [@yandex-int/hermione-muted-tests][hermione-muted-tests] и [json-reporter][json-reporter].

Во-вторых, нужна sandbox-задача, в которой запускалась [гермиона][hermione] и в которой этот тест упал.

#### Как подключить Тесткоп и работать с ним?

Об этом вы можете прочитать в разделе [Как подключить проект к Тесткопу?][how-to-add-project-to-testcop]

#### В чем недостатки заскипов через Тесткоп?

Несмотря на то, что Тесткоп позволяет разработчику относительно быстро заскипать плавающие тесты *(мешающие ему влиться),* у этого подхода есть ряд недостатков:

- тесты все равно скипаются не настолько быстро как хотелось бы, так как: 

  - разработчик должен убедиться, что тест, действительно, плавающий, а для этого он должен изучить статистику падений теста;

  - разработчик может не сразу заметить, что проверки в ревью-реквесте (или dev-сборке) упали из-за плавающего теста, и не сразу заскипать плавающий тест: за это время тест может уронить массу других сборок, замедлив работу их авторов;

- все заскипанные тесты при релизе проверяются вручную тестировщиками, а это стоит компании денег.

*Чтобы как-то компенсировать задержку между появлением плавающего теста и его заскипом, проекты были вынуждены привлекать своих дежурных к этой деятельности. Дежурный постоянно следил за статусом sandbox-задач с тегом DEV, в которых запускалась гермиона, смотрел на html-отчеты, изучал статистику прохождения тестов в случае их падений, и принимал решение – скипать или не скипать упавшие тесты. Всё это отнимало время у дежурного, требовало определенных навыков, а результат во многом зависел от человеческого фактора.*

Чтобы победить эти проблемы, мы создали механизм, который не требует участия человека – механизм автомьютов.

#### О том, что осталось за кадром – о ручных мьютах

На самом деле, между ручными заскипами и появлением автомьютов были ещё ручные мьюты.

В чем принципиальное отличие заскипов от мьютов? – Заскипанный тест полностью отключается и в прогоне больше не участвует. Соответственно, потом, в релизах, тестировщики вынуждены прогонять такие тесты вручную. А это означает затраты времени и денег. Замьюченный же тест всегда запускается, но никогда не роняет итоговый прогон. Если замьюченный тест успешно проходит, он прокрашивается зеленым. Если же он падает, то помечается как *(временно)* заскипанный и прокрашивается серым цветом. При этом разработчик может увидеть в html-отчете все попытки прогона этого теста и ошибки, с которыми он падал.

Если тест достаточно стабильный и в большинстве случаев успешно проходит, то тестировщикам не придется прогонять его в релизах вручную. Кроме тех редких случаев, когда тест окажется замьюченным по итогу прогона.

Почему бы тогда не использовать мьюты всегда, вместо ручных заскипов? Потому что это неэффективно с точки зрения утилизации инфраструктурных ресурсов. Мы потратили время и ресурсы на прогон нестабильного теста, а он, в итоге, все равно, упал *(например, потому что сломан)*. Значит, все расходы были напрасны.

Поэтому, перед тем как вручную замьютить тот или иной тест, разработчик (или дежурный проекта) должен был внимательно изучить статистику прогонов теста. И мьютить тест только в том случае, если он падает, например, не чаще, чем в 30% случаев.

С внедрением механизма автомьютов необходимость в анализе статистики и ручных мьютах практически отпала, хотя технически возможность их использовать в Тесткопе до сих пор осталась.

### Автомьюты

Упрощенно, идея автомьютов заключается в следующем:

- собираем статистику прогонов всех тестов во всех dev-сборках (почему только в dev-сборках? – потому что только так мы можем быть уверены, что на результат прогона тестов не влияют изменения, сделанные разработчиком);

- **при падении** теста смотрим на его статистику – если тест согласно статистике нестабилен, то мы **игнорируем его падение**, помечая тест как «заскипанный» *(почему в кавычках? – потому что мы скипаем тест только в этом прогоне, а не навсегда).*

#### Почему бы не скипать тест насовсем, как только мы видим, что он – нестабильный?

Потому что, если мы заскипаем тест насовсем, ручным тестировщикам придется проверять этот тест вручную во всех релизах. А это стоит денег. Если тест падает в 100% случаев, то да – такой тест прогонять в дальнейшем смысла нет – его нужно скипать. В остальных же случаях, при успешных прогонах, мы избавляемся от необходимости прогонять тест вручную.

Кроме этого, тест может стать нестабильным из-за проблем с внешним окружением (часто это актуально для hermione-e2e-тестов). В таких случаях временный мьют теста помогает пережить период нестабильности, без каких-либо ручных действий со стороны разработчиков или дежурных: как только внешнее окружение стабилизируется, тест будет снова успешно проходить.

#### Каким образом вычисляется нестабильность теста?

У алгоритма, определяющего нестабильность теста, есть 2 механизма определения нестабильности:

- через *success rate* теста;

- по паттерну ошибки.

Подробнее об этих алгоритмах вы можете прочитать в разделе [Автомьютов][auto-mutes].

#### Какие недостатки у автомьютов?

С одной стороны, автомьюты избавляют разработчика от необходимости следить за стабильностью тестов: система сама следит за их стабильностью и (относительно) вовремя их мьютит, а разработчику нужно только писать свой код и править те тесты, которые он затрагивает своими изменениями.

Но с другой стороны, если какие-то тесты начинают плавать, а система все чаще и чаще их мьютит, то это означает, что соответствующая функциональность проекта остается без покрытия тестами. А значит существует вероятность, что эта функциональность рано или поздно окажется сломанной и никто этого не заметит. 

Поэтому контур тестов, в свое время, разработал [дашборд](https://datalens.yandex-team.ru/48s8gauaji680-plavayushie-hermione-testy) по плавающим тестам, на одной из вкладок которого отображается *топ мьютов:*

![скриншот: дашборд по мьютам](https://jing.yandex-team.ru/files/robot-testcop/testcop.doc.user.auto-mutes.dashboard-for-flaky-tests.png)

Далее в [инструкцию](https://wiki.yandex-team.ru/serp/duty/) дежурного был добавлен пункт _«следить за мьютами и вовремя их скипать»_. Что значит _«вовремя»?_ – Когда тест начинает мьютиться больше чем в 50% сборок (прогонах гермионы), или по-другому: когда _**mute rate**_ достигает 50%.

Недостаток такого решения заключается в том, что оно требует затрат времени дежурного и зависит от человеческого фактора.

Поэтому мы внедрили ещё один механизм – [механизм автозаскипов][auto-skips].

### Автозаскипы

Когда какие-либо тесты начинают слишком часто мьютиться, появляется риск, что функциональность, которую они покрывают, окажется сломанной и никто этого не заметит. Чтобы избежать этого, система автозаскипов каждый день собирает статистику по замьюту тестов, то есть смотрит как часто тот или иной тест мьютился в прогонах.

Если тест мьютился чаще, чем в 50% сборок (гермиона-задач), система автозаскипов автоматически скипает этот тест через Тесткоп. При этом заводится тикет заскипа, с указанием имени теста, браузера, инструмента *(hermione / hermione-e2e),* *mute rate* и перечнем сборок, в которых этот тест мьютился.

#### Пример тикета, созданного системой автозаскипа

![скриншот: тикет автозаскипа](https://jing.yandex-team.ru/files/robot-testcop/testcop.doc.user.auto-skips.autoskip-ticket.png)

## Заключение

Итак, мы прошли путь от ретраев до автозаскипов – когда нестабильные тесты сначала мьютятся, а потом отключаются системой автоматически, на основе анализа статистики их прогонов.

Решают ли все вышеперечисленные методы проблему стабильности? – Решают, но не на 100%.

Не на 100%, потому что остается вероятность, что разработчик сломает какую-то функциональность, а она не будет протестирована из-за замьюченных или заскипанных тестов. Тесты могут начать плавать ещё до изменений, внесенных разработчиком. И мы не всегда можем определить, что изменения разработчика затрагивают указанные тесты, чтобы наложить запрет на их авто- или ручной мьют.

**Что могут сделать разработчики со своей стороны?**

- вовремя разбирать и чинить заскипанные тесты (см. по указанным ссылкам [как получить автоматическую расстановку приоритетов](https://doc.yandex-team.ru/si-infra/tests-stability/testcop/testcop-how-to-add-project.html#chtoby-testkop-bral-prioritety-dlia-tiketov-zaskipa-iz-testpalm-a) и [v-team](https://doc.yandex-team.ru/si-infra/tests-stability/testcop/testcop-how-to-add-project.html#chtoby-testkop-bral-v-team-dlia-tiketov-zaskipa-iz-testpalm-a) для тикетов заскипа на основе информации из Testpalm'а);

- улучшать стабильность самих тестов, в целом – минимизируя факторы, способствующие их нестабильности: незастабанные даты, изображения, не задание игнор-областей при снятии скриншотов, зависимость от логинов конкретных пользователей и т. п.

[hermione]: https://doc.yandex-team.ru/si-infra/hermione/hermione.html
[hermione-muted-tests]: https://doc.yandex-team.ru/si-infra/tests-stability/hermione-muted-tests.html
[retry-limiter]: https://github.com/gemini-testing/retry-limiter
[hermione-retry-progressive]: https://github.com/gemini-testing/hermione-retry-progressive
[hermione-retry-command]: https://github.com/gemini-testing/hermione-retry-command
[json-reporter]: https://github.com/gemini-testing/json-reporter
[testcop]: https://testcop.si.yandex-team.ru
[how-to-add-project-to-testcop]: https://doc.yandex-team.ru/si-infra/tests-stability/testcop/testcop-how-to-add-project.html
[auto-mutes]: https://doc.yandex-team.ru/si-infra/tests-stability/testcop/testcop-auto-mutes.html
[auto-skips]: https://doc.yandex-team.ru/si-infra/tests-stability/testcop/testcop-auto-skips.html
