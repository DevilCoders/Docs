# Работа с кластером Posgres

## Небольшое введение

Для создания отказоустойчивой базы данных необходимо иметь несколько хостов (инстансов базы данных), которые могут заменить друг друга в случае выхода из строя одного из них.

В нашем случае используется схема Master - slave. В данной схеме существует master хост на котором происходит все операции записи, соответственно на данном хосте всегда будут саммые актуальные данные. Все остальные хосты являются slave хостами. На данных хостах доступны только операции чтения, а для синхронизации данных между master хостом и slave хостами настраивают репликацию.

MDB берет на себя задачу репликации данных. Еще раз повторимся все операции записи делаются через master хост. Но транзакция на этом не заканчивается. Она считается подтвержденной, только в том случае, когда данные оказываются записанными на синхронной реплике (один из slave хостов). На остальных slave хостах данные реплицируются ассинхронно.

Это было краткое введение в то зачем нужен кластер, какие плюсы это дает и как он работает. Дальше поговорим о том, какие технические проблемы нужно решить на уровне приложения при работе с кластером.

## Проблемы с подключением к кластеру
---

Обычно, в большинстве приложений, наши не исключение, мы хотим подключиться к базе данных единожды и держать это соединение открытым до окончания работы приложения. Но, даже не смотря на то что мир не идеален и сбои в сети или базе данных происходят, особенностью кластера является то, что переодически происходит сменна master хоста на один из slave хостов.

Если обрыв соединения решается простым повторным подключением, то со сменной роли хоста задача становится уже не такой простой. Так как от ролей хостов зависит то как между ними будут распределяться запросы. Ведь операции записи мы должны направлять только на master хост, в ином случае мы получим ошибку попытки записи в read-only базу данных.

Typeorm из коробки предлагает функциональность для работы с репликами, но, к сожелению, он подразумевает захардкоженный master хост, а у нас он может меняться. Так что это решение было отброшено и создана своя реализация управления хостами в кластере.

## Краткое описание работы
---

В целом тут есть две вещи кластер и подключение к хосту.

Кластер создается единожды при запуске приложения. А подключения к хосту происходят изначально при создании кластера для каждого их хоста, которые указаны в конфиге. Так же эти подключения происходят при переподключении, вызванным закрытием предыдущего соединения.

Кластер после изначального установления соединения ко всем хостам, определяет мастер хост, путем совершения запроса `select not pg_is_in_recovery() as result limit 1`. Таким образом он разделяет хосты на master и slave роли.

Но роль хостов может поменяться, для этого кластер раз в 5 секунд делает повторный запрос о роли для каждого хоста, и в случае необходимости меняет запись о текущем мастере.

Подключения к хосту также периодически опрашивают свой хост для того, чтобы убедиться что соединение все еще живо, и, если необходимо, переподключаются.

## Примеры работы
---

1. Все начинается с описания конфига. Тут все тривиально. Отдельно отмеить стоит то, что в hosts требуется перечислить список хостов через запятую, так как конфги пока не поддерживает массивы. Пример конфига:
```json
{
    "hosts": "rc1a-ktxs3kne40mlly2f.mdb.yandexcloud.net,rc1b-o59jw4zql0rvr4xr.mdb.yandexcloud.net",
    "port": 6432,
    "database": "db1",
    "password": "123456",
    "username": "user1",
    "connectionsLimit": 200,
    "clusterConfig": {
        "roleUpdateInterval": 5000,
        "roleUpdateIntervalOnError": 1000,
        "connectTimeout": 10000,
    },
    "connectionConfig": {
        "retryTimeout": 10000,
        "aliveCheckInterval": 10000,
    }
}
```

2. Создаем кластер. Для этого передаем конфиг, а также список entities. Как видно мы получаем в возвращаемом значении clusterId, это может пригодиться если у нас будет больше 1 кластера, в таком случае мы сможем обращаться к определенному кластеру используя этот clusterId. По умолчанию все методы обращения к базе данных будут обращаться к самому первому кластерую, если clusterId не создан.

```js
const clusterId = await PgConnection.create(dbConfig, [UserEntity]);
```

3. Получаем соединение до правильного хоста для нужного класса операции.

```js
    const users = await PgConnection.getReadConnection()
        .getRepository(UserEntity)
        .find();
```
или если нужно создать новую запись в базе
```js
    const user = new User();
    await PgConnection.getWriteConnection()
        .getRepository(UserEntity)
        .save(user);
```