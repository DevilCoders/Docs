# Сервис расчетов экспериментов

## Оглавление

- [Глоссарий](#глоссарий)
- [Общие вопросы](#общие-вопросы)
- [Пользовательские сценарии](#пользовательские-сценарии)
- [API и детали реализации](#api-и-детали-реализации)
  - [API](#api)
    - [v1/metric_groups](#v1metric_groups)
    - [v1/metric_groups/configs/validate](#v1metric_groupsconfigsvalidate)
    - [v1/metric_groups/\<group_id\>](#v1metric_groupsgroup_id)
    - [v1/experiments/\<experiment_name\>](#v1experimentsexperiment_name)
    - [v1/experiments/\<experiment_name\>/revisions](#v1experimentsexperiment_namerevisions)
    - [v1/metrics](#v1metrics)
    - [v1/facets](#v1facets)
  - [Конфиги](#конфиги)
  - [Задача для индексации прекомпьютов (STQ)](#задача-abt_index_precomputes-stq)
  - [Фасеты](#фасеты)
- [Этапы реализации](#этапы-реализации)

## Глоссарий

**Таблица с наблюдениями** - таблица на YT, которую формирует аналитик для обсчета эксперимента

**Таблица с прекомпьютами** - таблица на YT, которая построена из слияния множества таблиц наблюдений и таблиц с логами эксприментов. Это широкая таблица с различными метриками, сгруппированными по бакетам, отражающим распределение реальных данных.

**CHYT** - [ClickHouse over YT](https://docs.yandex-team.ru/yt/description/chyt/about_chyt). Технология, которая позволяет делать запросы к статическим и схематизированным таблицам YT с помощью кластера ClickHouse, понятого внутри операции YT.

**Ревизия экспримента** - уникальный идентификатор, отражающий пириод времени, за который конкретный эксперимент не менялся. Имеет смысл считать метрики по эксперименту только в рамках одной ревизии так как в разных ревизиях могут быть разные разбиения по группам пользователей

**Фасеты** - термин из information retrieval. По сути - это поисковый фильтр, нужный для сужения области поиска. В нашем случае для сужения аудитории.

## Общие вопросы

### Название сервиса

abt

### Какую продуктовую проблему решаем?

Мы проводим много AB-тестов. Отчеты по этим тестам аналитики делают руками. Это может быть долго и мешает нам проводить еще больше тестов.

### Почему нельзя решить эту задачу без разработки нового сервиса существующими решениями?

Есть <https://ab.yandex-team.ru> и [cofe](https://wiki.yandex-team.ru/serp/experiments/cofe/doc/). Эти решения покрывают наши сиюминутные потребности где-то на 80%.

Мы хотим добиться быстрой визуализации ad-hoc расчетов. Cofe не позволит нам сделать это быстро.

ab.yandex-team.ru и cofe заточены на решение одной задачи и разрабатываются сторонними командами. У нас уже сейчас есть хотелки, которые вряд ли войдут в ab.

Мы хотим встроить отчеты по экспериментам в tariff-editor чтобы увеличить количество проводимых экспериментов и снизить порог входа. Сейчас для проведения эксперимента нужны аналитики и большое количество времени затрачивается на задачи, которые можно автоматизировать. Уже сейчас есть несколько решений, которые эту задачу в целом решают, но имеют по-прежнему высокий порог входа и не унифицируют подход в расчёте метрик.

Новый сервис поможет проводить эксперименты не только аналитикам, но и менеджерам. Первоначально мы автоматизируем расчёты для аналитиков, но держим в голове, что с развитием системы будет расширяться круг пользователей и сервисов.

### Как именно сервис будет решать поставленные перед ним задачи?

Сервис будет строить отчеты по таблицам на YT и отдавать данные для админки Такси.

Аналоги:

- Поиске Яндекса - <https://ab.yandex-team.ru>
- Авито - <https://habr.com/ru/company/avito/blog/454164>
- Airbnb - <https://medium.com/airbnb-engineering/experiment-reporting-framework-4e3fcd29e6c0>

Дизайн - <https://www.figma.com/file/I9A0bYzrRjUg5FmwrlDOnn/ABT?node-id=0%3A1>

- Описание проекта - <https://st.yandex-team.ru/TAXIANALYTICS-9899>
- Работа с требованиями - <https://st.yandex-team.ru/TAXIBACKEND-29715>

### Разрабатывается один сервис или система?

Один сервис

### С кем взаимодействует сервис?

1. taxi-exp - получение метаинформации об эксперменте
2. YT - запросы к таблицам прекомпьютов.

### Какие базы использует?

**Postgresql**

Основная база данных Такси. Нужна для хранения метаданных.

**YT**

Основные данные, по которым будут производиться расчеты, будут лежать в YT.

Во-первых, это удобно для аналитиков.
Во-вторых, используя технологию **ClickHouse over YT** мы получим приемлемую для нас скорость выполнения операций и уберем необходимость копирования данных в локальное хранилище сервиса.

Тестирование производительности для наших запросов - https://st.yandex-team.ru/TAXIBACKEND-29715#5f1805c7335d3754c19b77c4

### Какие периодические процессы?

Периодический процесс, который будет раз в несколько секунд (десятки) обходить все таблицы прекомпьютов и смотреть на дату изменения. Если она больше, чем та, что лежит в локальной БД, то будем ставить STQ на индексацию таблицы.


### Прикрепите схему того, где этот сервис находится в текущей инфраструктуре

![](static/01_architecture/abt-dataflow.png)

На цикл заказа не влияет.

Потребители - все заинтересованные.

### Какие данные и по какой схеме сервис будет хранить в базе?

**Postgresql**

![](static/01_architecture/abt-db.png)

**YT**

Широкая таблица с расчетами. Будет много таблиц, которые будут формироваться аналитиками.

Пример - <https://yt.yandex-team.ru/hahn/navigation?path=//home/taxi_ml/dev/abt/precomputes/drivers_main&>.

### Какой объем данных будет храниться и какой объем будет изменяться в единицу времени?

**Postgresql**

Объем данных - до 5ГБ.

В основном, данные будут дописываться.

**YT**

Десятки ГБ. Данные будут только дописываться. Срок хранения до 12 месяцев.

**tilgasergey@:**

> Ниже оценка для продакшн прекомпьютов (весь эдхок будт примерно такого же порядка, мне кажется).

> - храним за 6-12 месяцев
> - месяц около 50 экспериментов
> - 300-500 колонок для всех продакшн прекомпьютов
> - 500-1000 бакетов
> - 3 среза по приложению
>
> = 30-50 gb

### Какие операции над данными заложены?

**Postgresql**

CRUD

**YT**

- Чтение

> Все остальные операции над данными будут происходить за пределами сервиса

### Есть ли какой-то стейт в памяти, как он обновляется и валидируется?

Нет

### Какая нагрузка ожидается?

Сервис внутренний. Единицы rps.

### Какие фолбеки предусмотрены внутри этого сервиса на взаимодействие с другими сервисами?

- лежит YT - не можем строить отчеты (есть ок от Андрея Кармацкого). Сервис бесполезен. Если будет нужно, то сделаем репликацию на 2 кластера YT.
- лежит локальный PG - не работаем
- лежит taxi-exp - не можем получать метаданные по экспериментам. Возможность строить отчеты сохраняется. Не можем индексировать таблицы.

### Какие возможности масштабируемости закладываются?

- при росте количества таблиц прекомпьютов можно увеличивать количество клик в CHYT.

### Укажите ключевые продуктовые метрики сервиса, за которыми планируете следить

- Количество обсчитываемых экспериментов за единицу времени
- Количество метрик
- Количество уникальных пользователей сервиса

### Укажите технические метрики

- Основные технические метрики работоспособности сервиса
- Доступность YT
- Скорость выполнения аналитических запросов через CHYT
- Время индексации таблиц в YT

### Какая функциональность ожидается в сервисе в будущем?

Дополнительные функции по анализу процесса эксперимента.

### Активно ли будет изменяться сервис?

Будут добавляться новые плюшки в отчет по эксперименту.

## Пользовательские сценарии

- 🔥 Появился новый эксперимент и нужно чтобы он пророс в сервисе
  - Вне скоупа сервиса
    - Если в сервисе уже есть какое-то количество метрик, то скорее всего какие-то метрики для нового эксперимента уже доступны
    - Заведен новый эксперимент в экспериментах 3.0 для того чтобы провести ab-тестирование
    - Аналитик готовит таблицы наблюдений
    - Аналитик встраивает свои таблицы наблюдений в процесс подготовки прекомпьютов
  - В зоне ответственности сервиса
    - Если данные по эксперименту попадают в уже известные для сервиса таблицы прекомпьютов, то данный эксперимент просто доступен для построения отчетов
    - Если была создана новая таблица прекомпьютов, то аналитик должен:
      - Создать новую группу метрик
        - Зайти в список групп метрик и нажать кнопку «создать новую группу»
        - Придумать название группы
        - Добавить ответственного за группу
        - Прописать к какому проекту относится группа (такси, еда, etc)
        - Указать, показывать эту группу свернутой или развернутой при отображении отчета
          - Эта опция доступна только для главного аналитика. По умолчанию все свернуто
        - Прописать конфиг группы
          - Указать ОДНУ таблицу прекомпьютов для данной группы
            - Прописать настройки storage
              - Прописать кластер YT
              - Прописать путь к таблице в кластере YT
            - Прописать маппинг полей в этой таблице прекомпьютов для фасетов
          - Добавить нужное количество метрик для данной группы
            - Для каждой метрики
              - Указать name (англ типо gmv)
              - Указать title (русский)
              - Указать description
              - Указать тип
              - Прописать параметры
              - Указать, является ли эта метрика верифицированной
                - Верифицированность метрики нужно подтвержать. Если писать признак подвержденности
                  в конфиг, то использовать АБК не получится.
                  Если сбудется вариант с тесстингов для ad-hoc метрик, то можно будет считать, что все
                  метрики на проде верифицированные. А на метрики в тестинге пофиг. Там может быть хаус.
                  В проде тогда навесить пермишены на создание/редактирование конфига метричной группы.
        - Сохранить конфиг. Исправить ошибки валидации, если такие возникнут
    - После сохранения новой группы в течение нескольких секунд таблица прекомпьютов будет проиндексирована и данные из нее будут доступны для построения отчетов
- 🔥 Аналитик хочет добавить в отчет экспериментальную метрику (ad-hoc)
  - Вне скоупа сервиса
    - Аналитик готовит таблица наблюдений
    - Аналитик готовит таблицу прекомпьютов
  - В зоне ответственности сервиса
    - Аналитик заводит отдельную группу по сценарию выше
- 🔥 Аналитик понял, что его экспериментальная метрика всем нужна и хочет чтобы эта метрика была подсвечена как верифицированная
  - Вне скоупа сервиса
    - Аналитик должен позаботиться о том, чтобы данные для его метрики были в какой-то таблице прекомпьютов
  - В зоне ответственности сервиса
    - Аналитик добавляет свою метрику в одну из существующих продакшн групп или
      - Аналитик заводит новую группу со своей метрикой и просит (или сам) отмечает её верифицированной
- 🔥 Пользователь хочет построить отчет по эксперименту
  - Пользователь заходит на страницу экспериментов 3 и находит нужный эксперимент. Нажимает на него чтобы открылось выпадающее меню справа
  - В выпадающем меню пользователь жмет кнопку "Посмотреть метрики".
    "На первом шаге можно просто рисовать эту кнопку везде, а уже на втором сделать ручку чтобы сервис экспериментов отображал кнопку только там, где есть данные по эксперименту. Но вроде у всех аналитических эксприментов должны быть данные. Так что вот"
  - Пользователь переходит на страницу с отчетом об эксприменте.
    - На странице видно название эксперимента на английском и русском, какое-то описание экспримента и тикет
    - На странице есть контролы для для выбора обязательных параметров
      - Ревизий эксперимента с датами
        - Должны быть подсвечены даты начала и конца (если уже есть) ревизии. Плюс даты, за которые вообще есть данные по этой ревизии.
      - Групп экперимента с привязкой к конкретной ревизии
        - Должы быть выведены все группы конкретной ревизии. Причем должно быть сделано предположение о том, какая группа контрольная (эвристики).
    - После этого уже будут загружены метрики (может быть стоит делать по кнопке)
    - Дальше пользователь может задать срезы. Они должны быть уже загружены в интерфейс. После задания срезов пользователь нажимает "Применить" и метрики пересчитываются.
    - Отображается полотно метрик. Некоторые группы закрыты, некоторые открыты.
    - Пользователь может менять параметры и метрики должны пересчитываться
    - Пользователь может нажать на эксперимент и отобразятся еще какие-то данные
    - Если пользователь нажмет на кнопку "Копнуть глубже", то откроется выпадающее окно справа и там будет еще много инфы
    - При нажатии на закрытую группу, она должна открываться и метрики должны прогружаться. Пока грузятся показывается спиннер
    - Было бы прикольно отображать какие-то данные по прокраскам на закрытых группах (2️⃣ этап)
- 🔥 Пользователь хочет поделиться отчетом по эксперименту (2️⃣ этап)
  - Пользователь задает все фильтры и вообще все
  - Нажимает на кнопку "Сделать снепшот"
    - Формируется read-only снепшот, доступный по ссылке.
    - Возможно будет возможность куда-то экспортировать (трекер, pdf, etc)


## API и детали реализации

### Операции (API)

#### v1/metric_groups

##### GET

Получение всего списка групп с метаинформацией по каждой группе без конфига. На втором этапе можно прикрутить сюда выбор групп по параметрам и/или поиск.

**Запрос**

```json
GET /v1/metric_groups
```

**Ответ**

```json
HTTP 200 OK

{
  "metric_groups": [
    {
      "id": 2,
      "title": "Заголовок",
      "description": "Описание",
      "owners": [
        {
          "login": "ivan"
        }
      ],
      "scopes": ["taxi"],
      "is_collapsed": true,
      "updated_at": "2020-05-06T11:07:04.273624+03:00",
      "created_at": "2020-05-06T11:07:04.273624+03:00"
    }
  ]
}
```

##### POST

Создание новой группы. Эта ручка также валидирует конфиг группы как и ручка `v1/metric_groups/configs/validate`.

Создание групп с полем `verified=true` будет возможно только при наличии прав. Реализовано будет с помощью динамических пермишенов АБК (https://wiki.yandex-team.ru/taxi/backend/adminka-bez-koda/#dinamicheskiepermisheny)

**Запрос**

```json
POST /v1/metric_groups

{
  "metric_group": {
    "title": "Заголовок",
    "description": "Описание",
    "owners": [
      {
        "login": "ivan"
      }
    ],
    "scopes": ["taxi"],
    "is_collapsed": true,
    "config_source": "\nprecomputes:\n  storage:\n    yt:\n      - cluster: hahn\n        path: //home/taxi_ml/dev/abt/precomputes/users_main\n  facets:\n    sys:\n      revision:\n        column: _exp_revision_id\n      group:\n        column: _exp_group_id\n      date:\n        column: _date\n      bucket:\n        column: bucket\n    custom:\n        - type: application\n          column: _app\n        - type: city\n          column: home_town\nmetrics:\n  - name: gvm\n    title: Общий объем заказов\n    description: |\n      Cуммарная стоимость всех успешных заказов включая субсидии,\n      скидки, купоны, комиссию\n    type: ratio\n    params:\n      numerator: gmv\n      denominator: _distinct_count\n",
    "updated_at": "2020-05-06T11:07:04.273624+03:00",
    "created_at": "2020-05-06T11:07:04.273624+03:00"
  }
}
```

**Ответ**

```json
HTTP 201 CREATED

{
  "code": "ok"
}
```

```json
HTTP 400 BAD REQUEST

{
  "code": "validation_error",
  "message": "Есть ошибки валидации",
  "details": {
    "config_source": [
      {
        "error": "yt_table_not_found",
        "message": "Таблица //home/taxi_ml/dev/abt/precomputes/users_main не найдена"
      }
    ]
  }
}
```

#### v1/metric_groups/configs/validate

##### POST

Валидация конфига группы (с привязкой к идентификатору группы, если она уже создана, или нет). Вызывается на экране редактирования конфига.

**Запрос**

```json
POST v1/metric_groups/configs/validate

{
  "config": {
    "source": "\nprecomputes:\n  storage:\n    yt:\n      - cluster: hahn\n        path: //home/taxi_ml/dev/abt/precomputes/users_main\n  facets:\n    sys:\n      revision:\n        column: _exp_revision_id\n      group:\n        column: _exp_group_id\n      date:\n        column: _date\n      bucket:\n        column: bucket\n    custom:\n        - type: application\n          column: _app\n        - type: city\n          column: home_town\nmetrics:\n  - name: gvm\n    title: Общий объем заказов\n    description: |\n      Cуммарная стоимость всех успешных заказов включая субсидии,\n      скидки, купоны, комиссию\n    type: ratio\n    params:\n      numerator: gmv\n      denominator: _distinct_count\n"
  },
  "metric_group": {
    "id": 2
  }
}
```

**Ответ**

```json
HTTP 200 OK

{
  "code": "ok"
}
```

```json
HTTP 400 BAD REQUEST

{
  "code": "validation_error",
  "message": "Есть ошибки валидации",
  "details": {
    "config_source": [
      {
        "error": "yt_table_not_found",
        "message": "Таблица //home/taxi_ml/dev/abt/precomputes/users_main не найдена"
      }
    ]
  }
}
```

#### v1/metric_groups/\<group_id\>

##### GET

Получение всей информации по группе с конфигом группы

**Запрос**

```json
GET v1/metric_groups/2
```

**Ответ**

```json
HTTP 200 OK

{
  "metric_group": {
    "id": 2,
    "title": "Заголовок",
    "description": "Описание",
    "owners": [
      {
        "login": "ivan"
      }
    ],
    "scopes": ["taxi"],
    "is_collapsed": true,
    "config_source": "\nprecomputes:\n  storage:\n    yt:\n      - cluster: hahn\n        path: //home/taxi_ml/dev/abt/precomputes/users_main\n  facets:\n    sys:\n      revision:\n        column: _exp_revision_id\n      group:\n        column: _exp_group_id\n      date:\n        column: _date\n      bucket:\n        column: bucket\n    custom:\n        - type: application\n          column: _app\n        - type: city\n          column: home_town\nmetrics:\n  - name: gvm\n    title: Общий объем заказов\n    description: |\n      Cуммарная стоимость всех успешных заказов включая субсидии,\n      скидки, купоны, комиссию\n    type: ratio\n    params:\n      numerator: gmv\n      denominator: _distinct_count\n",
    "updated_at": "2020-05-06T11:07:04.273624+03:00",
    "created_at": "2020-05-06T11:07:04.273624+03:00"
  }
}
```

#### PUT

Изменение информации о группе.

Сохранение групп с полем verified=true будет возможно только при наличии прав. Реализовано будет с помощью динамических пермишенов АБК (https://wiki.yandex-team.ru/taxi/backend/adminka-bez-koda/#dinamicheskiepermisheny)

**Запрос**

```json
PUT v1/metric_groups/2

{
  "metric_group": {
    "id": 2,
    "title": "Другой заголовок",
    "description": "Описание",
    "owners": [
      {
        "login": "ivan"
      }
    ],
    "scopes": ["taxi"],
    "is_collapsed": true,
    "config_source": "\nprecomputes:\n  storage:\n    yt:\n      - cluster: hahn\n        path: //home/taxi_ml/dev/abt/precomputes/users_main\n  facets:\n    sys:\n      revision:\n        column: _exp_revision_id\n      group:\n        column: _exp_group_id\n      date:\n        column: _date\n      bucket:\n        column: bucket\n    custom:\n        - type: application\n          column: _app\n        - type: city\n          column: home_town\nmetrics:\n  - name: gvm\n    title: Общий объем заказов\n    description: |\n      Cуммарная стоимость всех успешных заказов включая субсидии,\n      скидки, купоны, комиссию\n    type: ratio\n    params:\n      numerator: gmv\n      denominator: _distinct_count\n",
    "updated_at": "2020-05-06T11:07:04.273624+03:00",
    "created_at": "2020-05-06T11:07:04.273624+03:00"
  }
}
```

**Ответ**

```json
HTTP 200 OK

{
  "status": "ok"
}
```

```json
HTTP 400 BAD REQUEST

{
  "code": "validation_error",
  "message": "Есть ошибки валидации",
  "details": {
    "config_source": [
      {
        "error": "yt_table_not_found",
        "message": "Таблица //home/taxi_ml/dev/abt/precomputes/users_main не найдена"
      }
    ]
  }
}
```

#### v1/experiments/\<experiment_name\>

##### GET

Получение метаинформации по эксперименту (описание, ответственные, тикет)

**Запрос**

```json
GET v1/experiments/superapp_parameters
```

**Ответ**

```json
HTTP 200 OK

{
  "experiment": {
    "name": "superapp_parameters",
    "description": "Параметры супераппа",
    "status": "running",
    "tracker_task": "TAXIANALYTICS-9899"
  }
}
```

#### v1/experiments/\<experiment_name\>/revisions

##### GET

Получение полной информации про ревизии эксперимента experiment_name включая даты каждой ревизии и группы, присутствующие в каждой ревизии

**Запрос**

```json
GET v1/experiments/superapp_parameters/revisions
```

**Ответ**

```json
{
  "revisions": [
    {
      "id": "efd96ed062314a7607130621ad106180",
      "started_at": "2020-05-06T11:07:04.273624+03:00",
      "ended_at": "2020-05-06T11:07:04.273624+03:00",
      "data_started_at": "2020-05-06T11:07:04.273624+03:00",
      "data_ended_at": "2020-05-06T11:07:04.273624+03:00",
      "group_div_arg_name": "phone_id",
      "groups": [
        {
          "id": 1,
          "title": "Тест-1: точки посадки (25%, Москва)"
        },
        {
          "id": 2,
          "title": "Тест-2: точки посадки (25%, Москва)"
        },
        {
          "id": 3,
          "title": "Контроль: точки посадки (25%, Москва)",
          "is_control": true,
          "is_selected": true
        },
        {
          "id": 4,
          "title": "Контроль 2: точки посадки (25%, Москва)",
          "is_control": true
        }
      ]
    }
  ]
}
```

#### v1/metrics

##### POST

Получение всего списка метрик, сгруппированного по группам. Метод предполагает передачу в него сужающих параметров.

**Запрос**

Ручка будет POST чтобы можно было передать ей кучу параметров в теле

```json
POST v1/metrics

{
  "experiment_name": "superapp_parameters",
  "revision": "efd96ed062314a7607130621ad106180",
  "groups": {
    "control": 4,
    "test": [
      1,
      2
    ]
  },
  "metric_groups": [
    1,
    2,
    3
  ],
  "facets": [
    {
      "type": "application",
      "values": [
        "ios",
        "android"
      ]
    },
    {
      "type": "city",
      "values": [
        "moscow"
      ]
    }
  ]
}
```

**Ответ**

Если в запросе поле `metric_groups`, то бекенд возвращает все перечисленные metric_groups со всеми метриками. Если клиент не шлет `metric_groups`, то возвращаются все metric_groups, но только те, которые имеют is_collapsed=true, возвращаются с метриками.

```json
{
  "params": "параметры запросы для правильной отрисовки интерфейса (обсудить с фронтом)",
  "groups": {
    "control": {
      "id": 4,
      "title": "Контроль 2: точки посадки (25%, Москва)"
    },
    "test": [
      {
        "id": 1,
        "title": "Тест-1: точки посадки (25%, Москва)"
      },
      {
        "id": 2,
        "title": "Тест-2: точки посадки (25%, Москва)"
      }
    ]
  },
  "metric_groups": [
    {
      "id": 2,
      "title": "Заголовок",
      "description": "Описание",
      "owners": [
        {
          "login": "ivan"
        }
      ],
      "scopes": ["taxi"],
      "is_collapsed": true,
      "updated_at": "2020-05-06T11:07:04.273624+03:00",
      "created_at": "2020-05-06T11:07:04.273624+03:00",
      "metrics": [
        {
          "name": "gvm",
          "title": "Общий объем заказов",
          "description": "Cуммарная стоимость всех успешных заказов включая субсидии, скидки, купоны, комиссию",
          "groups": {
            "control": {
              "id": 4,
              "metric": {
                "value": "20.78259520920341"
              }
            },
            "test": [
              {
                "id": 1,
                "metric": {
                  "value": "23.102021236344417",
                  "diff": {
                    "abs": "2.319426027141006",
                    "relative": "11.160425364556328"
                  },
                  "positive": true,
                  "color": "#009900",
                  "pvalues": {
                    "mannwhitneyu": "5.168440993868269e-33",
                    "shapiro": "8.605913759396344e-10",
                    "ttest": "5.085985476207968e-68"
                  }
                }
              }
            ]
          }
        }
      ]
    }
  ]
}
```

#### v1/facets

##### GET

Получение списка всех фасетов со всеми значениями по ним по данному эксперименту

**Запрос**

```json
GET v1/facets?experiment_name=superapp_parameters
```

**Ответ**

```json
{
  "facets": [
    {
      "type": "application",
      "title": "Приложение",
      "values": [
        "ios",
        "android"
      ]
    },
    {
      "type": "city",
      "title": "Город",
      "values": [
        "moscow",
        "spb",
        "etc"
      ]
    }
  ]
}
```


### Конфиги

**Конфиг фасетов**

Конфиг для ручки `v1/facets` и валидации таблицы прекомпьютов.

Расположение: сервис конфигов

```yaml
application:
    title: Приложение пользователя
    values_limit: 10
city:
    title: Город
    values_limit: 1000
```


**Конфиг группы метрик**

Описание метрик и источника данных одной группы метрик.

Расположение: локальная бд


```yaml
precomputes:
  storage:
    yt:
      - cluster: hahn
        path: //home/taxi_ml/dev/abt/precomputes/users_main
  facets:
    sys:
      revision:
        column: _exp_revision_id
      group:
        column: _exp_group_id
      date:
        column: _date
      bucket:
        column: bucket
    custom:
      application:
        column: _app
      city:
        column: home_towm
metrics:
  - name: gvm
    title: Общий объем заказов
    description: |
      Cуммарная стоимость всех успешных заказов включая субсидии,
      скидки, купоны, комиссию
    type: ratio
    params:
      numerator: gmv
      denominator: _distinct_count
```

Предполагается, что данный конфиг будет валидироваться в отдельной
ручке (`v1/metricgroups/configs/validate`) и при сохранении конфига группы метрик (`v1/metricgroups`)

**Список валидаций:**

  - проверки таблицы YT
    - проверяем, что она существует в указанном кластере
    - проверяем, что таблица статическая и схематизированная
  - проверки заданных колонок (сверка со схемой)
    - системные фасеты
      - все необходимые фасеты и поля указаны
      - проверка существования колонок
      - проверка типов для каждой колонки (для системных фасетов могут быть разные типы)
    - кастомные фасеты
      - проверка, что заданный тип фасета есть в конфиге фасетов
      - проверка, что для одной таблицы настроено не более, чем по одному типу каждого фасета
      - проверка существования колонок
      - проверка, что фасет имеет строковый тип (на первых парах будут только строки)
    - колонки в метриках
      - проверка существования колонок
      - проверка, что у колонки численный тип
  - проверка правильности задания метрики
    - проверки по типу метрики (пока не знаю, какие)


### Задача для индексации прекомпьютов (STQ)

Задача на индексацию **одной** таблицы прекомпьютов.
В рамках задачи мы хотим актуализировать списки экспериментов, ревизий и групп в локальной БД. А также обновить фасеты каждого типа для данной таблицы с прекомпьютами.

> Фактически, список экспериментов, список ревизий этих экспериментов и список групп каждой ревизии являются данными, которые будут только добавляться. То есть список экспериментов будет только расти. Могут только появляться новые ревизии. Список групп жестко привязан к ревизии. Не может быть нового списка групп у ревизии без появления новой ревизии.
>
> Это позволяет нам сколь угодно много раз запускать обновление этих списков без опасения за консистентность данных.
>
> Может быть мы будем обновлять заголовки групп, но не будем менять их список. И так же и с ревизиями и экспериментами.
>
> Почему это важно?
>
> Дело в том, что несколько задач stq могут выполняться параллельно. Более того, порядок выполнения задач не гарантирован. Если задача зафейлилась и выполнилась потом, то никто не гарантирует, что другая задача не выполнится пока другая фейлится.
>
> Обе эти проблемы не страшны так как сама операция идемпотентна. Нам не важен порядок так как любая задача приводит базу к консистентному состоянию.

**В рамках этой задачи:**

- Обновление списка экспериментов, групп, ревизий
  - Забираем из таблицы все **уникальные ревизии** с **группами** по каждой ревизии и с минимальными и максимальными датами по каждой ревизии
    - Вычисляем по идентификаторам ревизий **список экспериментов**, по которым у нас есть прекомпьюты. Вычисляем с помощью сервиса taxi-exp или запросом к dwh-таблице
  - Обновляем список экспериментов, ревизиий и групп в одной транзакции к локальной базе
    - Данные только дописываем
    - Если меняются какие-то минорные поля (title, name, etc), то просто обновляем их
- Пересчитываем фасеты по этой таблице


### Фасеты

Возможность делать кастомные фасеты - это постоянной растущий объем данных. В теории.

Есть один хак - ограничить количество уникальных данных для каждого фасета. Тут опять же 2 варианта - или брать ограниченное количество значений или просто запрещать такие фасеты, для которых количество данных больше N. Я за второй вариант.

**Схема хранения**

![](static/01_architecture/facets-db.png)

Внутри поля **values** будет лежать список строк с возможными значениями данного фасета.

**Алгоритм построения фасетов:**

1. При индексации таблицы прекомпьютов мы делаем простой **group by** по колонке с фасетом и получаем список уникальных значений этого фасета. Для application будет ['iphone', 'android', ...]
2. Если количество данных по этому фасету будет больше конфигурируемого N, то мы на этапе валидации скажем об этом пользователю
3. Если все ок, то мы сохраняем этот список в таблицу фасетов с привязкой к таблице прекомпьютов в сортированном виде


**Алгоритм выдачи фасетов по эксперименту пользователю**

1. Так как нам список фасетов нужен только для сужения аудитории для построения отчета по эксперименту, то данные для фасета будут привязаны к таблице прекомпьютов
2. Таблица прекомпьютов через ревизии привязана к эксперименту
3. То есть для каждого эксперимента мы будем знать, от каких таблиц прекомпьютов он зависит
4. Дальше будем делать запрос к таблице с фасетами и выбирать фасеты только для нужных таблиц прекомпьютов
5. У кажого фасета есть **type**. Список типов будет в конфиге. Пользователь не сможем создать фасеты произвольного типа.
6. Этот type нужен для того, чтобы смержить списки возможных значений фасетов из разных таблиц
7. Так как мы будем хранить фасеты в сортированном виде, то мержить списки можно будет очень эффективно
8. Возможно, это слияние можно на pg написать


## Этапы реализации

### Этап №1

Цель этапа - дать возможность строить отчеты хоть как-то.

**Скоуп:**

1. Общее **(3d)**
    1. Прохождение архревью и заведение нового сервиса в backend-py3 **(2-3d)**
    2. Заведение новой клики в CHYT на нормальном пуле **(1d)**
2. Заведение новой группы метрик **(1.5-2.5w)**
    1. Создание БД
    2. Заведение конфига для групп и метрик и разработка механизма синхронизации его с локальной бд **(2-3d)**
    3. Логика STQ для индексации таблицы прекомпьютов **(1-2w)**
3. Возможность строить отчеты **(2-3w)**
    1. Ручка `v1/experiments/<experiment_name>` **(2d)**
    2. Ручка `v1/experiments/\<experiment_name\>/revisions` **(1w)**
    3. Ручка `v1/metrics` для построения отчета без возможности указать группу метрик **(1-2w)**


### Этап №2

**Скоуп:**

1. Исправить косяки первого этапа
2. Сделать заведение групп без конфигов
3. Сделать фасеты
4. Сделать правое выдвигающееся меню


### Этап №3

**Скоуп:**

1. Шаринг отчетов
2. Кеширование (?)
3. Показывать прокрасы на группах без запроса метрик
