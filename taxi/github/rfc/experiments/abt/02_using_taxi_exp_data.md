- [Задача](#задача)
- [Как сейчас работает](#как-сейчас-работает)
  - [Процесс подготовки прекомпьютов](#процесс-подготовки-прекомпьютов)
  - [Схема базы (таблицы, связанные с ревизиями и экспериментами)](#схема-базы-таблицы-связанные-с-ревизиями-и-экспериментами)
  - [Индексация таблицы прекомпьютов](#индексация-таблицы-прекомпьютов)
  - [Ручки](#ручки)
- [Какие проблемы это приносит](#какие-проблемы-это-приносит)
  - [Самое главное](#самое-главное)
  - [Чуть менее главное, но все же](#чуть-менее-главное-но-все-же)
  - [Еще чуть менее главное](#еще-чуть-менее-главное)
- [Что хочется получить](#что-хочется-получить)
- [Решение](#решение)
  - [Целевое состояние](#целевое-состояние)
    - [Изменения в базе данных](#изменения-в-базе-данных)
    - [Изменения в процессе индексации](#изменения-в-процессе-индексации)
    - [Изменения в ручках](#изменения-в-ручках)
  - [Этапы](#этапы)
    - [1\. Переезд на бизнес-ревизии](#1-переезд-на-бизнес-ревизии)
    - [2\. Отказаться от использования таблицы revisions_flat](#2-отказаться-от-использования-таблицы-revisions_flat)
    - [Колбаски](#колбаски)


## Задача

Перейти в бэкенде abt на использование данных о ревизиях экспериментов сервиса taxi_exp вместо кастомной таблицы на YT.

Сначала опишу текущее состояние вещей.


## Как сейчас работает

### Процесс подготовки прекомпьютов

[Процесс подготовки прекомпьютов](https://github.yandex-team.ru/taxi/ml/blob/develop/projects/projects/abt/calculate_precomputes.py) берет ревизии экспериментов из таблицы [//home/taxi/production/replica/postgres/experiments_history/experiments_history](https://yt.yandex-team.ru/hahn/navigation?offsetMode=key&path=//home/taxi/production/replica/postgres/experiments_history/experiments_history) и по некоторой логике кладет в таблицы прекомпьютов только часть этих ревизий. Алгоритм предполагает выбор первой ревизии среди одной бизнес-ревизии (я тут опустил совсем содержательную часть процесса подготовки прекомпьютов и написал только про ревизии).

### Схема базы (таблицы, связанные с ревизиями и экспериментами)

![](static/02_using_taxi_exp_data/abt_db_experiments.png)

### Индексация таблицы прекомпьютов

В момент индексации таблицы прекомпьютов в [STQ](https://github.yandex-team.ru/taxi/backend-py3/blob/ef5544bc124bc51e9f2cad4c716abf8802e39750/services/abt/abt/stq/abt_index_precomputes.py#L51) происходит следующее:

1. Забираем все уникальные идентификаторы ревизии из таблицы прекомпьютов
2. Идем с ними в таблицу [//home/taxi_ml/dev/abt/precomputes/revisions_flat](https://yt.yandex-team.ru/hahn/navigation?path=//home/taxi_ml/dev/abt/precomputes/revisions_flat) и забираем оттуда название эксперимента (от которого эта ревизия), описание этого эксперимента, группы этого эксперимента (id и название)
3. Обновляем полученными данными таблицы `experiments`, `revisions`, `revisions_groups`. Плюс обновляем связи в `precomputes_tables_experiments`

### Ручки

Данные, полученные в STQ, используются в ручках `/v1/experiments`:

1. Получаем по названию эксперимента все ревизии, которые с ним связаны
2. Получаем по всем этим ревизиям их группы
3. Выводим на фронт с некоторой логикой про предзаполнение контрольных групп

и `/v1/metrics` с `/v1/metrics/plot`:

1. Резолвим по эксперименту таблицы прекомпьютов и группы метрик
2. Делаем запрос к CHYT к нужным таблицам прекомпьютов с идентификатором ревизии, который пришел


## Какие проблемы это приносит

### Самое главное

Сервис экспериментов специально для ABT ввел понятие бизнес-ревизия, которая вычисляется по какому-то алгоритму внутри сервиса экспериментов.

Сейчас существует 2 версии этого алгоритма в репозитории ml и в сервисе эксприментов. Они не совпадают.

Это плохо потому что пользователи не могут вносить разрешенные правки в эксперименты без разрыва ревизии.

### Чуть менее главное, но все же

Таблица [//home/taxi_ml/dev/abt/precomputes/revisions_flat](https://yt.yandex-team.ru/hahn/navigation?path=//home/taxi_ml/dev/abt/precomputes/revisions_flat) - костыль, от которого хочется отказаться. Все эти данные есть в ручках сервиса `taxi_exp`.

Это плохо потому что таблицу поддерживает лично Сергей Тильга и это не ок для продакш-процесса. Плюс наличие этой таблицы отдаляет нас от полного переезда процесса подготовки прекомпьютов на инфраструктуру DWH, что нужно для стабильности и предсказуемости расчетов.

### Еще чуть менее главное

В некоторых местах нам нужны данные об эксперименте и его группах. Сейчас это:

- описание эксперимента
- названия и идентификаторы групп

Мы эти данные просто берем и через таблицу `//home/taxi_ml/dev/abt/precomputes/revisions_flat` тащим в свои таблицы `experiments` и `revisions_groups`.

Одни и те же данные хранятся и поддерживаются в 3 местах:

1. Сервис экспериментов
2. Таблица `//home/taxi_ml/dev/abt/precomputes/revisions_flat`
3. Локальная база abt


Чтобы затащить новые данные нужно их добавить в `revisions_flat`, потом сделать миграцию базы и написать код, который будут их в этой базе обновлять. От `revisions_flat` вообще обязательно отказаться.

Как и описано в заголовке к этойму пункту, это минорная боль. Но её нужно полечить вместе с отказом от `revisions_flat`.


## Что хочется получить

1. Алгоритм вычисления бизнес-ревизии живет в одном месте - сервис экспериментов. Со стороны данных для этого все готово - DWH поддержали в объекте [agg_experiment_v3_revision](https://doc.yandex-team.ru/taxi/dmp/services/Taxi/yt/cdm/ab_experiment/agg_experiment_v3_revision.html) поле `business_min_version_id`, но нужно синхронизироваться с сервисом abt, так как ревизии поменяются.
2. Отказаться от использования таблицы `//home/taxi_ml/dev/abt/precomputes/revisions_flat`
3. Не хранить в локальной базе abt метаданные эксперимента в том числе группы ревизий. Брать эти данные на лету из сервиса `taxi_exp`


## Решение

### Целевое состояние

Флоу идеального варианта :)

![](static/02_using_taxi_exp_data/flow.png?v3)

#### Изменения в базе данных

1. Удаляем таблицу `experiments`
2. Удаляем таблицу `precomputes_tables_experiments`
3. Добавляем таблицу `precomputes_tables_revisions` для связи таблиц прекомпьютов напрямую с ревизиями. Одна ревизия может фигурировать во многих таблицах прекомпьютов, так что *many-to-many*.
4. Удаляем таблицу `revisions_groups`
5. Заменяем в таблице `revisions` foreign-key `experiment_id` на `experiment_name TEXT NOT NULL`
6. Добавляем в таблицу `revisions` колонки:
   - `business_revision_id INT`
   - `business_max_version_id INT`
   - `business_min_version_id INT`

#### Изменения в процессе индексации

1. Получаем из таблицы прекомпьютов все уникальные ревизии
2. С помощью `archive-api` получаем из таблицы [//home/taxi/production/replica/postgres/experiments_history/experiments_history](https://yt.yandex-team.ru/hahn/navigation?offsetMode=key&path=//home/taxi/production/replica/postgres/experiments_history/experiments_history) пары `revision_id<->experiment_name`
3. Для каждого полученного эксперимента через запросы к ручке `/v1/experiments/revisions` сервиса `taxi_exp` получаем нужные нам ревизии. Цель - актуализировать таблицу `revisions`. Добавить, если нужно, новые ревизии. И обновить, если нужно, поле `ended_at` у уже существующих (подробное описание алгоритма лучше в тикете). В локальной базе данных по эксперименту должны лежать все ревизии, если хотя бы одна из ревизий есть в таблице прекомпьютов. Обновлять нужны только data_available_days, если они меняются в прекомпьютах.
4. Обновляем `data_available_days` из данных таблицы прекомпьютов.
5. Обновляем связи в `precomputes_tables_revisions`

#### Изменения в ручках

**Ручка** `/v1/experiments`

Цель этой ручки - это выдать инфу про эксперимент со списком ревизий.

Всю эту информацию можно восстановить из ручки `/v1/history` сервиса `taxi_exp`. Так как ревизий у одного эксперимента может быть много, есть 2 варианта реализации:

1\. Без создания новых ручек и без работы фронта

1. Фронт шлет нам `experiment_name`, мы по нему поднимаем список всех N ревизий данного эксперимента из локальной базы
2. Делаем N запросов к `taxi_exp:/v1/history`
3. Формируем и отдаем ответ

> `taxi_exp:/v1/history` внутри себя ходит либо в локальный PG (быстро) либо в YT (медленно ~1-2 секунд). Все старые ревизии вытесняются в YT. Так что для них всегда будет медленно.
> При N запросах, это может сильно увеличить скорость ответа нашей ручки и ухудшить UX

2\. С созданием новых ручек и работой фронта

> По фронтенду оценка 2-4 часа после 19 февраля

1. Шлем запрос на новую ручку `/v2/experiments?experiment_name=exp`
2. Ручка отдает из локальной базы идентификаторы ревизий (`business_max_version_id`) и даты
3. Пользователь выбирает нужную
4. Фронт делает запрос на вторую новую ручку `/v1/revisions?revision_id=100500`
5. В этой ручке один раз ходим в `taxi_exp:/v1/history` и отдаем пользователю инфу про ревизию

> Здесь тоже есть проблема с медленным походом к `taxi_exp:/v1/history`, но тут будет только один поход. Велика вероятность, что пользователь выберет самую свежую ревизию и она будет в PG `taxi_exp`


**Ручки** `/v1/metrics` и `/v1/metrics/plot`

Для получения названий групп нужно сходить к `taxi_exp:/v1/history`.

> Этот запрос можно делать параллельно с запросом метрик.

От фронта мы получаем ревизию `business_max_version_id`, но для запроса к CHYT нужна `revision_id`. Её нужно получить запросом к `revisions`.


### Этапы

> Как же дойти до целевого состояния без простоя...

Как мне кажется, тут лучше всего работать по стримам в соответствие с тем, [что хочется получить](#что-хочется-получить)

#### 1\. Переезд на бизнес-ревизии

В процессе подготовки прекомпьютов все относительно просто. Логи экспериментов будут матчиться не с [//home/taxi/production/replica/postgres/experiments_history/experiments_history](https://yt.yandex-team.ru/hahn/navigation?offsetMode=key&path=//home/taxi/production/replica/postgres/experiments_history/experiments_history), а с [agg_experiment_v3_revision](https://doc.yandex-team.ru/taxi/dmp/services/Taxi/yt/cdm/ab_experiment/agg_experiment_v3_revision.html). При этом в поле `_exp_revision_id` таблиц с прекомпьютами будут попадать идентификаторы из поля `business_min_version_id`.

Сразу после обновления и до того момента, пока процесс индексации abt не пройдет все обновленные таблицы, данные будут неконсистентны. Это около 2 минут. Учитывая загруженность abt, с этим можно смириться. А, если сделать вечером или в субботу, то вообще никто не заметит.

Еще есть прекрасный конфиг [ADMIN_NOTIFICATIONS](https://tariff-editor.taxi.yandex-team.ru/dev/configs?name=ADMIN_NOTIFICATIONS), которым можно показывать нотификации в админке.

Сейчас в abt поддержана только операция upsert. То есть ревизии могут только добавляться. После изменения идентификаторов все ревизии будут новыми. Но и старые останутся. Нужно будет сделать процесс, который будет удалять старые ревизии.

Это актуально и для кейса устаревших данных. Прекомпьюты считаются только за последний месяц. Все, что раньше, нужно чистить. Иначе пользователь видит фигню в интерфейсе.

**Задачи:**

  - Сделать процесс удаления из локальной БД ревизий, которых нет ни в одной таблице прекомпьютов


#### 2\. Отказаться от использования таблицы revisions_flat

Так как нельзя просто взять и сделать миграции БД, надо идти последовательно. Сначала перестать использовать старые таблицы, потом их удалить.

Сначала начинаем брать данные по эксперименту напрямую из `taxi_exp`

**Шаг 1**

Делаем новую ручку `/v2/experiments?experiment_name=exp`, которая пока через foreign-key к `experiments` находит все связанные ревизии и возвращает их.

Делаем новую ручку `/v1/revisions?revision_id=100500`, которая выдает всю инфу по ревизии через поход до `taxi_exp`.

Меняем поведение в ручках `/v1/metrics` и `/v1/metrics/plot` - получаем имена групп из ответа `taxi_exp`.

*Все можно делать параллельно*

**Шаг 2**

Ждем пока фронт полностью перейдет на новые ручки. Только после этого закапываем старые и двигаемся дальше.

Удаляем таблицу `revisions_groups`

Создаем новые поля в таблице `revisions`:

- `experiment_name`
- `business_revision_id`
- `business_max_version_id`
- `business_min_version_id`

Создаем новую таблицу `precomputes_tables_revisions`

Переписываем код индексации таблиц прекомпьютов таким образом, чтобы создавались и старые связи (`precomputes_tables_experiments`) и новые (`precomputes_tables_revisions`, `experiment_name` в таблице `revisions`).

Процесс очистки ненужных ревизий может работать только с новыми связями.

**Шаг 3**

Делаем миграцию, в которой:

- заполняем все пустоты поля `experiment_name` таблицы `revisions`
- восполняем все связи в таблице `precomputes_tables_revisions`

Меняем логику работы `/v2/experiments?experiment_name=exp` таким образом чтобы она ходила только в таблицу `revisions`.

Меняем поведение в ручках `/v1/metrics` и `/v1/metrics/plot` - резолвим таблицы прекомпьютов только через ревизии.

**Шаг 4**

Удаляем таблицы `experiments` и `precomputes_tables_experiments`.


#### Колбаски

![](static/02_using_taxi_exp_data/sausages.png)
