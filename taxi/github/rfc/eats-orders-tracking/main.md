## Опросник для ревью комитетом

> Этот опросник нужен для [архитектурного ревью комитетом](https://forms.yandex-team.ru/surveys/25357/). Его можно будет скопировать.

> После его написания можно пробежаться по списку из [этой статьи](https://stackoverflow.blog/2020/04/06/a-practical-guide-to-writing-technical-specs/). Он подскажет, какие аспекты еще стоит осветить.

**Название сервиса**

eats-orders-tracking

**Какую продуктовую проблему решает сервис?**

Сервис отдает данные по заказам (включая данные по ресторану, курьеру, статусу платежа и курьерским координатам), доступным пользователю для трекинга.

**Почему нельзя решить эту задачу без разработки нового сервиса существующими решениями?**

* Сервис создается в рамках выноса логики из монолита Еды в отдельный сервис на C++.
* Текущее решение съедает около 20–25% CPU PHP-монолита, вынос в отдельный сервис позволит снять эту нагрузку с монолита.
* В дальнейшем планируется активное увеличение количества данных на Трекинге, имеет смысл делать это уже в отдельном сервисе.
* Также в дальнейшем планируется сделать управление типами экранов трекинга через админку - сами типы экранов будут заложены на первом этапе, управление в админке добавится на следующем.

**Как именно сервис будет решать поставленные перед ним задачи?**

1. Сервис Трекинга получает из Монолита Еды эвентом данные о заказе (включая промис) и кэширует их в стейт и базу.
2. На каждый клиентский запрос Трекинг достает пулингом ID курьера, статус доставки, курьерские координаты и eta (время до доставки) из сервиса Courier Aggregation (CA, пока отсутствует) и кэширует их на 45 секунд.
3. Данные по курьеру, ресторану и КЦ сервис достает пулингом из Монолита 1 раз на заказ и затем кэширует их в стейт и базу.
4. При смене курьера Трекинг обновляет данные по нему из Монолита.
5. Со временем Трекинг получает эвенты об изменении заказа.
6. Если клиент приходит за трекингом конкретного заказа, которого ещё нет у нас (Монолит не прислал данные), то идем за этим заказом в ручку Монолита.

**Разрабатывается один сервис или система?**

Один сервис

**Сколько и какие сервисы входят в систему?**

[Документация](https://wiki.yandex-team.ru/eda/dev/backend/services/tracking-service/#kartaservisov).

**С кем взаимодействует сервис?**

- Клиентское приложение получает список заказов из Трекинга (HTTP)
- Монолит Еды:
    - пушинг эвентов о заказе в Трекинг (через HTTP)
    - Трекинг может пулить заказы из ручки Монолита, если Монолит до этого еще не успел их запушить
    - Трекинг получает данных о ресторане, курьере и КЦ из Монолита
- Сервис Courier Aggregation (сейчас отсутствует):
    - Трекинг идет в CA за ID курьера, статусом доставки, курьерским координатам и eta

**Какие базы использует?**

PostgreSQL.

**Какие периодические процессы?**

Периодическая очистка данных в БД от устаревшего кэша.
Кэш заказов будет храниться сутки, кэш курьеров и ресторанов - 12 часов.

**Прикрепите схему того, где этот сервис находится в текущей инфраструктуре**

Схема в [документации](https://wiki.yandex-team.ru/eda/dev/backend/services/tracking-service/#kartaservisov).

**Какие данные и по какой схеме сервис будет хранить в базе?**

```sql
CREATE SCHEMA eats_orders_tracking;

-- таблица списка заказов авторизованных итеров
CREATE TABLE IF NOT EXISTS eats_orders_tracking.auth_orders
(
  id BIGSERIAL PRIMARY KEY,
  eater_id TEXT NOT NULL,
  order_nr TEXT NOT NULL,
  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);
CREATE INDEX auth_orders_eater_id_idx ON eats_orders_tracking.auth_orders (eater_id);

-- таблица списка заказов неавторизованных итеров
CREATE TABLE IF NOT EXISTS eats_orders_tracking.noauth_orders
(
  id BIGSERIAL PRIMARY KEY,
  inner_token TEXT NOT NULL,
  order_nr TEXT NOT NULL,
  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);
CREATE INDEX noauth_orders_inner_token_idx ON eats_orders_tracking.noauth_orders (inner_token);

-- таблица кэша заказов
CREATE TABLE IF NOT EXISTS eats_orders_tracking.orders_info
(
  order_nr TEXT NOT NULL,
  payload JSONB NOT NULL, -- пэйлоад с кэшированными данными по заказу,
                          -- включая данные КЦ, статус платежа, eta и курьерские координаты
  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  PRIMARY KEY (order_nr)
);

-- таблица кэша ресторанов
CREATE TABLE IF NOT EXISTS eats_orders_tracking.places_info
(
  place_id TEXT NOT NULL,
  payload JSONB NOT NULL, -- пэйлоад с кэшированными данными по ресторану
  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  PRIMARY KEY (place_id)
);

-- таблица кэша курьеров
CREATE TABLE IF NOT EXISTS eats_orders_tracking.couriers_info
(
  courier_id TEXT NOT NULL,
  payload JSONB NOT NULL, -- пэйлоад с кэшированными данными по курьеру (кроме eta и координат)
  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  PRIMARY KEY (courier_id)
);

-- таблица типов экранов
CREATE TABLE IF NOT EXISTS eats_orders_tracking.display_types
(
  display_type_code TEXT NOT NULL,
  title TEXT NOT NULL, -- заголовок ситуации
  description TEXT NOT NULL, -- описание ситуации
  buttons JSONB NOT NULL, -- json кнопок на экране (тип, title, payload и actions для каждой кнопки)
  icons JSONB NOT NULL, -- json иконок на экране (статус, uri и payload для каждой иконки)
  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  PRIMARY KEY (display_type_code)
);
```

Сами ситуации, для которых определены типы экранов, заведем в экспериментах.
Для каждой ситуации по параметрам: client_app, delivery_type, order_type, order_status, эксперименты будут возвращать код типа экрана.

**Какой объем данных будет храниться и какой объем будет изменяться в единицу времени?**

Объем хранимых данных: от нескольких десятков Мб до 100 Мб при хранении заказов за последнии сутки.
Рассчитывается как 100 000 заказов в день * 20 полей * 8-30 байт = 15-60 Мб хранимых данных по заказам в сутки.
Также на 12 часов будут кэшироваться данные по ресторанам (20 000 ресторанов * 10 полей * 8-30 байт = 1.5-6 Мб) и курьерам (30 000 курьеров в сутки * 5 полей * 8-30 байт = 2-7 Мб).

Объем типов экранов будет незначительным по сравнению с заказами (до 1 Мб), хотя и будет храниться постоянно.

Объем изменяемых данных: при пушинге будут добавляться/обновляться до нескольких десятков записей - т.е. примерно 30-50 Кб в секунду.

**Какие операции над данными заложены?**

Данные ресторанов и курьеров будут кэшироваться на 12 часов.
Данные заказов будут храниться сутки, при пушинге будут обновляться.

Удаление устаревшего кэша (для заказов - старше суток, для ресторанов и курьеров - 12 часов).

Типы экранов будут храниться на постоянной основе.

**Есть ли какой-то стейт в памяти, как он обновляется и валидируется?**

Кэш заказов на сутки, ресторанов и курьеров на 12 часов, а также статус доставки, eta и курьерские координаты на 45 секунд.

Кэш типов экранов.
Нужен, чтобы при старте сервиса доставать из базы все типы экранов и закэшировать их в стейт, чтобы не делать лишних запросов в базу на получение типа экрана.
А потом периодически обновлять этот кэш (раз в 15 минут, скажем).

**Какая нагрузка ожидается?**

- До 2500 RPS на ручку `/tracking` (текущая нагрузка на ручку трекинга в Монолите).
При этом надо учитывать, что большая часть запросов будет отваливаться, не доходя до логики, т.к. при неавторизованном запросе мы отдаём захардкоженный json.
Аналогично для ситуации с отсутствием заказов в трекинге (но в этом случае будет запрос в базу).

- До нескольких десятков RPS на ручку `/order` для пушинга данных по заказу.
Рассчитывается так: 100 000 заказов в сутки * 5-10 запросов на заказ / 86400 = 6-11 запросов в секунду.

Возможен рост нагрузки с ростом количества заказов в Еде.

**Какие фолбеки предусмотрены на сам этот сервис?**

Если сервис откажет, то пользователь не сможет увидеть список своих заказов в трекинге.
После восстановления сервис Трекинга достанет данные из базы, если их там нет - то обратится к ручке Монолита для получения заказов пользователя.
При обращении к трекингу по заказу, которого нет в БД, мы сходим в ручку Коры за данными по order_nr.

Если для заказа не нашелся тип экрана, то эксперименты должны отдать фолбэчное значение. Соответственно, должен быть фолбэчный тип экрана на случай, если для заказа не нашелся никакой.

**Какие фолбеки предусмотрены внутри этого сервиса на взаимодействие с другими сервисами?**

- Если откажет Монолит, то Трекинг будет брать данные из базы. После восстановления Монолита он запушит эвенты в Трекинг, и данные там обновятся.
- Если откажет сервис Courier Aggregation (CA), то берем текущие координаты курьера из базы, а eta уменьшаем линейно относительно последнего значения из базы.
- Если недоступны эксперименты, то должен отдаваться фолбэчный тип экрана.

**Какие возможности масштабируемости закладываются?**

Наращивание количества инстансов сервиса при увеличении нагрузки.

**Какие точки отказа есть в сервисе?**

- БД
- Потеря связности с Монолитом и сервисом Courier Aggregation

**Укажите ключевые продуктовые метрики сервиса, за которыми планируете следить**

- Количество заказов, доступных для трекинга, в единицу времени
- Количество типов экранов, которые собираются в единицу времени

**Укажите технические метрики**

- Все ответы от трекинга в логах для дебага, с order_nr, eater_id, inner_token в контекстах для индексации
- Серверные метрики (CPU, RAM, i/o и т.д.)
- Ошибки в логах

**Какая функциональность ожидается в сервисе в будущем?**

Добавление новых данных, выводимых в трекинге.

**Какое изменение нагрузки планируется?**

Пропорционально росту количества заказов в Еде.

**Активно ли будет изменяться сервис?**

Возможно, будет добавляться агрегация новых данных, выводимых в трекинге.
Также на следующем этапе будет добавлено управление типами экранов трекинга.

<hr>

## Бизнесовая задача

## Архитектура

### API

[Здесь.](docs/api/)

### Эксперименты

Для выбора типа экранов будет использоваться либа экспериментов для uservices - она кэширует эксперименты консьюмера и периодически их обновляет из сервиса экспериментов.

### Клиентская логика

Не меняется, то, какой роут (старый из Монолита или новый из сервиса) будет использоваться, будет разграничиваться экспериментом в api-proxy.

### Дальнейшая судьба трекинга в Монолите

Ручка Трекинга в Монолите постепенно будет упразднена.
