## Цель изменений:
- научить платформу автоматически:
  - разделять топики на логи/не логи
  - конфигурировать топики с логами для поставки в новую систему
  - поставлять топики в конфиги логшаттера для запуска
- сделать более прозрачным для пользователя добавление логов его сервиса в систему

## Идеальная ситуация, к которой хочется стремиться:
1) клиент пишет что-то простое у себя в service.yaml
2) выкатывает сервис
3) \*логи сервиса в новой системе\*

## Основная идея:
### На стороне платформы (core, uservices, backend-py3):
Сейчас кор-плагин push-client по каждому сервису собирает файлик logbroker.yaml 
со списком топиков и разной метой (logbroker_installation, topic_path, service_environment).

Пример logbroker.yaml: https://a.yandex-team.ru/arcadia/taxi/codegen/tests/codegen_plugins/static/test_push_client/test_clownductor_aliases/generated/services/test-service/push-client/logbroker.yaml

Сейчас этот файлик через teamcity и clownductor при выкатке сервиса проксируется 
в logs-from-yt (где по сервису есть список топиков, сконфигурированных 
через плагин push-client), чтобы тот создал топики и настроил права. 

Предлагается в этот файлик logbroker.yaml добавить ещё один
параметр `content_types: Array['app_logs', 'traces', 'extra']`, и для каждого топика из плагина push-client прописывать 
параметр. Таким образом мы сможем в logs-from-yt понимать, в каких топиках сервиса действительно 
лежат логи (и добавлять их в пайплайн логов). 
Список значений этого поля type может в будущем расширяться (3 строчки в кор-плагин push-client + мёрж в платформы)

### На стороне logs-from-yt:
Предлагается в самой ручке конфигурации логброкера в logs-from-yt только создавать нужные топики
 и выдавать writeTopic права нужному сервису (как и было раньше). 
Но дополнительно на этом этапе будем сохранять в базу (в новую табличку) данные,
 полученные в этой ручке (logbroker.yaml сматченный на бранчи) в каком-то виде.

А для конфигурации топиков именно для логшаттера и кх будет отдельная крона logshatter-for-logs-configuration, 
которая будет проходиться по этой новой табличке (и по конфигу LOGS_FROM_YT_CONFIGURE_LOGSHATTER) 
и понимать, какие топики для каких сервисов нужно сконфигурировать, т.е. дать readTopic права логшаттеру, 
создать read-rule и добавить топик в какой-то конфиг логшаттера (в данный момент в зависимости от платформы сервиса).

Сохранение в базу также даст возможность ловить коллизии в именовании топиков на этапе ручки 
(например, 2 сервиса с разных платформ почему-то пишут в один топик логи, нужно это обработать).

Также, для новой кроны конфигурирования логшаттера, предлагаю сделать конфиг:
```
LOGS_FROM_YT_CONFIGURE_LOGSHATTER

{
    'platform_to_lsh_config_map': {                                   // маппинг из платформы в конфиг логшаттера, чтобы понимать
        'uservices': 'logshatter_config_name_for_uservices_logs',     // в какой конфиг класть логи сервиса из такой-то платформы
        'backend-py3': 'logshatter_config_name_for_backend-py3_logs'
    },
    'services': {
        'project_name1': {
            'service_name1': {
                'lsh_configuration_enabled': false
            }
        },
        'project_name2': {
            'service_name2': {
                'lsh_configuration_enabled': true,
                'extra_params': {}
            }
        }
    },
    ‘default’: {        // То, что будет подставляться, если сервиса нет в services.
        'lsh_configuration_enabled': true
    }
}
```

из которого мы будем понимать, для каких сервисов нужно конфигурировать logshatter (в кроне logshatter-for-logs-configuration). 
Параметр default определяет дефолтное поведение, если сервиса нет в services.

### Реализация идеи со стороны платформы:
Теперь о том, как будет прокидываться этот параметр content_types: Array[app_logs/traces/extra] в push-client.
1) Не хочется, чтобы плагин пуш-клиент сам как-то матчил и определял, что это за файлик
   => матчить файлики на их тип должны те, кто ходит в push-client, а он будет просто проксировать это поле
2) __Uservices__: сейчас там есть плагин server-log, с помощью которого люди включают запись продакшн-логов сервиса в 
   logbroker. Этот плагин генерирует имя топика, знает, в каком файлике лежат логи, и дёргает push-client.
   Помимо этого, этот плагин делает ещё много чего.
3) __backend-py3__: сейчас есть 2 способа начать писать файлик в логброкер:
   1. написать конфиг для push-client самому и воспользоваться плагином debian, чтобы довезти этот файлик
   2. воспользоваться плагином push-client в service.yaml (никто этим не пользуется)
   Оба этих способа не подходят под "что-то простое и прозрачное"
   
   
4) Из-за отсутствия простого инструмента в uservices и backend-py3 решили написать __core-плагин logs-to-logbroker__:
      - он будет вызываться из service.yaml так же просто, как и server-log (не требуется знание файлов/топиков)
      - плагины юнитов backend-py3 (web, cron, stq) и uservices (uservice_unit) будут ходить в него, передавая имена файликов с логами
      - он будет генерировать имя топика и активировать push-client (с нужными файликами, топиками и content-types: [app_logs])

5) Для корректной совместимости, те сервисы, которые уже пишут логи в логброкер каким-либо образом, нужно будет перевезти на другие (новые) инструменты:
    - С самописных конфигов и debian: environment_install на использование плагина push-client (с возможностью указания кастомных watcher и logger и топиков)
    - С использования server_log:send_to_yt:true на использование logs_to_logbroker:send_to_logbroker:true (с возможностью указания кастомных/старых топиков)

Итоговая схема:
![](./schema.png)
