# Общая информация

* [**Источник**](../../sources/sources.md) (**source**) — это сущность, из которой идет чтение данных.
* [**Таргет**](#target) (**target**, **destination**, **приемник**) — это сущность, в которую пишутся предобработанные данные.
* [**Маппер**](mappers.md) (**mapper**) — это набор преобразований данных, сопоставляющийся таргетам.
* [**Правило**](#rule) (**rule**) — единица, однозначно определяющая источник (то, откуда идет чтение данных) и его таргеты (то, куда данные пишутся).
* **Группа правил** (**rule_scope**) — одна папка (ее имя — имя группы) в общем каталоге [**replication_rules**]({{ link_to_rule_scopes }}).
* [**Драфты**](drafts.md) — основной способ поменять состояния правил и таблиц.
* [**Секрет**](secrets.md) — набор данных для подключения к источнику.

{% cut "Структура каталога такая:" %}

```
replication_rules/
    {rule_scope_1}/
        mappers/
            {mapper_1}.yaml
            {mapper_2}.yaml
        mappers-tests/
            {mapper_1}.json
        {target_type}-targets/
            {target_1}.yaml
        plugins/
            __init__.py
            config.yaml
        {rule_1}.yaml
        {rule_2}.yaml
    {rule_scope_2}/
        {rule_3}.yaml
    ...
```

{% endcut %}

* В корне каждой группы лежат yaml-правила
* В папке `mappers` и `mappers-tests` — описываются мапперы и их тесты, в папке `/{target_type}-targets` — описываются таргеты
* В папке `plugins` находится [плагины для мапперов](mappers.md) и `config.yaml` для группы правил

## Быстрое заведение новых правил

{% note warning %}

Для создания нового правила воспользуйтесь тулзой [**ГЕНЕРАЦИИ ПРАВИЛ**]({{ link_to_gen_rules }}) - это самый быстрый
способ завести новые правила. Для редактирования переходите сразу к [описанию правил](#rule).

{% endnote %}

## Ручное заведение yaml правила {#new-rule}
Для нестандартных ситуаций придется отредактировать сгенерённые файлы или создать новые вручную. Общая схема такая:
Нужно описать в формате yaml **правило**, **мапперы** и **приёмники** (targets).

1. Если источник ранее не был добавлен нужно заполнить новый [yaml-файл с правилом](#rule). Есть 2 способа:
    * Запустить тулзу для [генерации правил]({{ link_to_gen_rules }}).
    * Создать файлы вручную, если ваш кейс не поддержан.

2. Для [$raw](generated-targets.md) шаг можно пропустить. Иначе, если создаётся новый [маппер](#mappers),
то нужно добавить в:
    * `mappers/` - `*.yaml` описание
    * `mappers-tests/` - тесты в формате `*.json` или `*.yaml`
    * `plugins/` - опционально, тут можно писать свой код для мапперов
    * Детальное описание приемников хранится в `/{target_type}-targets`, например, для YT это будет
подкаталог: `/yt-targets`.

3. Если заводится новая группа правил, то необходимо также [указать ответственных](responsible.md).

## Пример правила репликации с комментариями {#example}

{% cut "Полный пример" %}

```yaml
# Created with generator. Save this comment for future reference.
# Launch args: --source postgres --secret-source market_logistics_management_service --tables logistics_point --with-ext
name: market_lms_logistics_point  # имя правила, уникально в рамках сервиса, хорошо, если начинается с имени неймспейса группы правил
replication_type: queue   # queue - для репликации диффа чанками по какому-то полю, queue_snapshot - снапшот
source:
    type: postgres
    connection:
        # алиас секрета из plugins/config.yaml
        secret: market_logistics_management_service
    table: logistics_point  # тут таблица в общей схеме, но если есть кастомная, ее надо указать
    # Для постгреса есть кастомная настройка, если источник не поддерживает prepared_statment, то есть идут ошибки в духе:
    # pgbouncer with pool_mode set to "transaction" or "statement" does not support prepared statements properly
    prepared_statement_disabled: true
    primary_key:
      - id  # список ключевых колонок, ключ может быть композитным
    #######   replicate_by, timezone, iteration_type - нужно только для реплкации инкрементом
    replicate_by: updated  # имя поля в таблице, по которому будем брать дифф,
                           # тут может быть поле со временем обновления или целое id (если нет обновлений)
    timezone: Europe/Moscow # если в replicate_by дата не в UTC, надо указать таймзону поля. иначе будут задержки в 3 часа
    iteration_type: sequence  # нужно только для postgres, есть убрать, то дифф будет забираться строго чанками в 5 минут
    #######  при заборе диффами запуск по умолчанию раз в минуту
    #######  при заборе снапшотом запуск по умолчанию раз в сутки. Когда релиз выкатил, тогда и время запуска. Чтобы это поменять, нужно использовать upload_planner:
    upload_planner: # тут настраивается расписание или периодичность запуска, актуально для снапшотов
        schedule:
            period: 7200  # Частота в секундах. Тут - раз в 2 часа, в 00:00, 02:00, 04:00 и тд. Тут же можно указать и крон

destinations:  # тут фактически консьюмеры очереди репликации - raw, raw_history (если есть) и внешний - для потокового чтения
  # описание RAW поставки
  - market_lms_logistics_point_raw:
        type: yt
        mapper: $raw  # стандартный маппер для сырых данных
        target:
            cluster_groups:
              - map_reduce  # для поставки на хан и арольд
              # - runtime  # для поставки на seneca-* кластера
            prefix: market-dwh  # по этому префиксу выбирается корневая папка в YT, алиас задан в replication_rules/replication.yaml
            # относительный путь на YT. Если таблица не партиционирована, она должна лежать в одноименной папке
            path: raw/logistics_management_service/logistics_point/logistics_point
            raw_settings:  # параметры таблицы на YT
                yt_columns_info:
                # тут только поля ПК, поля партиционирования (если есть) и их трансформации (если есть)
                  - name: id  #  это ключ ПК
                    type: int64 # его исходный тип, если надо поменять - стоит использовать cast
                    sort_order: ascending  # для ПК нужна сортировка
                    description: Идентификатор
            raw_rebuild_data: true  # по умолчанию стоит ставить для сырого слоя, чтобы он автоматически выстапал потом доверительным источником данных в драфтах yt_ctl
    # описание RAW history поставки для диффов
    market_lms_logistics_point_raw_history:
        type: yt  # тип таргета
        mapper: $raw  # тот же стандартный маппер
        target:
            cluster_groups:
              - map_reduce
            prefix: market-dwh
            # raw history обычно лежит в подпапке etl
            path: etl/raw_history/logistics_management_service/logistics_point
            raw_settings:
                yt_columns_info:
                # тут только поля ПК, поля партиционирования (если есть) и их трансформации (если есть)
                  - input_column: updated  # это поле для партиционирования исторических даных
                    name: utc_updated_dttm  # переименовываем в стандартное
                    cast: datetime_to_string_with_default  # это кастомный маппер, определен в plugins/ группы правил
                    type: string  # тип на YT
                    sort_order: ascending
                    description: Дата последнего изменения в UTC
                  - name: id  # это ПК, его надо указывать всегда с sort_order
                    type: int64
                    sort_order: ascending
                    description: Идентификатор
                partitioning:
                    rotate_policy: eternal
                    type: by_months  # партиционирование по месяцам. Рекомендация на 1 партицию: несколько гигабайт
                    cast_to_date: utc_from_isostring  # как вычислять дату из поля партиционирования, стандартный маппер
                    field_name: utc_updated_dttm  # поле партиционирования - новое имя после переименования
    # это возможность подключить читателя к репликации по API. Используется для ODS загрузок
    market_lms_logistics_point_ext:  # любое имя, дальше по нему можно читать
        type: ext
        target: {}
queue_data:
    db_cluster: replication_queue_1  # тут есть возможность указать кастомную очередь репликации
```

{% endcut %}


## Описание правила репликации {#rule}
Правило репликации — это совокупность условий, по которым данные
будут проходить полный цикл от источника до приёмника.
Они описываются в yaml формате следующим образом:

* `name` — имя правила. По нему можно будет найти правило в админке. Стоит указывать имена с префиксом группы правил или неймспейса: имена глобальные по сервису.
* `replication_type` — тип репликации.
    * **queue** — стандартный итеративный тип репликации через очередь.
    * **queue_snapshot** — полное перекладывание снапшотов
    (с учётом удаления), на данный момент
    реализовано не для всех типов источников.
* `source` — информация об источнике. Подробнее в [разделе](../../sources/sources.md) про источники.
    * `type` — указывает на тип источника.
    * `primary_key` — первичный ключ источника. Также будет дедуплицировать записи в очереди, так что крайне важно указать его точным (возможно, композитный).
       Нужен не для всех типов источников.
    * `connection` — есть почти у всех источников, тут нужно указать примерно следующее: `secret: secret_alias_from_config_yaml`,
       подробнее [здесь](secrets.md#secret_config_yaml).
    * `table` — есть почти у всех источников, тут нужно указать имя таблицы вместе со схемой
    * `replicate_by` — поле репликации, для репликации по инкременту (`replication_type: queue`). Подробнее можно прочитать здесь.
    * `upload_planner` — возможность указать дополнительные параметры для загрузки.
        * `schedule` — здесь можно указать расписание. Считается по Москве.
        Можно указать для всех типов репликации (и для снапшотов, и для репликации по
        инкременту). По умолчанию задан `period`: 60 секунд для прода, 120 секунд для тестинга.
        Если тип репликации снапшот, то по умолчанию `period` равен 86400 и для тестинга, и для прода.
            * `cron` — строка в крон формате, пример: `'*/5 * * * *'`.
            При этом поддерживается вариация по окружениям:
            ```
            cron:
                production: '*/5 * * * *'
                testing: '* * * * *'
            ```
            * `period` — период, делящий сутки в секундах. Пример: 600 (10 минут).
            Поддерживается вариация по окружениям. Взаимоисключающий параметр с `cron`.
        * `overlaps` — здесь можно указать отступы для источника. Для репликации по дате задаётся
        в секундах.
            * `past` — отступ влево от левой границы (в секундах) интервала, за который
            выбираются документы. Отсутп делается только один раз в начале, а не на каждый
            чанк. Используется, например, при изменениях задним числом на N минут.
            Этот параметр может привести к увеличению объёма обрабатываемых документов.
            Поддерживается вариация по окружениям (примеры выше).
            * `future` — отступ вправо от правой границы (в секундах) интервала, за который
            выбираются документы. Используется при частых обновления документов. Этот параметр
            может привести к увеличению объёма обрабатываемых документов. Поддерживается вариация
            по окружениям (примеры выше).

        {% note warning %}

        Если нужно реплицировать только документы, которые не моложе N минут, то стоит
        воспользоваться параметром `from_now_by_targets` в
        [конфиге](https://tariff-editor.taxi.yandex-team.ru/dev/configs/edit/REPLICATION_SERVICE_CTL?group=replication_service).

        {% endnote %}

    * `pre_map_func_names` — возможность указать дополнительные премапперы,
    например чтобы зафильтровать часть документов при чтении из источника.
    Не используется для типа **api**.
    * `iteration_type` — можно указать следующие типы итерирования:
    **sequence** — чтение с фиксированной правой границей и лимитами
    (лимит можно поправить параметром `data_chunk_size`).
    Для репликации по автоинкременту (int) нужно использовать следующую комбинацию
    параметров (такой тип репликации может быть поддержан не для всех источников):
    ```
    type_of_replicate_by: int
    iteration_type: sequence
    ```
* `queue_data` — кастомные настройки для очереди:
    * `db_cluster` — кластер для размещения коллекции-очереди
    для правила. По умолчанию идёт replication_queue_mdb_1.
    Для новых правил, если не предполагается использование специально
    выделенного кластера, указывать не нужно. У некоторых нейспейсов или групп правил есть свои выделенные очереди.
    * `shards_num` — число шардов в очереди (1 по умолчанию).
* `destinations` — про это ниже.

## Таргеты {#target}
* `destinations` — список таргетов для данных.
    * `mapper` — путь к yaml-описанию маппера (нужно указывать
    локальный путь из директории mappers, без постфикса .yaml). Маппер будет применён к данным до их отправления в источник.
    При добавлении нового источника **обязательно** добавлять в качестве таргета т.н. "сырой слой" (маппер **\$raw**).
    Подробнее о маппере **\$raw** [тут](generated-targets.md). Для получения таблиц в формате BSON необходимо использовать
    маппер **\$bson**. При использовании
    * [генерируемых таргетов](generated-targets.md) можно опционально
    указать поля, конфигурирующие генерацию мапперов и таргетов. **Важно:** писать yaml-конфигурации
    YT-приемника и маппера при использовании **\$bson** или **\$raw** не нужно, они сгенерируется автоматически.
    * `type` — **yt**, **logbroker**, **ext**.
    * `target` — информация о приёмниках:
        * Для **yt**:
            * `bson_settings` — настройки BSON-таблиц (при использовании маппера **\$bson**).
                * ...(кофигурация маппера согласно [этому](generated-targets.md) разделу)
            * `raw_settings` — настройки RAW-таблиц (при использовании маппера **\$raw**).
                * ...(кофигурация маппера согласно [этому](generated-targets.md) разделу)
            * `path` — путь к таблице в YT
            * `partial_update` — укажите `true`, если несколько таргетов пишут в одну и ту же таблицу в YT (каждую колонку пишет ровно один таргет).
                У каждого такого таргета должен быть указан одинаковый `path`
            * `cluster_groups` — список групп кластеров: можно указать
            **map_reduce**, **runtime**, либо обе.
            Есть возможность задать алиасы имен в такой форме:
            `group_name`: **map_reduce**, `destination_alias`: **alias**
            * `verification_settings` — настройки [сверки](verification.md):
                * `cron_schedule` (**required**) - частота запуска кроны сверки в формате строки из кронтаба (например, `'*/5 * * * *'`).
                * `period_to_check` (**required**) - timedelta для выбора начальной границы сверки (вычитается из настоящего времени),
                словарь из следующих возможных значений:
                    * `weeks`
                    * `days`
                    * `hours`
                    * `minutes`
                    * `seconds`
                * `client_name` (**required**) - название кластера YT, с которым будет проихводиться сверка из первоисточника.
                * `fields_to_check` - колонки на **YT**, которые нужно сверить с первоисточником. При отсутствии поля сверяются все колонки.
                **Внимание:** Если не выбрать колонки для сверки, туда могут попасть поля, создаваемые премапперами и завязанные на время,
                что сломает сверку, так что поля лучше выбирать. ** (!) ** Для сверки **raw** нужно выбрать поле doc.
            * `encoding` — нужно указать `false`, если в документе
            присутствуют сырые бинарные данные,
            в противном случае это поле не нужно заполнять.
            На данный момент возможность поддержана только для BSON таблиц.
            * `raw_rebuild_data` — нужно указать `true`,
            если это таблица с **RAW** данными, которые можно использовать
            для построения других таблиц этого правила, [подробнее](drafts.md#build_struct).
            * `is_index` — можно пометить `true`, чтобы уточнить
            что таблица является индексом.
        * **logbroker**:
            * `topic` — топик для загружаемых данных.
        * **external**:
            * `info` — дополнительная информация о таргете.
