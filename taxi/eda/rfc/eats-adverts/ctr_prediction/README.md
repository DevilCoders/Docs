# Улучшение CTR/CR рекламы в Еде

Сейчас рекламное ранжирование ресторанов (и баннеров) в Еде ничего не знает
про свойства ресторанов и про пользователей, которые с этими ресторанами взаимодействуют

Есть гипотеза, что можно улучшить качество рекламного ранжирования, если
провести два простых эксперимента:

- отфильтровывать из запроса в аукцион рестораны, которые не подходят
  пользователю по каким-либо критериям
- обогатить запрос в ранжирование аукциона знаниями о характиеристиках
  пользователя и ресторана (коэффициенты A,B,C в формуле value для аукциона)

## Фильтрация ресторанов, перед отправкой в аукцион

Гипотеза в следующем: в момент запроса мы можем отрезать из рекламы те
рестораны, которые не подходят пользователю.

С точки зрения данных и алгоритма это может выглядеть примерно так:

1. Получить данные о пользователе
2. Получить данные о каждом ресторане
3. Отфильтровать рестораны с помощью полученных данных и получить релевантность для каждого ресторана
4. Отправить отфилтрованные рестораны в БК экспериментруя с отправляемыми
   множителями и добавкой ресторанов если прошлый метод отфильтровал все

Из этого возникают следующие вопросы:

- где хранить данные о пользователе?
- где хранить данные о ресторанах?
- где (в каком сервисе) заниматься логикой фильтрации?

## Где хранить данные о пользователях?

Для проведения экспериментов пользователя можно представить как следующую
структуру:

```cpp
/// @struct Данные о пользователе для экспериментов по улучшению CR/CTR
/// рекламы Еды.
struct User {
	/// @property ID пользователя в Паспорте.
	int64_t passport_id;
	/// @property Вектор характерстик пользователя.
	std::vector<double> embeds;
};
```

У кого:danpolyakov будет настроен регулярный процесс, результатом которого
будет таблица на YT про пользователей Еды. Ожидается:

- ~5M строк с пользователями
- перестроение раз в сутки

## Гдe хранить эмбеды?

Эмбеды из таблицы можно разложить в следующие места:

### Подложить в отдельный ресурс в umlaas-eats

Дешевый способ с точки зрения разработки на стороне ML - добавить новый ресурс
про пользователей в сервис **umlaas-eats** и открыть к нему доступ по HTTP.
Таким образом, данные о пользователе может использовать umlass и все желающие
их использовать по http, но это +1 сетевой подход в сервис который не хочется
лишний раз ходить

### Заливать в существующий сегмент в BigB

нужно:
- написать скрипт который собирает таблицы на yt в шард для bigb(на питоне)
- окнуть у дежурного bigb
- выкатить скрипт
- передать скрипту отформатированные таблицы для загрузки в bigb

### eats-eaters and eats-eaters-meta?

eats-eaters содержит критичную минимальную инфу о пользователях и потому не
подходит 
eats-eaters-meta по логике подходит но возникает две проблемы
- он на питоне, нагрузку каталога может не выдержать (он и так медленный)
- у него нет бд 
eats-eater содержит инфу для авторизации и потому не критичные
  данные туда класть никто не хочет

### eats-recommender

В eats-recommender есть шарды в которых можно хранить данные о пользователях и
ресторанах однако он ограничен в размерах и может не вместить все данные
пользователя и рано или поздно придется ехать в BigB

### На чем предлагаю остановиться

Хотим BigB, потому что 
- быстро - 95 квантиль 10 ms 
- уже есть готовая библиотека для похода
- данные можно переиспользовать если появится желание использовать
ml/caesar в других местах еды

## Где хранить данные о ресторанах?

### YT + cache  

Первый вариант это хранения данных о ресторанах в таблице на YT + кеширования
Реализовать кеш можно в библиотеке eats-adverts-places
Однако будет дубликат кеша в разных сервисах

### Umlass resource

Ресурс в умлаасе 
Плюсы:
- Коллеги из ML умеют с этим работать
- Могут возвращать их и использовать у себя 
Минусы:
- Требует редеплоя сервиса чтобы экспериментировать с данными

### eats-catalog-storage

Сервис который хранит и отдает данные о ресторанах по логике и флоу
взаимодействия с другими сервисами наиболее подходящий источник хранения
эмбедов ресторана

есть eats-catalog-storage-cache который содержит актуальные данные о ресторане
в виде проекций (например place_id - embeds) с помощью кеша можно доставить
знания об эмбедах ресторанах в сервисах где эти эмбеды нужны

так как данные о ресторанах будут хранится в таблице на yt изменение
информации о эмбедах ресторана не равно обновлению ресторана в коре в ручке
place и изменение ревизии в таком случае приведет к большому количество обновлений

Выходом является написания кеша поверх YT в catalog-storage и отдача ответа с эмбедами 

### eats-recommender 

Аналогичное хранению данных о пользователе хранение данных о ресторане в шарде сервиса eats-recommender

## Где заниматься логикой фильтрации

Фильтрация ресторанов будет происходит следующим образом: 
свертка из параметров ресторана * параметры пользователя * коэффицент 

### umlass 
Возвращать рекламные рестораны в отдельной подборке - полностью
завязывает рекламу на умлаас от которого хотят отказаться

### Почему не eats-catalog-storage в ручке *places? 
потому что фильтрация
происходит только для рекламных заведений а в стораже нет никакой информации о
том рекламный ли ресторан (и не должно быть)
+ хочется включение экспериментом ранжирования максимально близко к рекламному коду, чтобы можно было выключить его в eats-full-text-search например

### eats-adverts-places 
библиотека реалиюзующая функционал рекламы ресторанов, один из вариантов
положить функционал фильтрации в нее, чтобы его можно было переиспользовать в
разных сервисах ожидаемый флоу:
1. Получить эмбеды ресторанов из eats-catalog-storage и данные пользователей
2. Считать свертку пользователи * рестораны * коэффициенты
3. По получившемся значению отфильтровывать рестораны с некоторым порогом
4. Получившиеся значения также можно отправлять в БК под экспом

### eats-recommender
Сервис использующий библиотеку dj, позволяет проводить умную фильтрацию и
ранжирование ресторанов по данным из шарда в сервисе 
Также возможно достать скор catboost из него для отправки в БК 
Данные о пользователях можно доставать из BigB если они не поместятся в шард в eats-recommender 
можно отправлять эксперименты и экспериментировать с признаками по которым
проихводятся фильтрация и ранжирование

## Останавливаемся на

Будем хранить данные о пользователях в BigB потому что их много и рано или
поздно все равно придется переехать туда Эмбеды ресторанов будет хранить шард
eats-recommender Общий алгоритм будет таким:
1. Из каталога/поиска отправляем в eats-recommender рекламные рестораны, поход
   за ресторанами закроем конфигом на стороне каталога, в этом же конфиге
   зададим эксперименты которые будут использоваться для задания используемых
   признаков 
2. eats-recommender отфильтровывает и ранжирует рестораны беря данные
   пользователя из bigb(хорошая скорость ответа) и данные ресторанов из своего
   шарда
3. В каталоге получаем отфильтрованные рестораны и скор кэтбуста из
   eats-recommmender, с скорами проводим эксперименты: домножение на множитель
   и другие. Так как eats-recommender все равно пришлет скоры ресторанов даже
   если отфильтровал все можно сделать эксперименты с отправкой БК топа
   ресторанов и другие внутри каталога/поиска 
4. Отправляем отфильтрованные рестораны в БК c коэффициентом B полученному из
   eats-recommender

В каталоге есть кеши сохраняющие из yt коэффициенты релевантности расчитанные
по формулам, от них можно будет отказаться в пользу скора eats-recommender

Общая схема:

![Client scheme](./scheme.png)

## P.S.

Сейчас средний rps в eats-recommender около 3 рпс, в свою очередь у
eats-catalog около 270 рпс в пике + нагрузка eats-full-text-search
Таким образом неизвестно хватит ли ресурсов сервису чтобы выдержать нагрузку
каталога и поиска,  поэтому по сервису будут произведены стрельбы
после них будем решать добавить ли ему еще ресурсов

Также обнаружилось что у сервиса есть даунтаймы при выкатке шарда на котором находятся данные пользователя
Будет необходим дополнительный ресерч по поводу того как избежать даунтаймов -
пока они сохранятся нужен фоллбек, например на старую логику

