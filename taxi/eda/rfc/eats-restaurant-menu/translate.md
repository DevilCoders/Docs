# Цель

Обеспечить близкий к рантайм перевод UGC текстов на все поддерживаемые в стране языки.

# Требования

- В одной стране может быть больше одного языка (Армения - русский и армянский)
- Сейчас UGC нужно добавить только в один сервис. Заложить переиспользование и в других (к примеру LC, каталог)
- Система фолбэков для переводов. Все тексты хранятся в базовых таблицах в выбранном для страны языке. Если передан "родной" язык, то отдаем из локального хранилища. Если передан другой язык, смотрим наличие и возвращаем перевод, иначе на "родном" языке

# Аналитика

### Скорость обновления текстов

За ориентир можно взять 5 rps (~400к в сутки)

Посчитано на основе [логов](https://kibana.taxi.yandex-team.ru/goto/d1e60d51af7546bb644bec835fd408b8) обновления сервиса ERMS.

За счет кэша будет на порядки меньше.

### Ручка меню

~25 rps в пике

![картинка](https://jing.yandex-team.ru/files/ryurasov/Screenshot%20from%202022-07-20%2010-41-33.png)

[график](https://grafana.yandex-team.ru/d/2wE7wJyMk/nanny_eda_eats-api-proxy_stable?orgId=1&from=now-24h&to=now&viewPanel=291)

Для перевода контента экрана меню можно ориентироваться на 200-2000 ключей

### Объем текстов

Суммарно вышло для категорий, блюд, групп опций и опций на перевод
- Кол-во элементов: 3,562,452
- Кол-вл символов: 576,647,656

Детальнее

1. Категории
```
select count(1), sum(c), sum(s) from (
select name, char_length(name) c, length(name) s
from place_menu_categories
group by name
) tmp ;

уникальных,символов,байт
33295,570249,1038555
```

2. Блюда
```
USE hahn;

$start = '2015-01-01';
$end = '2022-01-01';

$items = SELECT i.name, i.description, LENGTH(i.name || IF(i.description IS NULL, "", i.description)) AS len
FROM RANGE('//home/eda-dwh/ods/bigfood/place_menu_item', $start, $end) AS i
INNER JOIN `//home/eda-dwh/ods/bigfood/place/place` AS p ON i.place_id = p.id
WHERE p.enabled = 1
GROUP BY i.name, i.description ;

SELECT COUNT(*) AS cnt, SUM(len) AS len
FROM $items ;

уникальных,байт
3207760,1137107653
```

3. Группы опций
```
select count(1), sum(c), sum(s) from (
select name, char_length(name) c, length(name) s
from place_menu_option_groups
group by name
) tmp ;

уникальных,символов,байт
35345,680071,1246301
```

4. Опции
```
select count(1), sum(c), sum(s) from (
select name, char_length(name) c, length(name) s
from place_menu_options
group by name
) tmp ;

уникальных,символов,байт
286052,6843510,11884532
```

# Решение

## Рассмотренные варианты

1. Доработать [сервис локализаций](https://wiki.yandex-team.ru/taxi/backend/architecture/communications/localizations/)
   
   Плюсы
   - уже написан
   - легкая интеграция

   Минусы
   - перевод приложения и контент все же разные вещи
   - не совсем очевидная зависимость от tanker и фолбека нет
   - полный кэш в памяти

> Vladimir Belikov

> Хороший вопрос, думаю, стоит сначала спросить даже не у нас, а у танкера готовы ли они это переварить.

> Сервис локализация от такого объема тоже поломается, надо его переделывать. Он не умеет хранить кейсеты больше 35-50 Мб (примерно).
Также кеш локализаций сломается т.к. он хранит весь кейсет в памяти

2. Новый сервис переводов для UGC
   
   Плюсы
   - вся логика переводов в одном месте
   - единое место с квотами и доступами в API переводов

   Минусы
   - писать много кода
   - гора http запросов в сервис
   - либа для сервисов-потребителей
   - единая точка отказа

3. Подключаемая библиотека

   Плюсы
   - вся логика переводов в либе, а их использование и хранение результатов в сервисе
   - нет единой точки отказа

   Минусы
   - писать меньше кода
   - использовать локальные ресурсы и квоты (но это и плюс)

4. Танкер и автопереводы

[Документация](https://wiki.yandex-team.ru/l10n/tanker/)

Минусы
- еще один хоп в системе
- еще одна точка отказа (нет гарантий стабильности). Есть вариант решения с хранением данных в бункере или локально в сервисе

Плюсы
- внешнее хранилище
- есть возможность настроить [автопереводы](https://wiki.yandex-team.ru/l10n/tools/translate-autoticket-v2/), но в наших объемах выглядит нерационально. 

Комментарии
> Danil Demintsev
А хранение UGC в танкере подразумевает его использование в качестве runtime сервиса?
Если да, то мы бы настоятельно не рекомендовали так делать

> Тут вопрос не только и не столько rps, как мне кажется - держать запросы на чтение мы умеем достаточно прилично

> Вопрос скорее в стабильности сервиса - мы не даём достаточных гарантий для того, чтобы вытаскивать тексты из танкера “в онлайне“, поэтому я бы не стал так рисковать

> Если не пытаться выкачивать всё и сразу, то должно быть норм - в постгрес оно, кажется, влезает

---

> Aleksei Lapenok
при этом бункер умеет в нас ходить не часто и кешировать ключи, поэтому если нужна гарантия для онлайн, то бункер тут поможет

> мы скорее заточены под хранение небольших текстов и их переводов
кажется директ хранит даже больше элементов и символов, поэтому к таким порядкам готовы

## Предлагаемое решение

3 вариант - библиотека локализации

В библиотеке реализуется:
- работа с API Яндекс.Переводчика
- хранение в локальной постгре/монге переводов
- событие на перевод и обраточик в STQ
- фоновые задачи

В коде сервиса:
- инициализация перевода
- перегрузка переводами данных в зависимости от переданной локали

Логика постановки задачи на перевод

- Изменились данные, которые требуют перевод
- Включен ли перевод и есть ли языковые пары к переводу
- Берем hash от строки и проверяем, есть ли уже перевод
  - Есть перевод
    - Ничего не делаем
  - Перевода нет
    - Ставим задачу в STQ
    - В обработчике идем в API переводчика
    - Записываем результат

### Таблицы

`some_table` // какая-то таблица, в которой нужно перевести два текстовых поля name и description
- id
- name // то самое первое поле
- description // и самое второе поле

`some_table_translations` - таблица связей между исходной таблицы и поля в ней с таблицами переводов
- id
- some_table_id // ключ в исходной таблице
- field // поле в таблице
- source_id // внешний ключ на таблицу переводов

Таблицы переводов необходимые для работы библиотеки переводов:

`source`: // оригинальный текст, необходимый перевеси
- id (string sha1(text)) // хэш от исходного текста
- text // оригинальный текст
- lang // язык оригинального текста, к примеру ru, en, hy
- status enum(new, translated) // статус обработки
- created_at
- updated_at

`translated_texts`: // переводы
- id
- source_id // внешний ключ на оригинальный текст
- translate // перевод текста
- lang // язык в который переведен текст
- mode enum(auto, manual) // ручной перевод или через переводчик
- need_refresh_at // когда надо обновить перевод
- created_at
- updated_at

Получение переводов сводится к запросу вида:
```
SELECT
   stt.some_table_id AS id
   stt.key,
   tt.translate
FROM some_table_translations stt
   INNER JOIN translated_texts tt ON stt.source_id = tt.source_id
WHERE stt.some_table_id IN (1, 2, 3)
   AND stt.key IN ("name", "description")
   AND tt.lang = "EN" ;
```

Дополнительно сделать LRU кэш на популярные переводы (к примеру переводы категорий меню будет занимать мало места в памяти и иметь почти 100% hit rate)

### Конфиги

Проверяем включен ли перевод и в какие языковые пары необходмо переводить:
```
{
  "enabled": true,
  "lang_pairs_enabled": {
    "ru": {
      "en": true,
      "hy": true
    },
    "hy": {
      "ru": true,
    }
  }
}
```

### STQ на перевод

При событии появление или изменения новых данных ставим задачу на перевод

### Фоновые задачи

1. Проверяем переводы, которые нужно освежить и ставим задачи на перевод
2. Чистка ненужных переводов (удаленные исходные данные, которые переводились)

### Поиск

В SaaS есть [префиксные индексы](https://wiki.yandex-team.ru/jandekspoisk/SaaS/Architecture/#funkcionalnyevozmozhnostisistemy). Т.к. ценности в поиске одновременно по нескольким языкам нет, предлагаю использовать полное разделение в рамках одного индекс по префиксу

### Интеграция с Яндекс.Переводчиком

Требует API ключ
Прописать в потребителей: https://wiki.yandex-team.ru/translate/api/clients-yandex/

### Метрики

- Продуктовые
  - Сколько переведено текстов в разрезе языков
  - Отставание переводов
- Технические
  - Размер очереди
  - Hit-rate попадание в кэш при получении переводов
  - Hit-rate попадание в кэш при изменении переводов

### Точки отказа

- stq
- яндекс.переводчик

# Вопросы
- Что делать, если перевод будет содержать ругательные слова, экстримистские высказывания и др дичь. Как решение - добавить постфильтрацию.
