# хранение оффсетов тайлов

Формата хранения оффсетов тайлов два (и еще один deprecated), у каждого есть свои преимущества и недостатки для хранения разных датасетов.
Для большинства датасетов подойдет sparse формат. Для датасетов типа архива подложки есть упрощенный формат plain.


## хранение "как есть" (plain_index.h)

Для больших датасетов типа подложки информация о расположении дедуплицированных тайлов в файле может иметь достаточно большой размер,
который не получится загрузить с холодного старта полностью и быстро.
Поэтому хочется уметь хранить информацию о расположении тайлов в формате, позволяющем отдать тайл с холодного старта за минимальное время.  

В данном формате мы храним эту информацию линейно.  
На каждом зуме `z` у нас `4^z` тайлов,
для каждого зума (по порядку) мы упорядочиваем тайлы на этом зуме по кривой Гильберта
и сохраняем для каждого тайла 8 байт: 40 бит оффсет в файле и 24 бит размер тайла.  
Сначала 4^0 позиций для 0 зума, потом 4^1 позиций для 1 зума, 4^2 позиций для 2 зума и т.д.

В итоге для определения позиции тайла в файле нам нужо прочитать 8 байт по заранее известному оффсету в файле.  
Недостаток такого подхода - нужно хранить оффсеты для ВСЕХ тайлов, для 15 зума это 8*4^15=8GB данных.  
Для маленьких датасетов это сильно больше самих данных в тайлах.


## (deprecated) компактное хранение (compact_index.h)

Заметим что достаточно большая часть тайлов в датасетах - либо пустая (земля), либо залита одним цветом (вода, зеленка).  
Заметим что если такой тайл - пустой на некотором масштабе, то он скорее всего будет пустой и на больших масштабах.  
Также такие тайлы имеют одинаковое представление, поэтому мы можем попробовать заиспользовать какого-либо рода дедупликацию.

Представим весь набор тайлов в виде дерева по зумам:
- корень - тайл `[z,x,y]` = `[0,0,0]`
- сыновья каждой вершины - все тайлы следующего зума, находящиеся внутри родительского тайла  
Например, у `[1, 0b1, 0b0]` будут сыновья `[2, 0b10, 0b00]; [2, 0b10, 0b01]; [2, 0b11, 0b00]; [2, 0b11, 0b01]`.

<img src="https://jing.yandex-team.ru/files/eak1mov/tile_locations_p1.JPG" height="500" alt="представление тайлов в виде дерева"/>

Рассмотрим сначала простую дедупликацию тайлов - если два тайла на некотором зуме совпадают,
то для одного из них будем хранить содержимое тайла,
а для другого - только номер первого тайла, т.е. второй тайл будет ссылаться на первый.

Аналогично можно дедуплицировать и поддеревья тайлов.
Если два тайла на некотором зуме совпадают, а также совпадают все тайлы-сыновья на больших зумах,
то можно для одного поддерева тайлов хранить полное содержимое поддерева,
а для другого - только номер тайла корня первого поддерева.

<img src="https://jing.yandex-team.ru/files/eak1mov/tile_locations_p2.JPG" height="500" alt="случай пустого датасета"/>

При такой дедупликации мы можем хранить два набора тайлов:
- тайлы-источники с уникальными данными для конкретного зума, для них храним идентификатор `[x,y]` тайла и сам тайл (оффсет с расположением данных этого тайла в файле),
- тайлы-дубликаты со ссылками на другие тайлы этого же зума, для них храним идентификатор `[srcX,srcY]` тайла-дубликата и идентификатор `[dstX,dstY]` тайла-источника.

Из этого набора тайлов мы можем восстановить исходное дерево тайлов,
причем делать это как offline (с полным восстановлением дерева за `O(количество тайлов)` времени и памяти и дальнейшим получением оффсетов тайлов за `O(1)`),
так и online (с хранением только этого набора тайлов и дальнейшим получением оффсетов тайлов за `O(log^2 количества зумов)`).


### offline восстановление

При таком способе хранения у нас получаются тайлы трех типов:
- None - тайлы-пустышки, отсутствующие в сохраненных тайлах (они находились внутри скопированного поддерева тайлов)
- Uniq - тайлы-источники
- Link - тайлы-дубликаты

Начнем восстановление с вершины дерева (нулевой зум). Такой тайл только один и он не может быть дубликатом.  
Дальше будем восстанавливать уровнями, на каждом уровне восстановим все тайлы следующего зума.  
Сначала восстановим все тайлы-источники (мы сохранили полную информацию о них). Дальше пройдемся по всем тайлам.  

Если мы встречаем тайл-дубликат, то восстановим его данные из тайла-источника, индентификатор которого мы сохранили вместе с идентификатором тайла-дубликата.  

Если мы встречаем тайл-пустышку отсутствующий в сохраненных данных, то в оригинальном дереве он находился внутри скопированного поддерева тайлов.
Для его восстановления сначала найдем тайл-родитель, поддерево которого мы копировали (поднимаемся вверх по дереву пока не найдем тайл помеченный как тайл-дубликат).
Дальше вычислим позицию нашего тайла-пустышки в поддереве тайла-родителя (это младшие биты координат xy, старшие биты у тайла-родителя и тайла-пустышки совпадают).
Дальше используя вычисленную позицию тайла, но уже в поддереве тайла-источника (взяв старшие биты из координат тайла-источника и младшие биты из координат тайла-пустышки) получим идентификатор тайла, который нам нужно скопировать на место тайла-пустышки.
И наконец восстановим тайл-пустышку из полученного идентификатора тайла.  
В качестве оптимизации можно пометить тайл-пустышку как тайл-дубликат, сохранив ссылку на тайл-источник. Это позволит в дальнейшем ходить только на один уровень вверх для поиска тайла-дубликата.

Замечание: порядок обхода тайлов важен и должен быть тем же, как и при создании дедуплицированных данных.  
После завершения обхода всех тайлов на текущем зуме можно переходить на следующий.  
Алгоритм работает за `O(количество тайлов)` времени и памяти.


### online восстановление

При online восстановлении мы хотим оставить низкое потребление памяти, свойственное дедуплицированному хранению тайлов,
но получить возможность делать запросы к произвольному тайлу за разумное время (не за `O(1)`, но что-то близкое к такому).

Будем хранить в памяти исходный набор дедуплицированных тайлов, но с быстрым доступом к этим тайлом по их идентификатору (хэш-мапа xy -> тайл).

Алгоритм восстановления похож на offline восстановление,
только нужно будет делать несколько дополнительных шагов из-за того что мы не можем использовать дополнительную память.

Точно так же будем рассматривать тайлы трех типов.  
Если тайл из запроса является тайлом-источником, то вернем его сохраненное содержимое.  
Если тайл из запроса является тайлом-дубликатом, то аналогично восстановим его данные из тайла-источника.  
Если тайл из запроса является тайлом-пустышкой, то алгоритм немного усложняется.
Мы точно так же найдем тайл-родитель, поддерево которого мы копировали.
Далее точно так же вычислим позицию нашего тайла-пустышки в поддереве тайла-родителя.
Далее точно так же получим идентификатор тайла (назовем его тайлом-целью) в поддереве тайла-источника, который нам нужно скопировать на место тайла-пустышки.
Но теперь тайл-цель уже не обязательно присутствует в наших данных т.к. мы в отличие от offline процедуры могли его еще не успеть восстановить. Он точно так же мог быть скопирован, но, что важно, из поддерева меньшей высоты.
Поэтому далее мы рекурсивно сделаем запрос с новым идентификатором тайла-цели.

За счет того что возможная высота поддерев тайла-родителя постоянно уменьшается наш алгоритм когда-нибудь дойдет до тайла-источника или тайла-дубликата и завершится.

Худший случай для online алгоритма - пустой входной датасет и запрос с максимальными xy координатами на максимальном зуме.
В таком случае на каждом шаге рекурсии нужно будет пройти на максимально возможную для этого шага высоту вверх.
Сначала с 15 до 1 зума вверх, потом с 15 до 2 зума вверх, потом с 15 до 3 зума вверх и т.д.  
Алгоритм работает за `O(log^2 количества зумов)` времени. Скорее всего пожертвовав небольшим количеством памяти можно придумать алгоритм за `O(log количества зумов)`, но это усложнит алгоритм, а время работы в данном случае не настолько принципиально.


### алгоритм дедупликации

Для данного подхода к дедупликации основным является вопрос определения поддерева, на которое мы будем ссылаться при обозначении поддерева дубликатом.  
Для упрощения алгоритма можно всегда выбирать только эквивалентные поддеревья этого же зума.  

Для быстрого определения эквивалентности поддеревьев можно использовать алгоритмы вычисления классов эквивалентности,
наподобие применяемого в алгоритме построения суффиксного массива.

Будем действовать от больших зумов к меньшим (от листьев дерева к корню).  
Для листьев классы эквивалентности очевидны (тайлы равны -> листья в одном классе эквивалентности).  
Пусть мы рассчитали классы эквивалентности для зума z+1, посчитаем их для зума z.  
Поддеревья с корнем в двух тайлах эквивалентны если равны тайлы их корней и равны классы эквивалентности их прямых детей (классы эквивалентности которых мы уже вычислили).  
Вычислить эти классы эквивалентности можно пройдясь по всем тайлам, сохраняя набор предыдущих классов эквивалентности в хэш-мапе.
Другой способ вычисления - отсортировав набор тайлов на зуме по классам эквивалентности тайла+детей,
а потом пройдясь по тайлам со счетчиком (номером класса эквивалентности) и
увеличивать счетчик в случае неравенства классов эквивалентности соседних тайлов+детей.

Следующим этапом после вычисления классов эквивалентности будет выставление типа тайлов (источники, дубликаты) и их сохранение.  
На этот раз будем действовать от меньших зумов к большим.  
Пройдемся по всем тайлам. Сначала посмотрим на тип тайла-родителя.  
Если он был тайлом-дубликатом, то все его поддерево было скопировано,
а значит и текущий тайл был скопирован и нам не нужно сохранять информацию об этом тайле-пустышке.  
Иначе нам нужно сохранить информацию о тайле. Посмотрим на класс эквивалентности тайла,
сохраним его как тайл-источник если это первый экземпляр этого класса эквивалентности,
а если нет - то сохраним его как тайл-дубликат.

Данный подход с ссылкой на эквивалентные поддеревья не всегда оптимальный.
Можно придумать алгоритм посложнее, в котором мы будем иногда ссылаться на похожее но не эквивалентное поддерево, отличающееся небольшим количеством тайлов,
при этом добавив все отличия в список тайлов-источников.
Это может значительно уменьшить размер дедуплицированного набор тайлов, но алгоритм восстановления останется тем же.


### примерные результаты

датасет mapsearch.tar: 3331661 дедуплицированных поддеревьев, *12байт = 38MB  
датасет dump.tar: 160809197 дедуплицированных поддеревьев *12байт = 1840MB = 1.8GB


## блочное плоское хранение (plain_index.h) и блочное разреженное хранение (sparse_index.h)

Заметим что тайлы часто запрашиваются локально по координатам x, y и зуму z - батчами по 9-25 соседних тайлов, часто с изменением зума на соседние.

Хранение оффсетов в плоском формате ("как есть") не очень оптимально для кэширования индекса.
Обращаться к файлу за каждым тайлом (чтобы получить 8 байт) очень накладно и такого рода кэш прогревается очень меленно.
А запрашивать файл блоками не сильно увеличивает хитрейт ввиду того, что оффсеты для каждого зума хранятся независимо (не локально по z).

Хранение оффсетов в компактном формате требует полной загрузки индекса и хранения его в памяти, что сильно замедляет время холодного старта
(размер индекса для больших датасетов может достигать пары гигабайт).

Обе эти проблемы можно решить храня индекс независимыми блоками, содержащими некоторую локальную часть индекса.

Представим весь набор тайлов в виде дерева по зумам (аналогично компактному хранению).  
Разобьем дерево тайлов на два уровня, в первом уровне будут все тайлы первой половины зумов, на втором уровне будут все тайлы второй половины зумов.  
Например, для зумов `[0, ..., 15]` первый уровень будет содержать все тайлы на зумах `[0, ..., 7]`,
а второй уровень - все тайлы на зумах `[8, ..., 15]`.
Первый уровень будет представлять собой одно поддерево с корнем в z=0 и высотой 8.
Второй уровень будет представлять собой 4^8 поддеревьев с корнями в z=8 и высотой 8.

Каждое такое поддерево содержит локальную часть индекса - все тайлы поддерева находятся в некоторой ограниченной области карты на некотором последовательном подмножестве зумов.  
Каждое поддерево второго уровня можно генерировать и хранить независимо от других.
При запросе тайла из какого-либо поддерева можно скачивать все поддерево и сохранять его в кэш в расчете на локальность запросов.

Сохраним такие поддеревья в файл отдельными блоками, для блочного плоского хранения запишем каждый блок в плоском формате, для блочного разреженного хранения запишем либо в компактном формате, либо в плоском формате - в зависимости от того какой из них займет меньше места.

За счет того что плоский формат имеет фиксированный размер блока, блоки можно найти по заранее известному оффсету в файле.  
Для разреженного формата блок первого уровня нужно будет дополнить оффсетами на блоки второго уровня, которые можно дедуплицировать аналогично тому как это делается для оффсетов тайлов.
