# SEO

Для качественного индексирования сервиса поисковыми системами были созданы специальные "посадочные" страницы, на которых добавлены специальные мета-данные и соответствующий контент.

Для корректного отображения сниппетов в поисковой выдаче, на каждой странице генеруются специальные мета теги title и description.

На каждой странице указывается специальный мета тег, в котором указана [каноническая ссылка](http://h.yandex-team.ru/?https%3A%2F%2Fsupport.google.com%2Fwebmasters%2Fanswer%2F139066%3Fhl%3Dru) на страницу.

Для мультиязычных доменов указываются [мета теги](http://h.yandex-team.ru/?https%3A%2F%2Fsupport.google.com%2Fwebmasters%2Fanswer%2F189077%3Fhl%3Dru), содержащие ссылки на страницы на других языках. Данные страницы формируются путем добавления параметра `lang` к урлу. Ссылки с `lang` на страницы с альтернативными языками являются каноническими для таких страниц.

Ссылка на страницу с языком по умолчанию для домена не имеет параметра `lang`.

## Лендинги

Поддерживаемые лендинги находятся в модуле `server/seourl/landing.ts`.

Для лендигов городов seoname генерируется по следующему принципу: название города берется из геобазы на английском (поле ename) с заменой всех пробелов на тире.

## Разработчику

От чего зависит ранжирование в поисковых системах, точно никто не знает. Ходят слухи, если контент страницы подменять специально для робота, это негативно влияет на ранжирование. Мы почти всегда для ботов и людей отдаём контент одинаковый.

Иногда мы можем отдавать поисковому роботу контента больше, чем видят пользователи. Например, в карточке линии маршрута общественного транспорта мы показываем пользователям _только одну_ нитку маршрута, а остальные прячем за кликом в выпадашку. Роботу же хорошо показывать _сразу все_ нитки, чтобы он более качественно проиндексировал контент, и потом предлагал пользователям пройти на нашу карточку маршрута, чтобы посмотреть и одну нитку, и другую, и третью.

Сео-специалисты говорят, так поступать можно, при условии, что контент для робота от контента для пользователей будет отличаться "немножко", на условные 10%. В таких случах сео-специалист заводит таску, а разработчик вносит изменения бережно, аккуратно и с опаской.

Для этого в коде используем доступен флаг `config.uatraits.isRobot`, который взводится для запросов, пришедших от поисковых роботов.

```jsx
// было
{
    this._renderBlock();
}

// стало
{
    config.uatraits.isRobot ? this._renderSeoBlock() : this._renderBlock();
}
```

В `_renderSeoBlock` показываем контент в более полном виде. Какой этот вид — спрашиваем у `seo`-специалиста.

Чтобы увидеть наше приложение глазами робота, в урл добавляем параметр `debug=robot`.
