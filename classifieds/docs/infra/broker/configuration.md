# Конфигурация поставки

## Общее

Для конфигурации поставки используются protobuf-аннотации. Актуальную схему аннотации можно найти [здесь](https://a.yandex-team.ru/arcadia/classifieds/schema-registry/proto/broker/broker_options.proto)

* **name** - обязательное поле. Является логическим названием стрима. Рекомендуемое наименование service/name.
Должно быть в kebab-case (`subscriptions/notification-event`)

* **services** - список сервисов из [карты сервисов](https://a.yandex-team.ru/arc_vcs/classifieds/services), пишущих в эту поставку. Обязателен для новых поставок, старым тоже надо заполнить.

* **testing_only** - на случай, если поставка экспериментальная и будет еще какое-то время сильно меняться и обкатываться в тестинге. В этом случае в проде она не будет создана.

* **max_lag** - определяет насколько старое или, наоборот, будущее событие можно прислать, чтобы api его приняло. При превышении будет ошибка _MESSAGE_TOO_OLD_ / _MESSAGE_TOO_FAR_INTO_FUTURE соответственно.
Измеряется в единицах партиционирования (параметр _partition_).
То есть в случае _BY_DAY_ - будет измеряться в днях, _BY_MONTH_ - месяцах и тд.
По умолчанию - 7, максимально - 30. Если нужно больше, приходите [поговорить](https://t.me/joinchat/Rf9HXgmSuEGxW6YB)

* **substreams** - позволяет настроить разбиение исходного стрима на несколько сабстримов по некоторым условиям. Сейчас поддерживается только простейший фильтр на равенство по строковому полю или строковому значению enum. Из имени сабстрима и имени исходного стрима будет сформировано логическое название сабстрима: например, для стрима **telepony/event** и сабстрима **auto** результатом будет **telepony/event/auto**. Для каждого из сабстримов можно настроить поставку в любой из существующих приёмников по аналогии с основным стримом.

    Пример настройки сабстрима событий в категории CARS с записью в кликхаус:
    ```
    option (broker.config) = {
        name: "cannon/events"
        ...
        substreams: [
            {
                name: "cars"
                filter: {
                    field_name: "card_category"
                    field_value: "CARS"
                }
                clickhouse: [{
                    cluster: "autoru"
                    db: "broker_load_test"
                    table: "cannonball_cars"
                    expire_in_days: 1
                }]
            }
        ]
    }
    ```

Остальная конфигурация относится к конкретным приемникам.

{% note warning %}

Важно понимать, что все настройки поставок берутся из последней версии схемы, а не из той, с которой был послано сообщение.

{% endnote %}

## Типы приемников

## YT

Все данные, которые пишутся в брокер, попадают на YT. В данный момент поставка осуществляется только в кластер Hahn. Отключить поставку в YT нельзя.

### Доступные настройки

За поставку в YT отвечает секция YtConfig

```
yt: {
    sort_by = ["domain", "id"]
    expire_in_days = 30
    partition = BY_DAY|BY_MONTH|BY_YEAR
    repartition = ...
    spawn = ...
    archive = ...
    holocron = false
}
```

* **sort_by** - поля, по которым нужно сортировать данные в yt. Поддерживаются только [примитивные типы](schema_guide.md#правила-конвертации-protobuf-полей-в-типы-YT) верхнего уровня. Таблицы сортируются не сразу, самые свежие могут быть не отсортированы.

* **spawn** - настройки [срезов](#spawn)

* **partition** - настройка партиционирования. По-умолчанию данные партиционируются по дню.
Если вы пишете не очень много, то можно партиционировать по месяцу или даже году.
Это позволит нам сэкономить ресурсы ытя, а вам - ускорить запросы по большим периодам.
Слияние чанков и сортировка будут происходить в периоды, когда вы не пишете (например, ночью).
Разбивка на партиции производится по московскому времени.

* **repartition** - настройки [перепартиционирования](#repartitioning)

* **expire_in_days** - настройка экспирации таблиц в днях с момента создания. Должна быть >= `max_lag`. Задается только для прода, в тестинге для всех поставок будет использовано `min(expires_in_days, default_testing_ttl)`, где `default_testing_ttl` равно 30 дням.

* **holocron** - поставка для [холокрона](./holocron.md)

* **archive** - настройка [архивации](#archivation) таблиц

* **retro_evolution** - обновлять прото-схемы старых партиций. Может быть опасно если вы несовместимо меняли схему. По-умолчанию выключено. Обновления асинхронны.


### Раскладка данных

Все поля верхнего уровня конвертируются в типизированные колонки по следующим правилам:

 1) Примитивные поля (все целочисленные типы, double, float, bool, string)

    - конвертируются в соответствующий [примитивный тип](https://yt.yandex-team.ru/docs/description/storage/data_types.html#schema_primitive) YT
    - всегда имеют значение (возможно, дефолтное)
 2) Классы-обертки над примитивными типами (google.protobuf.DoubleValue и т.д.)

    - разворачиваются в соответствующий примитивный тип YT
    - при отсутствии значения будет записан null
 3) Cообщения

    - записываются как поля типа string, содержащие исходное сообщение в бинарном виде. Дескриптор сообщения будет передан в метаданных колонки
    - YQL прочитает такое поле как структуру
    - при отсутствии значения будет записан null.
 4) Списки (repeated-поля)

    - для списков будет сгенерировано protobuf-сообщение с единственным полем "values", содержащим исходный список. Далее будет записано в YT по тем же правилам, что и пользовательские protobuf-сообщения
    - всегда имеют значение, по дефолту - пустое ("values": [])
 5) Maps

    - так же, как и для repeated-полей, будет сгенерировано protobuf-сообщение с единственным полем "map_field", содержащим исходное значение
    - всегда имеют значение, по дефолту - пустое ("map_field": [])
 6) Enums

    - записываются как строковое значение из enum
 7) Timestamps

    - будет записан примитивный тип timestamp
    - при отсутствии (дефолтном значении) будет записано null
    - верно только для полей верхнего уровня: таймстампы, вложенные в protobuf-поля, будут отображаться по правилам YQL
 8) Oneof

    - будет записано в виде набора колонок – по одной для каждого из вариантов oneof-поля
    - незаданные примитивные поля, repeated и map поля будут заполнены дефолтными значениями
    - незаданные поля остальных типов будут записаны как null

### Где искать данные {#yt-data}

Базовые директории:
 - [тестинг](https://yt.yandex-team.ru/hahn/navigation?path=//home/verticals/broker/test/warehouse)
 - [прод](https://yt.yandex-team.ru/hahn/navigation?path=//home/verticals/broker/prod/warehouse)

Данные конкретной поставки будут лежать по пути из конфигурации относительно базовых директорий.

{% note warning %}

- менять имя сообщения нельзя (!). Вся поставка сейчас привязана к типу. Если нужно - приходите к нам
- таблица содержит все колонки, которые были в сообщениях, которые в нее попали. То есть удаление поля не приводит к удалению колонки.

{% endnote %}

### Перепартиционирование {#repartitioning}

Брокер не принимает события из далекого прошлого (по-дефолту старше 7 дней).
Но так как отправлять старые данные - довольно популярный случай, брокер предоставляет возможно переложить данные по другому полю.
То есть перепартиционировать по таймстампу из другого поля. Это позволяет потребителю отправлять события по текущему таймстампу.
А потом перепартиционировать их по реальному таймстампу события.

Процесс перепартиционирования не является реалтаймовым и сейчас происходит раз в час.

Для настройки нужно добавить секцию **repartition**:

```
 repartition: {
     timestamp_field: "event_timestamp"
     name: "holocron/auto/cars/events"
     expire_in_days: 60
 }
```

**timestamp_field** - поле с таймстампом, по которому будет происходить перепартиционирование. Должно быть задано, и, очевидно, отличаться от основного поля с таймстампом.

**name** - логическое название, куда нужно положить результат. **Должно быть уникальным!**.
Если будет неуникальным, то ваши данные отправятся в трубу.
Фактически является директорией в yt, куда мы переложим оригинальные данные (относительно корня broker/warehouse).
Т.е. партиционированные по основному таймстампу данные будут как обычно отправляться в директорию поставки, и оттуда асинхронно, не RT, раскладываться в директорию, заданную в repartition.name.

**sort_by** - поля, по которым нужно сортировать перепартиционированные данные в yt. Поддерживаются только [примитивные типы](schema_guide.md#правила-конвертации-protobuf-полей-в-типы-YT) верхнего уровня. Таблицы сортируются не сразу, самые свежие могут быть не отсортированы.

**expire_in_days** - настройка экспирации перепартиционированных таблиц в днях с момента создания.
Так же, как и expire_in_days в основном конфиге поставки, задается только для прода, в тестинге для всех поставок будет использовано min(expires_in_days, default_testing_ttl), где default_testing_ttl равно 30 дням.

{% note warning %}

repartition.expire_in_days это экспирация перепартиционированных таблиц, настройка для raw-таблиц осуществляется в основном конфиге

{% endnote %}

### Срезы часовых/5-минутных табличек {#spawn}

{% note warning %}

Срезы работает только с дневным партиционированием основной таблицы

{% endnote %}

Брокер может регулярно отщиплять из последних дней неизменяемые таблички в отдельную папку. Они нужны для того, чтобы yql мог кэшировать запросы по недавним данным. Можно настроить количество дней (не больше 3х), и период в минутах (не чаще, чем 5 минут). Мы не гарантируем что данные в табличках соответствуют какому-то отрезку времени, частота среза это примерная частота запуска таски по созданию новой таблички.

Иммутабельные таблички будут протухать через несколько дней (иначе они займут слишком много нод). Если вам нужны только они и не нужны дневные, имеет смысл выставить основной табличке экспирацию, см. **expire_in_days**. Пример:
```
spawn: {
    days_to_watch: 1
    cut_period_minutes: 5
}
```
События создания таблички-среза публикуются в [реактор](#publishing).

### Архивация {#archivation}

Мы архивируем дневные таблицы при выходе за границы периода для экономии нод, исходя из того, что старые данные уже особо никому не нужны, кроме редких ручных расчетов аналитиков.
По умолчанию для всех поставок, партиционированных по дню, выставлен период в 365 дней. Таблицы, вышедшие за его границы, будут заархивированы – то есть объединены в одну большую таблицу, со служебной колонкой `_day`, содержащей дату в формате "YYYY-MM-DD", и отсортированной сначала по дню, а затем по полям сортировки, заданным для поставки.
Есть возможность настроить свой период для архивации, а так же изменить партиционирование результирующей таблички (по умолчанию BY_YEAR, можно поменять на BY_MONTH, если вы каждый день пишете миллионы событий).
Для особых случаев можно выключить архивирование совсем.

Для поставок, у которых включена экспирация, архивирование выключено.
Для поставок партиционированных крупнее, чем по дню, архивирование бессмысленно.

Конфиг по умолчанию:
```
 archive: {
     delay: 365
     target_partition: BY_YEAR
     disabled: false
 }
```

### Публикация {#publishing}

Мы публикуем в reactor события обновления (для мутаблельных) и создания (иммутабельных) таблиц. Событие создания иммутабельной таблицы (это минутные/часовые [срезы](#spawn) и eod для холокрона) публикуются по-возможности сразу после создания таблицы (или позже при недоступности реактора). Для мутабельных таблиц есть период тишины (3 часа, не настраивается, приходите, если нужно), после которого при отсутствии обновлений мы создадим в реакторе новое событие (инстанс артефакта), и окно обновлений (3 дня/месяца/года по типу партиционирования), более старые таблички мы в реактор не опубликуем. Для репартиционированных таблиц публикуются обновления перепартиционированной таблицы не старше года, а обновления таблицы-источника публикуются только для последних 3х таблиц. Для таблиц холокрона публикуется весь набор - raw (последние 3 таблицы), event (перепартиционированная таблица, публикуется за последний год) и eod (иммутабельная таблица, публикуется при создании).

#### Где искать реактор-артефакты

Тестинговые артефакты мы публикуем в продовый реактор, поскольку тестовым не пользуются аналитики.
Корневые папки [тестинга](https://reactor.yandex-team.ru/browse?selected=8590640) и [прода](https://reactor.yandex-team.ru/browse?selected=2959085). Артефакты таблиц лежат по пути, совпадающем с именем таблицы в ыте (например [billing_order_state_log](https://reactor.yandex-team.ru/browse?selected=9632841)). Имя артефакта выбирается так:

* дневная таблица - daily
* месячная таблица - monthly
* годовая таблица - yearly
* часовой срез - hourly
* остальные срезы - {n}m, где {n} это **cut_period_minutes**

## Kafka

Поставка в Kafka настраивается добавлением соответствующей секции kafka:
```
kafka: [
//старая кафка не из облака, будет закопана, переходим на mdb
{
    disabled: true
    output_format:  BINARY|JSON //бинарный формат это прото, который вы отправляли, но без брокерной обёртки
},
//новая кафка в mdb
{
    disabled: false
    mdb_kafka {
        name: "kafka-shared-01" //имя сервиса mdb-кафки из services
        topic: "my-uniq-topic" //имя топика
    }
    output_format:  BINARY|JSON //бинарный формат это прото, который вы отправляли, но без брокерной обёртки
}]
```
Для старой кафки брокер сам создаст топик с фиксированным именем `broker-<имя поставки>`, где все слеши (`/`) заменены на минус (`-`)
Для новой кафки нужно задать имя сервиса (сейчас что он единственный, 'kafka-shared-01') и имя топика. В имени топика разрешены буквы, цифры и -. Желательно изобразить из имени иерархию и начать со слова broker (например broker-realty-rent-offer-chat-events). Пока что топики создаются руками (как и права на чтение для broker-pipeline-lb-kafka). Для этого нужно создать тикет в VASUP.
У одного стрима/сабстрима может быть не больше одного кафка-конфига на сервис (нельзя несколько раз писать в старую кафку или в один и тот же mdb кластер).

При записи в кафку брокер добавит каждому записанному сообщению заголовок **schema_version**, содержащий версию схемы этого сообщения в формате SRaaS.

## Logbroker

Поставка в Logbroker настраивается через секцию logbroker:
```
logbroker: {
    disabled: false
    output_format: BINARY|JSON //бинарный формат это прото, который вы отправляли, но без брокерной обёртки
    compression = ZSTD|LZOP|GZIP|RAW //ZSTD самый быстрый
}
```
Имя исходящего топика задать нельзя, оно формируется как "/vertis/broker/[prod|test]/out-topics/имя-стрима"

## ClickHouse

Мы умеем выгружать события в СlickHouse, в свой или в ваш. В первом случае вы договариваетесь о квоте и необходимых ресурсах, приходите к нам и мы создаем кластер под именем, заданным вами в конфиге (по схеме broker_{cluster}_{env}), и выдаем вам туда доступ. Во втором вам нужно будет завести нам пользователя с правами, и мониторить этот кластер.

Для создания поставки в СlickHouse нужно добавить в брокерный конфиг секцию **clickhouse** следующего типа:
```
 // тут может быть несколько поставок в разные кластера ch
 clickhouse: [{
     cluster: "general"
     db: "stats"
     table: "event"
     expire_in_days: 180
     primary_key: ["offer_id"]
     fields: ["offer_id", "user", "price"]
 }]
```
Clickhouse - колоночное хранилище, время записи зависит от числа колонок. Поэтому нужно явно задать фильтр, какие колонки вы хотите писать.
Это можно сделать либо разметив нужные поля аннотацией broker.include_to_ch, либо через 'fields' в примере выше.

Если сообщение поставляется в разные кластера ch, задать поля можно только через списки 'fields'.
Нельзя создавать несколько поставок в один и тот же ch-кластер, это просто неэффективно. Договоритесь со вторым потребителем и объедините ваши поля в одной поставке.


Доступные настройки:
* **cluster** - алиас для вашего кластера (autoru/realty/finstat/realty_finstat/cm_expert/vertis_bi, если вашего сервиса тут нет - пишите). Мы создаем кластеры сами и называем по схеме broker_{cluster}_{env}.
* **db** - имя базы данных, уникальное в кластере. Максимально осмысленное и отличающее его от других баз сервиса. Например 'events' - плохое имя.
* **table** - имя таблицы в базе. Тоже осмысленное, events или offers скорее всего будет путать людей.
* **expire_in_days** - экспирация таблицы в днях (будет отсчитываться от значения в поле с таймстампом события)
* **primary_key** - (опционально) список полей первичного ключа (они должны быть помечены аннотацией **include_to_ch**). По умолчанию в качестве ключа используется [id события](https://a.yandex-team.ru/arc_vcs/classifieds/schema-registry/proto/broker/api/requests.proto?rev=r9380289#L31).
* **fields** - список полей для записи (альтернатива **include_to_ch**)

В качестве примера можно посмотреть на [конфиг](https://a.yandex-team.ru/arc_vcs/classifieds/schema-registry/proto/broker/cannon/event.proto) события нашей пушки.

### Раскладка данных

Данные партиционируются по таймстемпу события (а точнее по дню).
Кроме выбранных полей и обязательного для всех поставок поля с **таймстампом** в таблице будут служебные поля **_id**, **_partition**, **_offset**.

Конвертация в типизированные колонки происходит по следующим правилам:

 1) Примитивные поля (все целочисленные типы, double, float, string)

    - конвертируются в соответствующий [примитивный тип](https://clickhouse.com/docs/en/sql-reference/data-types/) ClickHouse
    - всегда имеют значение (возможно, дефолтное)

 2) Boolean

    - конвертируются в [UInt8](https://clickhouse.tech/docs/ru/sql-reference/data-types/boolean/), в котором используются только значения 0 и 1
 3) Классы-обертки над примитивными типами (google.protobuf.DoubleValue и т.д.)

    - разворачиваются в соответствующий примитивный тип ClickHouse
    - при отсутствии значения будет записан null
 4) Cообщения

    - записываются как поля типа string, содержащие исходное сообщение в виде [json](https://developers.google.com/protocol-buffers/docs/proto3#json).
    - при отсутствии значения будет записан null.
 5) Списки (repeated-поля)

    - списки пишутся в виде [Array](https://clickhouse.com/docs/en/sql-reference/data-types/array/). Значение конвертируется по этим же правилам.
    - всегда имеют значение, по дефолту - пустое ("values": [])
 6) Maps

    - аналогично с сообщениями
 7) Enums

    - записываются как строковое значение из enum
 8) Timestamps

    - будет записан примитивный тип [DataTime(9), 'Europe/Moscow'](https://clickhouse.com/docs/en/sql-reference/data-types/datetime64/)
    - при отсутствии (дефолтном значении) будет записано null

 8) Oneof

    - будет записано в виде набора колонок – по одной для каждого из вариантов oneof-поля
    - незаданные примитивные поля, repeated и map поля будут заполнены дефолтными значениями
    - незаданные поля остальных типов будут записаны как null


### Эволюция данных
* умеем только добавлять новые колонки в схему. Matview нужно править руками
