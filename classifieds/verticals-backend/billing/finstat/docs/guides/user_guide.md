# Дока для потребителей

## Что это за сервис?

Инфраструктурный сервис, с помощью которого можно просто и быстро сделать доменный сервис финансовой статистики.
Например - финансовая статистика для дилеров в autoru.
Сервис умеет считать агрегаты, сейчас это сумма и кол-во.
Сервис может отдавать список сырых событий, например списаний/возвратов.

У сервиса есть ряд ограничений, о них написано дальше в доке. Если какое-то из них для вас не подходит приходите обсудить в чат.

## Коротко про архитектуру
![data_flow](../images/finstat_services.png) <br/>
Т.е наливаем данные с дублями через брокер, дубли вычищает finstat в момент запроса в clickhouse.

Описываем схему финансовых событий в protobuf, это единый message, который использует и брокер и finstat.
- [Дока брокера](https://docs.yandex-team.ru/classifieds-infra/broker/info)
- [Пример схемы](https://a.yandex-team.ru/arcadia/classifieds/schema-registry/proto/billing/finstat/autoru_dealers.proto?rev=r9532537?rev=r9558371L26)

У схемы есть обязательные для finstat-api поля, это
- transaction_id - уникальный id события, по которому мы дедуплицируем данные.
- version - если есть дубль по transaction_id, выбираем событие с самой большой версией.
  Как пример, в биллинге есть процесс переобиливания событий.
  Событие, за которое было списано 50 рублей, по каким-то причинам может измениться и мы спишем за него 100 рублей.
  Тогда в версию удобно писать таймстемп изменения события.

- event_time - время, когда произошло событие.
- spent_kopecks - расходы в копейках.
- и дополнительные поля для фильтров и группировок.
Эти дополнительные поля разные для разных сервисов и зависят от вашей бизнес-логики.
Для простоты api сервиса решили сделать их типом string.
Кроме того, эти поля считаем иммутабельными, так как без этого ограничения у нас не получилось написать эффективный запрос в кликхаус.

Наливаем данные в кликхаус брокером, так как он удобен своим grpc-api.
После записи через брокер в кликхаусе могут появится дубли(гарантии брокера at-least-once), которые мы удаляем во время селекта в finstat.

У finstat-api простое grpc-api.<br/>
- getSpendings - получение sum и count с фильтрами и группировкой. Всегда есть группировка по дням.<br/>
- getRawSpendings - получение сырого списка событий
- getWorkspaces - получение списка актуальных воркспейсов
- getSchema - получение списка имен полей таблицы кликхауса для опредленного воркспейса
- [proto схема](https://a.yandex-team.ru/arcadia/classifieds/schema-registry/proto/billing/finstat/api_model.proto?rev=r9492061#L1)
- [Описание схемы удобно читать отсюда](https://a.yandex-team.ru/arcadia/classifieds/schema-registry/proto/billing/finstat/api_model.proto?rev=r9558371L119) <br/>

Сложные агрегаты, например "медиана от средних по дням" считаем не в finstat-api, а по ответу от него.
Т.е получаем средние по дням от finstat-api и в своём сервисе считаем от этих данных медиану.
Решили сделать так, чтобы был баланс между сложностью/удобством использования нашего api.
Такие агрегаты сильно зависят от доменной области.

## Адреса балансеров grpc-api
- тестинг: [finstat-api-grpc.vrts-slb.test.vertis.yandex.net:80](finstat-api-grpc.vrts-slb.test.vertis.yandex.net:80)
- прод: [finstat-api-grpc.vrts-slb.prod.vertis.yandex.net:80](finstat-api-grpc.vrts-slb.prod.vertis.yandex.net:80)

## Запросы, на примере статистики дилеров autoru.
#### Запрос getSpendings
```
{
    "workspace": "AUTORU_DEALERS",
    "filters": {
         "client_id": "232"
    },
    "group_by": [
        "product"
    ],
    "from": "2022-02-09",
    "to": "2022-02-10"
}
```

#### Ответ getSpendings
```
{
  "spendings": [
    {
      "day": "2022-02-09",
      "grouped_by": {
        "product": "placement"
      },
      "spent_kopecks": "1240000",
      "count": "23"
    },
    {
      "day": "2022-02-10",
      "grouped_by": {
        "product": "placement"
      },
      "spent_kopecks": "1499000",
      "count": "28"
    }
  ]
}
```

#### Запрос getRawSpendings
```
{
    "workspace" : "AUTORU_DEALERS",
    "filters": {
        "client_id": "232"
    },
    "from": "2022-02-09",
    "to": "2022-02-10",
    "paging" : {
        "page_num": 1,
        "page_size": 10
    }
}
```

#### Ответ getRawSpendings
```
{
  "spendings": [
    {
      "transaction_id": "203784ce4d5e654d5fb2a3028c5cf46c",
      "version": "1644362790",
      "event_time": "2022-02-08T22:00:00Z",
      "spent_kopecks": "73000",
      "fields": {
        "category": "CARS",
        "client_id": "232",
        "company_group": "273",
        "offer_id": "1106307726-80d49b32",
        "product": "placement",
        "section": "USED"
      }
    },
    {
      "transaction_id": "d5414c8c00043cb6a75016064bc66a7e",
      "version": "1644394093",
      "event_time": "2022-02-09T07:00:00Z",
      "spent_kopecks": "73000",
      "fields": {
        "category": "CARS",
        "client_id": "232",
        "company_group": "273",
        "offer_id": "1114691496-f993dc4b",
        "product": "placement",
        "section": "USED"
      }
    }
  ],
  "paging": {
    "page_num": "1",
    "page_size": 10,
    "total_page_count": "6"
  }
}
```

## Как заехать?
Пишите в чат, есть некоторое кол-во ручной работы, которую нам нужно сделать.
- [телеграм чат финстаты](https://t.me/+y_dHHmRz1eU1ZDgy)
- [чат поддержки биллинга](t.me/joinchat/DN5j4EhyeEtKVkNXcFUDsg) <br/>

Что нужно будет сделать с вашей стороны:
1. Составить схему - по каким полям вы будете фильтровать? группировать?
2. Подумать о сортировке, сказать нам. Если для нового поля в кликхаусе нужно добавить сортировку, мы добавим это поле сами.
   Сортировка - главное что нужно, чтобы запросы в кликхаус не тормозили.
3. Подготовить скрипт в yt, чтобы собрать исторические данные. Данные должны быть в той же схеме что и таблица в кликхаусе.
   После этого мы запустим скрипт для переливки данных в вашу табличку.
   Почему так - у брокера есть ограничения по записи данных в прошлое. К тому же скрипт переливает данные быстро.
   [Пример скрипта в yt. Так собираем данные для дилеров autoru](https://a.yandex-team.ru/arcadia/classifieds/verticals-backend/services/dealer_finstat_writer/docs/upload_indexing?rev=r9253252#L1)
4. Написать сервис, который будет наливать real-time данные через брокер.
5. Использовать finstat-api, там где хотите показывать статистику

## Что может понадобится после заезда
Добавить новое поле.
Для этого нужно
1. Обновить схему. Если поле нужно добавить в ordering, написать нам перед тем как добавлять поле. Мы сами добавим его в схему.
2. Начать писать данные в это поле в сервисе, который в real-time наливает данные
3. Обновить скрипт наливки исторических данных в yt, чтобы в нём появилось новое поле.
   Если в качестве version используется timestamp, когда произошло событие данной версии,
   можно использовать следующий план.
   Поле version нужно выставить так, чтобы оно с одной стороны было больше чем раньше,
   c другой стороны, чтобы не было race-condition c новыми real-time данными
   и чтобы при следующем добавлении нового поля, не нужно было думать, а какой в прошлый раз использовали version?
   Этим условия удовлетворяет например max(version) + 1, одинаковое для всех.
   После обновления, написать нам, чтобы мы перелили исторические данные.

## Переливка данных из прода в тестинг

Бывает нужно, чтобы в тестинге тоже было много данных и/или в тестинге были продовые данные. В этом случае можно переливать данные из прода в тестинг.

На данный момент так переливается только таблица _autoru_dealer_events_ ([тикет, где заводили эту переливку](https://st.yandex-team.ru/VSDATA-1621)).

Если вы тоже хотите переливку, то нужно завести тикет в очереди VSDATA (подобный [этому](https://st.yandex-team.ru/VSDATA-1621)) и показать этот тикет [Бригаде перекладывания байтиков](https://staff.yandex-team.ru/departments/yandex_personal_vertserv_infra_dep72957/) и команде финстаты.
