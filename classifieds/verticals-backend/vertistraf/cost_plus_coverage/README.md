# Анализ покрытия Cost+

[Дашборд](https://grafana.vertis.yandex-team.ru/d/cost-plus-coverage-board/cost-coverage?orgId=1&refresh=1m)
[Сборка в TC](https://t.vertis.yandex-team.ru/buildConfiguration/VerticalsBackend_AutoRuExp_cost_plus_coverage_release?mode=builds)

### Как это работает

Изначально задаются сервисы, для которых и будет происходить анализ покрытия. 
Для конфигурирования сервиса необходимо указать его **projectId** и маркер cost+'a (узнается у аналитиков), a также 
ссылка на s3 со всеми фидами.

Само покрытие считается по логам серпа, которые [собирают аналитики](https://yt.yandex-team.ru/hahn/navigation?path=//home/verticals/marketing_analytics/logs_struct_with_comp). 
Пересборка этих логов происходит раз в день.

Данный анализатор делает следующее: 
1. Проверяет, есть ли лог серпа от аналитиков за вчера. Если его нет, то репортит в графану и завершается до следующего раза.
2. Со всех источников yml'ей в s3 выкачивает их во временную директорию на s3. Данный шаг был сделан для того, чтобы 
минимизировать различия между старой и новой версиями yml'ей в авто(т.к. запись фала там происходит после сборки).
3. Со временной директории yml'и скачиваются. Из них извлекаются урлы сетов и пушатся в таблички в yt.
4. Выполняется yql запрос, на выходе которого имеются следующие строки следующего вида:
    * **url** - сам урл
    * **preseneted_in_yml** - найден ли этот урл в yml файлах
    * **is_cost_plus** - воспринимает ли серп урл как урл cost+'а
    * **project_id** - идентификатор сервиса
5. Результат запрос из пункта **4** вычитывается и пушится в графану
