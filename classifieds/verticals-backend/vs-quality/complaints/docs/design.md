### Complaints - сервис обработки жалоб


### Какие задачи решает
- создание/хранение жалоб
- отправка сигналов в модерацию для выяснения проблем с оффером (т.е. создание задач в хобо)
- хранение и вычисление рейтинга жалобщиков
- бан спамщиков(занесение их в blacklist в админке)


### Компоненты
Complaints будет состоять из двух частей – `api` и `scheduler`.


### Основные сущности
- Complaint(жалоба) - это претензия к офферу. Обязательными атрибутами каждой жалобы являются идентификатор
    жалобщика, идентификатор оффера, идентификатор владельца оффера и причина(ы) жалобы
- Complainant — автор / инициатор жалобы.
- Накопительные жалобы - жалобы с определенной причиной, которые могут создать хобо задачу если "накопилось"
  достаточное количество на один оффер.



### Api
В качестве способов коммуникации(и описания апи) с другими сервисами используется grpc.

Методы:

- createComplaint(сomplaint: Complaint) : ComplaintId - создать жалобу
- getOfferComplaints(offerId: String, domain: Domain): List[Complaint] - достать все жалобы на оффер
- getOffersOwnerComplaints(userId:String, domain: Domain): List[Complaint] - достать все жалобы на офферы пользователя 
- getСomplainantAppeals(userId:String, domain: Domain): List[Complaint] - достать все жалобы(aka appeals) созданные пользователем

### Scheduler (см. ниже цикл обработки жалоб)

Шедулер будет отвечать за фоновые процессы. У нас они возникают потому что:
1) Наш механизм создания хобо задач, путем простановки сигналов офферу, предполагает, что оффер есть в модерации.
   Может быть так что при создании жалобы, оффер еще не доехал до модерации, поэтому должна присутствовать асинхронная обработка.
2) Нам нужно следить за тем подтвердится жалоба или нет, это можно делать асинхронно потребляя результаты хобо задач.
3) Нужно митигейтить количество создаваемых хобо задач на какой-то оффер. Запрошенный механизм:
   после обработки задачи в хобо, у оффера, на который пожаловались, должен быть cool down на час,
   то есть время когда мы не будем больше создавать хобо задачи на тот же оффер.


Как эти задачи будут реализованы:
- Для асинхронной обработки жалоб(пункты 1,3), будет таблица "queue"(просто очередь для обработки) и в ней будем отслеживать,
  что и когда следует сделать с той или иной жалобой. Queue - это внутренний механизм для обработки жалоб, 
  к ней доступа из вне не будет. В таблице можно хранить поле для времени последующей обработки и статус,
  который обозначит что следует сделать с жалобой.
  
  - AWAIT        - если жалоба в этом статусе, значит мы еще ждем создания оффера в модерации
  - IN_PROGRESS  - жалоба отправлена в модерацию для создания хобо задачи. Жалоба находится в этом статусе до получения
                   хобо резолюции
  - COOL_DOWN    - переходим на статус КД после получения резолюции, хобо задачи на оффер из жалобы не создаем час
                   c погрешностью 20 минут


- Таски, которые это сделают:
    - Регулярная таска(20 min) будет обрабатывать жалобы из queue, где process_after =< now and status == AWAIT.
       Если оффер нашелся, идем дальше по флоу(см внизу), если нет оставляем в queue и обновляем process_after
      
    - Регулярная таска(20 min) будет вычищать жалобы из queue после КД в примерно один час, i.e.
       process_after =< now and status == CD.


- Для пунктов 2, 3: будем обрабатывать результаты хобо задач для жалоб с помощью консьюмера и 
- отправлять их при переходе в статус КД в queue.

NOTE:  
1.Cтатусы присваиваются жалобам только в контексте обработки в queue, они внутренне просто помогают следить, за тем,
что и когда следует сделать с обрабатываемой жалобой в queue. Если жалоба никогда в queue не попадала, то все описанное выше
ей не релевантно.

2. Для отслеживания истории того, как жалоба получила ту или иную резолюцию, будет достаточно посмотреть в логи, так как
   каждое решение отправлять дальше жалобу по флоу(см внизу) будет логироваться вместе с причиной 

 
### Blacklist админка
Перед созданием задач в хобо будем проверять от спамщиков жалоба или нет
- addUser(complainant_id)
- deleteUser(complainant_id)


## Предположительная Нагрузка
В среднем сейчас 35rps на чтение и 1rps на запись 


нагрузка на запись - если в день примерно создается 3652 жалоб, то это по 2 запроса на запись в минуту
нагрузка на чтение - основная нагрузка будет из хобо задач на ручку getOfferComplaints. В datalens есть 
                     данные только по одной очереди для автору, всего там обрабатывается около 450 задач в день.
                     Есть 16 очередей complaints, модератор закрывает задачу примерно за 2-3 минуты, если в каждой очереди 
                     работает по ~10 модераторов, то макс рпс будет 160
                     
//TODO нагрузка на остальные ручки будет описана после ответа от менеджеров

## Хранение

В атвору накопилось 8 миллионов жалоб с 2016, значит в год создавалось примерно 1 333 000, и 3652 жалобы бы в день.
В недвиге накопилось 1 868 087 c 2016.

При такой нагрузке и объеме можно использовать Postgres вместо Ydb(срок хранения будет год).
Почему Postgres? Его проще использовать, все работает из коробки, обширная документация, и перформанс там не так страдает
при использовании вторичных индексов + постгря умная и умеет мержить и эффективно использовать индексы при запросах,
где в условиях будет больше одной индексированной колонки.


`complaints` – таблица с жалобами 
- `id: Uint64` - id жалобы
- `offer_id: Utf8`  – id объявления на которое пожаловались
- `offer_owner_id: Utf8` – id автора объявления, на которое пожаловались
- `offer_owner_type: Ut8` - тип автора (дилер, обычный юзер и тд.)
- `complainant_id: Utf8` - id жалобщика
- `complainant_type: Ut8` - тип жалобщика (дилер, обычный юзер и тд.)
- `source: Option[Utf8]`  - источник жалобы, как юзер узнал что с объявлением что-то не так
- `reason: List[Utf8]`  -  причины жалобы
- `comment: Utf8` -  опциональный комментарий к жалобе (уточнить макс длину)
- `resolution: Resolution` - подтвердилась жалоба или нет + может будут добавлены ризоны выбранные модератором
- `created_at: Timestamp` - дата создания
- `updated_at: Timestamp`- дата обновления  
- `domain: Uf8` - сервис из которого пришла жалоба
-  `hobo_key - Option[Utf8]` -  ключ хобо задачи созданной на эту жалобу
`PK = (id)`

индекс сделать по offer_id, complainant_id, offer_creator_id

Срок хранения - 365 дней


`queue` -  очередь жалоб на обработку
- `id: Uint64` - id жалобы
- `offer_id: Utf8` - id оффера
- `process_after: Timestamp` - когда следует обработать жалобу в след раз
- `status: Utf8` - статус жалобы("AWAIT", "IN_PROGRESS", "CD")

`PK = (id)`

индекс сделать по offer_id, process_after, status


`blacklist` - хранит id неугодных
- `id` - id пользователя
- `domain` - домен
`PK = (id)`

- todo уточнить ttl


`complaints_analytics` -  таблица событий создания жалоб, хранит в себе request context info
-  `id: Uint64` - id жалобы
-  `application: Utf8` - приложение, с которого отправлена жалоба 
-  `placement: Utf8` - окно приложения, с которого отправлена жалоба 
-  `is_authorized_user: Bool`  - от авторизированного пользователя или нет

`PK = (id)`


Пока вообще не нужна
`complainants` -  таблица жалобщиков с их рейтингом
- `user_id: Utf8` - id жалобщика
- `rating: ???` -  рейтинг жалобщика, определяет насколько полезны жалобы этого юзера

`PK = (user_id)`

TODO ждем еще требований от сервисов по рейтингу


## Поиск
Все нужные филды(сейчас коммент и ризон) будут индексироваться через модерацию в документе оффера.
Индексатор в модерации будет ходить за жалобами и обогащать ими документ перед индексацией.


## Наследование
Для того чтобы не перегружать хобо, и все равно иметь какую-то резолюцию на жалобу, которую задачу не создала, 
будет ограниченный механизм наследования резолюций от одной жалобы к другим.

При каких условиях будет происходить наследование:
1. Если пришла накопительная жалоба, и мы достигли желаемого количества таких жалоб, 
   после закрытия хобо задачи, все накопительные жалобы на оффер за последние 24 часа унаследуют резолюцию
   последней(создавшей хобо задачу)


### Цикл обработки жалобы
![flow](flow.png)


