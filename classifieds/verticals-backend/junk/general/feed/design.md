# FeedProcessor design doc

Сервис для работы с фидами

## Требования

- два способа выгрузки объявлений – ручная одноразовая заливка и регулярное скачивание фида по ссылке
- пользователь может иметь не более одной выгрузки на аккаунт
- каждое объявление должно содержать уникальный в рамках пользователя идентификатор
– удаление фида приводит либо к полному удалению всех объявлений, загруженных через него, либо к их переводу в ручной режим
- пользователь должен иметь возможность посмотреть историю загрузок и статистику по каждой загрузке
- для конкретной загрузки нужен подробный список ошибок

## Формат фида
[Пример](processor/parser/test/resources/feed.xml)

[XSD-схема](processor/parser/resources/feed.xsd)

## Компоненты
`FeedProcessor` состоит из трех частей:
 - `API` – отвечает за управление фидами и получение статистики/истории по ним
 - `feed-loader` - отвечает за скачивание файлов из внешнего интернета
 - `feed-processor` – унифицирует объявления и экспортирует их в [GOST](../gost/readme.md)

## Скачивание фидов
Для разовых выгрузок заливку на внутренний MDS осуществляет фронтенд через [uploader](https://wiki.yandex-team.ru/vertis/uploader/).

При добавлении/удалении фида по ссылке через api создается/удаляется соответствующая строка в таблице `feed_loader_task`.

Скачиванием файлов из внешнего интернета занимается фоновый процесс - `FeedLoader`.
Задачи на скачивание раздаются через шедулер и `TokenDistributor`.
Каждый процесс берет набор незаблокированных (по возрастанию `last_fetched_at`) урлов, а затем для каждого выполняет следующий алгоритм:
1) Пробует взять блокировку на пользователя (таблица `feed_locks`, контекст `feedloader`), чей фид сейчас обрабатывается.
2) Если блокировку взять не удалось, обработка заканчивается
3) Скачивает файл на локальный диск через `squid`-прокси
4) Считает хэш от контента
5) Сохраняет файл в S3 по ключу равному хэшу из шага 4
6) Создает таск на обработку в таблицах `tasks` и `task_queue`.
7) Если лок был получен на шаге 1, то отпускаем его вне зависимости от успешности выполнения предыдущих операций

Второй фоновый процесс отслеживает повисшие задачи (старше N часов) и удаляет локи.
## Обработка заданий

Задания обрабатываются фоново.

Задачи раздаются через шедулер и `TokenDistributor`.
Каждый процесс берет несколько заданий из очереди `task_queue`, далее для каждой задания выполняет алгоритм:
1) Пробует взять блокировку на пользователя (таблица `feed_locks`, контекст `feedprocessor`), чей фид сейчас обрабатывается. В противном случае два процесса могут начать обрабатывать задания одного пользователя и создания/удаления объявлений могут перемешаться
2) Если блокировку взять не удалось, обработка задания заканчивается
3) Скачивает фид и проверяет xsd-схему
4) Унифицирует объявления
5) Формирует сообщения для GOST и пишет их в кафку
6.1) Если в процессе обработки возникли фатальные не транзиентные ошибки, задание переводится в статус failed и удаляется из очереди `task_queue`.
6.2) Если в процессе обработки возникли фатальные транзиентные ошибки, обработка задания заканчивается, но его статус не меняется и из очереди не удаляется для последующего ретрая.
6.3) Если ошибок не было, задание удаляется из очереди.
7) Если лок был получен на шаге 1, то отпускаем его вне зависимости от успешности выполнения предыдущих операций

Второй фоновый процесс отслеживает повисшие задачи (старше N часов) и удаляет локи.

### Унификация объявлений
Для публикации на сервисе объявление из фида необходимо привести к стандартному виду
- распознать категорию
- распознать атрибуты

Все последующее обогащение (добавление новой информации в объявление), не влияющее на публикацию, предлагается вынести наружу, так как это потенциально нужно и для ручных объявлений.

Важно: если унификация упала из-за transient ошибки, то объявление все равно проходит по пайплайну дальше, чтобы gost имел возможность не удалить его.

#### Парсинг категории/атрибутов
По аналогии с парсингом в колдуне (для старта может даже через тот же код) получаем выгрузку каталога `Bonsai`, строим индексы и ищем по названиям/синонимам в тексте.

#### Геокодирование
Адрес в фиде может быть передан либо координатами, либо строкой.
Для публикации в `gost` нужен также `geoId` (метро, район обогащаются гостом).

Что если унести это в `gost`?

### Взаимодействие с GOST
Взаимодействие осуществляется посредством двух топиков в Kafka (исходящие запросы и ответы на них).
В топик с запросами пишутся пачки объявлений, относящихся к одной загрузке.
Каждая пачка имеет `seller_id`, `task_id` и `batch_id`.
Шардирование по `seller_id`.
В конце обработки фида отправляется специальное сообщение, сигнализирующее о конце обработки задания.
Все объявления, которые были созданы этим `seller_id` через фиды, но не переданные в текущей загрузке, будут удалены (или переведены в ручные, если выбрана соответствующая опция).

В топик с ответами поступают результаты публикации объявлений (добавлено/удалено/отклонено валидацией или модерацией/пропущено).
Они также должны заканчиваться терминальным сообщением.
Шедулер `FeedProcessor`'a читает ответы и сохраняет их в таблицы `offer_errors`, `feed_statistics` и `offer_batches`.

Ключевое требование – все промежуточные запросы (не считая дублей) должны быть отправлены строго до терминального сообщения.
Например, это можно реализовать через настройку `max.in.flight.requests.per.connection=1` у продюсера.
 
## Статистика/ошибки обработки
Типы ошибок:
 - Ошибка валидации (отсутствующее поле, неизвестное значение и т.д.)
 - Ошибка распознавания категории/атрибута
 - Ошибка геокодирования – не удалось распознать адрес
 - Объявление забанено
 - Дубликат (ищем только дубликаты по `external_id` - это поле `id` в фиде)

Все ошибки должны проходить через гост (иначе объявления удалят).
Ошибки хранятся как есть. Агрегация на лету невозможна. Как вариант, экспорт ошибок в Excel-таблицы.
Статистику накапливаем по мере обработки.

Скачка фотографий происходит асинхронно, поэтому ошибки по ним будет сложно привязать к `task_id`.
Вероятно, будет отдельная таблица url -> ошибка (Она должна экспортироваться из `Gost` в `FeedProcessor`?).

Фатальные ошибки (битый файл, несоответствие xsd-схеме) будем хранить на уровне задания в таблице `tasks`.

## Чистка старых данных
История скачиваний будет постепенно копиться.
Необходимо ее регулярно подчищать в шедулере.
Сюда входят как ссылки в `mds`, так и таблицы, где содержится информация про конкретный `task_id` (`tasks`, `offer_errors`, `feed_statistics`).

Варианты:
1) Удаление по времени. Добавляем колонку/индекс по времени модификации. Удаляем все, что старше n дней. Для ручных загрузок удалит единственную загрузку.
2) Удаление по версиям. Добавляем таблицу с очередью на очистку (`old_tasks`). Пишем туда прямо в методах API. Чистим все, кроме n последних скачиваний, либо при удалении фида всю историю. 

Далее в обоих вариантах чистим по порядку таблицы с данными, удаляем файл из `mds` и удаляем  последнюю запись про этот `task_id`.

Вариант 2 выглядит предпочтительнее.

## Флоу работы с parsed фидами
Parsed фиды - это фиды, которые snatcher спарсил из других классифайдев (авито и т.д.) и прислал в фид-процессор для дальнейшей обработки.
Когда snatcher получает json с профилем и объявлениям пользователя, он никак не обрабатывая файл, делает вызов в фид-процессор, указывая: 
* uid пользователя
* ссылку на загруженный файл 
* источник, откуда файл был загружен

Работы с parsed офферами почти не отличается от обработки офферов из обычных фидов, за исключением того, что ошибки обработки parsed офферов не должны показываться на фронте в списке ошибок обработки офферов (за показ ошибок пользователю отвечает snatcher)

Обработка parsed фидов реализована на основе множественных фидов для юзера, подробнее в следующем разделе.

## Множественные фиды для пользователя
Множественные фиды -- это возможность одному пользователю иметь несколько фидов, возможно, из разных источников.
Множественные фиды существуют каждый в своём неймспейсе, то есть не взаимодействуют с результатами работы друг друга: CRUD только свои офферы, имеют свои таймеры выполнения и сохраняют только свои ошибки выполнения.
Для поддержки множественных фидов необходимо: 
* Уметь в фид-процессоре создавать несколько тасок для одного юзера в разных неймспейсах, обрабатывать эти таски независимо друг от друга: парсить офферы, отправлять в гост, получать и сохранять результат обработки
* Уметь в госте сохранять, изменять, удалять и дедублицировать офферы внутри одного неймспеса, не модифицируя данные других неймспейсов

## Хранение
Данные хранятся в Postgres.
Если предположить, что фиды дают процентов 80% от нагрузки на `Gost`, то выходить 4к rps.
Так как обработка  идет батчами, то нагрузка спадает в 10-100 раз, что нормально должно ложиться на реляционную базу.
Данные бесконечно не растут.

`feed` – таблица с настройками фидов
 - `seller_id: Utf8` – id продавца
 - `version: Int64` - версия фида (увеличивается при каждом изменении)
 - `status: Int32` – статус фида (enum). Варианты значений: `active`, `removed`
 - `proto: String` – настройки фида в protobuf-формате (TODO добавить ссылку)
 
 `PK = (seller_id)`

`feed_loader_task` - таблица с фидами, которые нужно скачивать регулярно из внешнего интернета
 - `seller_id: Utf8` – id продавца
 - `feed_version` - версия фида
 - `url: Utf8` - ссылка на внешний интернет для скачивания
 - `last_fetched_at: Int64` - время последнего успешного скачивания

  `PK = (seller_id)`

  `Index = (last_fetched_at)`
 
`tasks` - таблица с задачами на обработку фидов
 - `seller_id: Utf8` – id продавца
 - `task_id: Int64` – id загрузки (монотонно возрастает)
 - `feedloader_task_id: Utf8` – id фида в `Feedloader`, требуется для обратного матчинга при получении задачи
 - `feedloader_task_result_id: Int64` – id загрузки фида в `Feedloader`, требуется для проверки актуальности ссылки
 - `created_at: Int64` – время создания задачи
 - `updated_at: Int64` – время последнего обновления
 - `url: Utf8` – ссылка на скачивание фида из внутренней сети
 - `status: Int32` – статус задания (enum , TODO добавить ссылку). Варианты значений: `in_progress`, `failed`, `succeed`.
 - `error_message: Utf8` – сообщение о фатальной ошибке
 - `settings: String` – настройки задачи (например, что делать при получении терминального сообщения – удалять или переводить в ручные)
 
 `PK = (seller_id, task_id)`
 
 `Index = (seller_id, updated_at)`
 
`task_queue` - таблица с задачами, которые необходимо обработать
 – `seller_id: Utf8` – id продавца
 - `task_id: Int64` – id загрузки
 - `created_at: Int64` – время последнего обновления

 `PK = (seller_id, task_id)`
 
`feed_locks` - таблица с локами для обработки фида
 - `context: Enum` - контекст, в котором взята блокировка (`feedprocessor/feedloader`)
 - `seller_id: Utf8` - id продавца
 - `acquired: Int64` - время взятия блокировки

 `PK = (context, seller_id)`

 `Index = (context, acquired)`

 `offer_batches` – таблица с обработанными батчами объявлений
  – `seller_id: Utf8` – id продавца
  - `task_id: Int64` – id загрузки
  - `batch_id: Utf8` – id батча (можно сделать монотонным числом и тогда вообще не нужно хранить предыдущие)
  
 `PK = (seller_id, task_id, batch_id)`
  
`feed_statistics` – таблица с агрегированной статистикой
   - `seller_id: Utf8` – id продавца
   - `task_id: Int64` – id загрузки
   - `statistics: String` – статистика в proto
   
 `PK = (seller_id, task_id)`

`offer_errors` - индексная таблица с подробными ошибками отдельных загрузок
 - `seller_id: Utf8` – id продавца
 - `task_id: Int64` – id загрузки
 - `external_id: Utf8` – id объявления
 - `error_id: Int64` - id ошибки
 - `error_level: Enum` -- уровень ошибки (`error`/`waring`) 
 - `title: Utf8` - заголовок объявления
 - `error_message: Utf8` – ошибка в текстовом виде
 
 `PK = (seller_id, task_id, external_id, error_id)`
 
 `Index = (seller_id, task_id, error_level, external_id, error_id)`
 
`old_tasks` - таблица для удаления старых данных
  - `seller_id: Utf8` – идентификатор фида
  - `task_id: Int64` – id загрузки
  
  `PK = (seller_id, task_id)`
