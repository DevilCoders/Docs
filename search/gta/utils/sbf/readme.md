# Scalable Bloom Filter

* Вероятностная структура данных, состоящая из нескольких фильтров Блума. 
* Входными параметрами являются размер в битах одного чанка и ошибка ложноположительного срабатывания на нем.
* Память растет _линейным_ образом от кол-ва объектов. На 1 объект расходуется 10-30 бит.
* Легко дампить и восстанавливать из хранилища.
* Питоновские биндинги

    
# Использование

Далее описывается код на питоне. 

ScalableBloomFilter - класс, инициализирующийся двумя числами. Первое - размер в битах, как степень двойки 
(1 мегабайту соответствует 23). 
Второе число - величина ложноположительной ошибки, опять же как степень двойки 
(0.1% соответствует 10. `2^-10` ~ 0.1%). 
В блумовских фильтрах эта величина также равняется количетсву хэш-функций. 
По-умолчанию этот параметр равняется 16, то есть величина ошибки ~ `1.5 *10^-5`.
    
```python
from search.gta.utils.sbf.python.sbf import ScalableBloomFilter
# создаем фильтр на 1024 бит с погрешностью в 0.1%.
sbf = ScalableBloomFilter(10, 10)  

# Добавляем элемент "1"
sbf.add('1')

# True
print('1' in sbf) 

# Добавляем 1000 элементов
for x in range(1000):
    sbf.add(str(x))
    
# False
print('1001' in sbf) 


# Добавляем вторую тысячу элементов
sbf_2 = ScalableBloomFilter(10, 10)
for x in range(1000, 2000):
    sbf_2.add(str(x))
    
# Соединяем фильтры

sbf.merge(sbf_2)

# Вычсляем примерное количество элементов
# ~ 2000
print(sbf.get_total_count())
```
        
# SaveLoad
    
```python
# Сохраняем куда-нибудь "регистры". Каждый регистр имеет 128 бит.
# сохранять можно как строки, например в YT.
for item in sbf.dump_registers():
    save_to_somewhere(item['register'])
    
    
# Создаем новый фильтр и загружаем в него регистры
sbf_2 = ScalableBloomFilter(10, 10)
for item in load_from_somwhere():
    sbf_2.load_register(item)

# Все 1000 элементов на месте
print(len([int(str(x) in sbf_2) for x in range(1000)]))
```
    
   
# Чем это лучше N обычных фильтров Блума?
* Контролируемый расход памяти. Входными параметрами являются не кол-во объектов, а размер памяти.
* Работает быстрее, чем N последовательных фильтров, потому как хэши для всех фильтров общие и вычисляются лишь раз.
* Можно независимо составлять несколько sbf фильтров (например, в map-reduce джобах), а потом мерджить в один фильтр.

# Значение ошибки.
При ресайзе фильтра, или при мердже двух фильтров, ошибка увеличивается пропорционально кол-ву элементов в фильтрах.
Если вы поставили ошибку в 0.0001, то sbf-фильтр, состоящий из 100 регистров увеличит ее до 0.01. 
Важно, что скорость проверки на вхождение в фильтр пропорционален кол-ву регистров и кол-во хэш-функций. 
А количество хэшфункций зависит от величины ошибки логарифмическим образом. Поэтому можете занижать значение ошибки без потери производительности.
Сам фильтр не корректирует "на ходу" ошибку при ресайзе, иначе нельзя гарантировать слияние двух фильтров с сохранением ошибки.
Поэтому занижайте ошибку во столько раз, во сколько максимум будет раздуваться регистр. 

# Потребление памяти

Для классического фильтра блума потребление памяти можно посчитать калькулятором https://hur.st/bloomfilter.
В ScalableBloomFilter потребление зависит от того, во сколько раз занижена ошибка одиночного фильтра. 
При использовании в одном ScalableBloomFilter до 1000 регистров (одиночных фильтров), 
один положенный хэшируемый объект будет занимать от 10 до 30 бит.

# Пример использования

У вас есть 100 млн идентификаторов мобильных устройств device_id . 
Каждый device_id это 32-байтная строка. Итого на старте вы имеете 3 Gb.
Допустим, вы хотите положить это в YT, составив регистры по 8 Мб (`2^-26`).  
Создав ScalableBloomFilter с ошибкой каждого ошибкой `2^-16`, 
вы затратите 16 бит * 100 млн = 200 Mb. Экономия в 10 раз.
