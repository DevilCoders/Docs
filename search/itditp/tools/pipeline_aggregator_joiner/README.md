## Pipeline aggregator + joiner

Практика показывает, что джоины истории занимают многие часы (или даже сутки), поэтому резонно ожидать, что пайплайн упадет в течение работы (e.g. случились учения на кластере, кончились чанки).

Целью создания пайплайна было обеспечение следующих двух свойств:
1. Данные кэшируются так, чтобы в случае падения надо было перезапускать как можно меньше операций. 
2. Когда пайплайн завершился (скорее всего после многочисленных перезапусков), лишних данных не остается

Вся информация за исключением пути выходной таблицы задается через protobuf-конфиг.
Запуск пайплайна выглядит так:
```./pipeline --config [PATH TO MY CONFIG] --output [PATH TO OUTPUT YT TABLE]```
Перезапуск пайпалайна (после устранения причин падения) выглядит таким же образом.

Существует также способ запустить пайплайн в интерфейсе Нирваны ([пример](https://nirvana.yandex-team.ru/flow/53f691d3-bdec-4cdb-a594-7d2fa6532f6a/ed276a91-6d39-45f1-8a77-9c4a44ac7738/graph)). В этом случае выходную таблицу генерит Нирвана и для запуска нужно вбить только текст конфига в кубик, создающий вход пайплайна. 

Промежуточные результаты зависят от:
1. Имени, creation time и modification time для **pool-table**
2. Имени, creation time и modification time для таблиц **param-tables** 
3. Параметров protobuf-конфига

Таким образом, если пользователь не меняет параметры конфига и не меняет входные таблицы, поддержка пайплайна в случае его падения не требует никаких усилий.
Но даже если пользователь меняет что-то из 1, 2, 3, перезапускаются только те успешные транзакции, которые зависят от измененных данных.

### Что значат параметры protobuf-конфига

```PipelineAggregatorJoinerConfig```

- **PoolTable**: path пула, к которому джоинится история пользователя
- **SortPool**: сортировать ли пул
- **CleanAggregatorOutput**: удалять ли вывод агрегатора после того, как пайплайн полностью успешно завершится
- **ParamTableConfig**: протобуф, описывающий param-table (о нем ниже)
- **UniqIDColumn**: поле с id пользователя, должно именоваться одинаковыо всех входных таблицы
- **TimestampColumn**:  поле с timestamp, должно именоваться одинаковыо всех входных таблицы
- **TmpDir**: директория, куда будет складываться весь кэш. **Note:** по дефолту это ```//tmp```, и в этом случае нет гарантии сохранности кэша при долгой работе пайплайна. Чтобы не гарантированно не потерять кэш, можно писать промежуточные данные в квоту.


```ParamTableConfig```

- **ParamTable**: путь до таблицы, историю с фичами которой мы агрегируем
- **SortParamTable**: сортировать ли ParamTable
- **Gap**: для данной записи в PoolTable история начинает собираться с момента Gap секунд назад
- **Split**: параметр для алгоритма агрегатора. Для каждой фичи подсчет истории разбивается на Split параллельных операций.
- **FeatureConfig**: протобуф, описывающий агрегацию конкретной фичи (о нем ниже)

```AggregateFeatureConfig```

- **Key**: так называется фича с таблице param-table
- **ToKey**: так будет называться поле с агрегированной историей по этой фиче
- **Limit**: для каждой записи в итоговой таблице будет собрана история из не более Limit последних фичей
- **EventType**, **EventColumn**: в историю будут входить только те записи, где в поле EventColumn записано значение EventType. Однако, если EventColumn == "",  то данное правило игнорируется.
- **ToHash**: вместо фичи будет записываться ее хэш
- **OutputType**:
     1. **REPEATED**: поле истории это JSON, например: 
        ```"{\"tokens\":[\"Садовый инвентарь и инструменты\",\"Текстиль\"]}"```
     2. **STRING**: поле истории это строка из сконкатенированных по пробелу фичей, например: 
        ```"Садовый инвентарь и инструменты Текстиль"```
     3. **LIST**: поле создается как NYT::TNode::CreateList();
