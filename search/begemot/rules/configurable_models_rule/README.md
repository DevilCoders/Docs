# Сервис моделей

Это сервис для вычисления gpu моделей в рантайме поиска.
Общий принцип разработки этого сервиса заключается в (по возможности) минимизации специфики предметной области.

Что умеет сервис:
- хостить модели в формате [bert_models](https://a.yandex-team.ru/arc_vcs/quality/relev_tools/bert_models) (более известный как .htxt)
- получать запрос в формате "вот для этих документов вычисли вон те модели, документы имеют такие входные параметры, и вот такие запросные".

## 1. Где находится в графе обработки запроса в поиске

Поисковая инсталяция (она же единственная, но в поиске всегда были амбициозные люди: они хотят сделать хорошо и для всех, а получается для поиска и с нюансами) живёт под сервисом models_proxy, который в свою очередь находится под средним метапоиском.

Поход в models_proxy является по факту частью *факторной стадии* обработки запроса.

- Средний после выполнения поисковой стадии формирует список docId документов, которые попадают в ранжирование на среднем
- Для них выполняется поисковые запросы и посылка в доп-источники, один из которых models_proxy
- models_proxy выполняет fetch-doc-data запросы за данными на базовые для получения документных полей
- после этого вызываются запросы 

Пример трейса:
https://setrace.yandex-team.ru/web/trace/1644611955682986-3185691502933813182-sas3-0670-75f-sas-l7-balancer-8080-BAL

В нём 2 типа запросов в cfg_models: за персональными gpu моделями и спец-моделями:
- CFG_MODELS
- CFG_MODELS_USERBODY

Запросов с типом CFG_MODELS несколько - потому что набор документов, отправленных на models_proxy разбился на под-батчи. Это делается так как в этом типе запроса вычисляются самые тяжелые модели и вычислять все документы на одной карте слишком долго.

Запрос CFG_MODELS_USERBODY один - там все документы входят в единый батч.

## 2. Дебаг запросов к сервису в проде и хамстере

**Вариант 1, через куку релевантности.**
Допишите к запросу ```&rearr=models_proxy_nocache_passthrough=ShowSubSourceRequestBody=CFG_MODELS``` (или аналогично ```CFG_MODELS_USERBODY```, ```CFG_MODELS_SPLIT```, если вас интересуют запросы соответствующего типа). Для каждого документа, вошедшего в запрос, в дереве запросов из куки появится дополнительный элемент:
https://jing.yandex-team.ru/files/grechnik/2022-03-18_16-35-04.png .

В запросе синтезируются cgi ```base64querypart=...``` и ```base64docpart=...```. Первый из них содержит часть запроса, общую для всех документов (кука релевантности умеет в дедубликацию на уровне отдельных cgi), второй - часть запроса, содержащую данные конкретного документа. Оба можно распаковать [во вьювере](https://relev-tools.viewer.yandex-team.ru/protobufs), выбрав тип ```TBegemotRequest```.

**Вариант 2, через setrace.**
Выполните запрос с параметрами (они должны дойти до среднего)
- ```&rearr=models_proxy_othercache_passthrough=LogSubSourceRequestBody=1``` - в трейсе (нужен режим plane-text) models_proxy будет тело запроса. распаковать его можно [во вьювере](https://relev-tools.viewer.yandex-team.ru/protobufs) выбрав тип ```TBegemotRequest```
- ```rearr=models_proxy_othercache_passthrough=LogSubSourceResponse=1```  в трейсе будет тело ответа. распаковать его можно тамже выбрав тип```TBegemotResponse```
- удобнее использывать вместе с ```url:``` чтобы уменьшить размеры запроса и ответа и увидеть данные для нужного вам документа

## 3. Параметры для управления

Основной параметр включения вычисления модели имеет формат 
- ``` scheme_Local/ModelsProxy/CfgModels/<DimensionId>=<model_id>:<targets_config>```
- Если вы скачиваете xlarge модели, то чтобы не ломать хамстер **обязательно** используйте бету factordev-xlarge.hamster.yandex.ru . Рпс на ней на уровне soy выставлен в 5 rps HAMSTER-202 . 
- [пример](https://a.yandex-team.ru/arc/trunk/arcadia/search/web/configurable_rearrange/configs/graphs/trunk_features_enabling_rearrs_conf.proto.txt?rev=r9115735#L48) ```scheme_Local/ModelsProxy/CfgModels/a=2022/01/aakshonov/2727189788:prod```
- кроме CfgModels, аналогично есть UserCfgModels и SplitCfgModels, отличающиеся набором передаваемых данных -
  UserCfgModels передаёт данные для вычисления userbody-моделей, SplitCfgModels передаёт запросный и документные эмбеддинги
- если вы руками задаёте cgi (а не пишете конфиг для ConfigurableRearrange), то *обязательно* нужны кавычки вокруг значения,
  ```&rearr=scheme_Local/ModelsProxy/SplitCfgModels/test="v3:prod"```: парсер ```&rearr=scheme_Local/*``` хочет json в качестве значения
  и в качестве любезности [разрешает не указывать кавычки вокруг alphanumeric строк](https://a.yandex-team.ru/arc/trunk/arcadia/library/cpp/json/fast_sax/parser.rl6?rev=r8701318#L253), но двоеточие (равно как и слеши и строки, начинающиеся с цифры) делает json невалидным.
  Для CfgModels есть альтернативный cgi ```&rearr=cfg_models=2022/...:prod```, который хочет строку, но недоступен из ConfigurableRearrange
- ```<DimensionId>``` - нужно для возможности задавать параметр более 1 раза, так чтобы они друг друга не перезатирали. В целом произвольная уникальная строка
- ```<model_id>``` - имя модели, допускается или StorageUniqId или <Layout>_StorageUniqId или имя сигнала из bundle.json 
- ```<targets_config>``` - имя конфига раскладки предиктов моделей по документным факторам на среднем
- есть встроенное значение ```<targets_config>=debug``` которое дописывает все предикты моделей в маркеры документа

## 4. Локальная разработка

## 5. Описание bundle.json

## 6. Логика кэша результатов

- для каждой модели собственный кэш
- в параметрах модели можно указать документные и запросные поля, значения которых будут использываться для вычисления ключа кэша
- кэш хранит хеш пары запрос-документ и результаты вычисления модели для данного документа
- схема ротации - LRU
- для отключения кэша прокиньте на срдений ```nocache=da```

## 7. Параметры и настройка деградации

- для каждой модели хранится load average для gpu-вычислений:
  - на основе статистики SlotCalcTimeMicroSeconds, возвращаемой применялкой модели
  - с экспоненциальным затуханием, "среднее время жизни" (за которое затухает в e раз) для определённости 10s
- load average для всех моделей, а также суммарная чиселка пушатся на графики
- для отдельно взятой модели можно настроить деградацию:
  - характеризуется тремя числами, момент начала деградации, момент максимальной деградации и коэффициент максимальной деградации
  - вычисляет по load average и числам выше значение GpuDeviceDegradationRatio и пишет его в контекст вычисления; что с ним делать, остаётся на усмотрение конкретной модели
  - пока load average меньше начала деградации, GpuDeviceDegradationRatio остаётся нулём;
  - когда load average больше максимальной деградации, GpuDeviceDegradationRatio выставляется в единицу минус коэффициент максимальной деградации;
  - в промежутке между началом и максимальной деградацией, GpuDeviceDegradationRatio вычисляется как линейная интерполяция
- для отдельно взятой модели можно (независимо) настроить жёсткий порог для load average, при превышении которого сервис прекратит расчёты этой модели, возвращая счётчик ошибок и нули вместо незакэшированных факторов; подтягивание из кэша расчётами не считается и (если кэш настроен для модели) продолжает работать
- для отдельно взятого запроса можно форсированно установить коэффициент деградации в заданное значение, причём независимо от того, настроена ли деградация в конфиге
  - ```&rearr=models_proxy_othercache_passthrough=degrade:CFG_MODELS=0.1``` устанавливает значение для CfgModels-подзапросов; аналогичный параметр есть с ```CFG_MODELS_USERBODY``` и ```CFG_MODELS_SPLIT``` (и даже для RTMODELS и RTMODELS_FPM, хотя тамошний сервис переданное ему значение не читает)
  - ```&rearr=models_proxy_othercache_passthrough=degrade=0.1``` устанавливает значение для всех подзапросов
  - ```&pron=nodegrade``` устанавливает значение в 0
  - если заданы несколько из параметров выше, приоритет берётся в порядке убывания специфичности: общепоисковый ```&pron=nodegrade``` игнорируется, из специфичного degrade:SOURCE и общего degrade выигрывает первый
  - вместо конкретного числа можно передать специальное значение ```floor``` (e.g. ```&rearr=models_proxy_othercache_passthrough=degrade=floor```), оно означает "посмотри в конфиг секции prod и возьми оттуда худшее разрешённое значение" (своё для каждой модели)
  - вместе с параметрами выше рекомендуется ```&rearr=models_proxy_othercache_passthrough=nocache:CFG_MODELS=1``` (или ```&rearr=models_proxy_othercache_passthrough=nocache=1```, или даже просто ```&nocache=da```), чтобы запрос действительно пересчитал факторы, а не подгрузил их из кэша
- для всего сервиса можно настроить отдельную деградацию:
  - характеризуется теми же тремя числами с тем же смыслом
  - возвращает наверх к среднему множитель, на который средний должен будет умножать размер PRS в будущих запросах
- если в конфиге для модели настроены и кэш, и деградация, то кэш этой модели вместе с посчитанными значениями хранит уровень деградации, с которым эти значения были посчитаны; запрос подгружает значения из кэша, только если их уровень деградации меньше или равен текущему
- если в конфиге для модели настроен кэш, но не деградация, то запросы с явно заданным ненулевым уровнем деградации могут читать значения из кэша (для согласованности с предыдущим пунктом), но не могут писать туда

# Приёмка и выкладка сервиса

Панель: https://yasm.yandex-team.ru/panel/ilnurkh.cfg_models?range=7200000



### Выкладка сервиса

1. запустите релиз в https://a.yandex-team.ru/projects/mmeta_model_calcers/ci/releases/timeline?dir=search%2Fbegemot%2Frules%2Fconfigurable_models_rule&id=release-cfg-models
2. CI-флоу соберёт артефакты, разложит их на престейбл машинку, обстреляет эту машинку потоком 10000 запросов, намайненных из прода, с сохранением ответов, после чего сравнит ответы с ответами параллельного обстрела хамстера этим же потоком и упадёт, если дифф слишком большой. Дождитесь окончания этого процесса и убедитесь, что ничего не упало.
3. Подтвердите коммит артефактов в прод и хамстер сервисы в релизном флоу https://disk.yandex.ru/i/qmEDrqJUihxCnQ
4. Запустите метарецепт [cfg_models_with_locks](https://nanny.yandex-team.ru/ui/#/services/dashboards/catalog/web_base/recipes/catalog/cfg_models_with_locks) в дашборде [web_base](https://nanny.yandex-team.ru/ui/#/services/dashboards/catalog/web_base/)
5. В нём выкладываются артефакты сначала на сасово хамстер. **Контролируйте** нормальность графиков на панели [cfg_models](https://yasm.yandex-team.ru/panel/ilnurkh.cfg_models?range=7200000)
6. Если всё ок - проинформируйте [чат релизов среднего](https://t.me/joinchat/CaUODkN2zNWU7HSBHK8V2Q), если за 5 минут не последовало просьб не катить, нет стандартных блокеров (работ, локов, и т.п.) - прожимайте выкладку далее

За координацию релизов отвественный [дежурный](https://abc.yandex-team.ru/services/mmeta-web/duty/?role=2853) по релизам среднего метапоиска, [чат релизов](https://t.me/joinchat/CaUODkKTwtMdwenQIkLLKQ).

В процессе релиза следует контролировать следующие панели:
- [cfg_models](https://yasm.yandex-team.ru/panel/ilnurkh.cfg_models?range=7200000)
- [web_models_proxy](https://yasm.yandex-team.ru/template/panel/web_models_proxy/geo=sas/)
- больше панелей [на вики](https://wiki.yandex-team.ru/users/sankear/devops-web/#grafiki)


### A. В няне подняты следующие сервисы:

Демон, запускающий код из этого правила собирается из этого таргета: https://a.yandex-team.ru/arc/trunk/arcadia/search/daemons/begemot/configurable_models

#### Prod:

- https://nanny.yandex-team.ru/ui/#/services/catalog/sas_mmeta_cfg_models/
- https://nanny.yandex-team.ru/ui/#/services/catalog/man_mmeta_cfg_models/
- https://nanny.yandex-team.ru/ui/#/services/catalog/vla_mmeta_cfg_models/

#### Hamster

- https://nanny.yandex-team.ru/ui/#/services/catalog/sas_mmeta_cfg_models_hamster/
- https://nanny.yandex-team.ru/ui/#/services/catalog/man_mmeta_cfg_models_hamster/
- https://nanny.yandex-team.ru/ui/#/services/catalog/vla_mmeta_cfg_models_hamster/
