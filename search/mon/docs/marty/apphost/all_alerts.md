# Как реагировать на платформенные алерты апхоста

Алерты хорошо, но еще полезно сразу открыть [системную панель](https://yasm.yandex-team.ru/menu/apphost/WEB/SYSTEM/).

Сообщите дежурному апхоста в телеге равносильно добавлению его в протокол.

При срабатывании любого алерта стоит ответить на следующие вопросы:
1. Локализуются ли проблемы до нескольких хостов?
2. Есть ли отрицательный тренд? Бывает, что график растет постепенно и уже давно, просто сейчас пробил алерт. Полезно понять, в какой момент началась проблема. 
2. Катится ли сейчас релиз апхоста или идет процесс препейринга?
3. Это продуктовый алерт или "железный" (память, сеть, цпу и т.п.)
4. Идут ли сейчас работы, учения или факап и часть дц закрыта.

Если любой алерт локализуется до нескольких хостов, то стоит их просто перевести в препейр и эвакуировать. Исключения - алерт на корки (там полезно понять, кто и почему коркается) и постепенные утечки (пункт 2), их эвакуировать сразу не надо. Если там постепенно утекает память или любой другой график, то важно тачку поизучать. Нужно завести тикет APPHOSTSUPPORT с графиками этой вершины.

## Срабатывание алертов при повышенной нагрузке

Алерты настроены так, что вполне могут звенеть при прогрузке (запланированной или не очень). На [системной панели](https://yasm.yandex-team.ru/menu/apphost/WEB/SYSTEM/) можно отследить текущую нагрузку по разделам ```requests *```.

Если на апхост действительно прилетело необычно много трафика, то нормально, что горят "железные" алерты. Понятно, что если уже почти 100% потребления памяти или цпу, то пора паниковать и призывать дежурных апхоста и веба, но если запас еще 10%-15% и нет отрицательного тренда, то все в пределах нормы.

Как реагировать на продуктовые алерты, описано дальше, в каждом конкретном алерте.

## Описание алертов

### Железные

#### cpu_throttled
##### cpu_throttled_cores 
##### cpu_throttled_cores_tmmv

Апхосту не хватает цпу. При нагрузке будет звенеть, сам по себе не является дизастером, но будет вызывать 5xx, фейлы вершин. Если звенит на "ровном месте", без релиза, нагрузки, на всех тачках и стабильно, то надо призывать дежурного апхоста. Если продуктовые мониторинги молчат, то никого будить не надо, локацию трогать тоже.

#### unistat_limit_usage_perc

Заканчивается лимит на головановские сигналы. Крайне сложно представить себе ситуацию, когда начинает звенеть без релиза апхоста или графов. Если релиза нет, то это странно, важны цифры, если они не достигают 100%, то ждет утра, иначе стоит будить дежурного апхоста. Опасность в том, что начинаются дропаться случайные сигналы, на которые завязаны другие, гораздо боле дизастерные алерты.

#### memory_anon_unevict_limit_usage_perc

Апхост объелся памяти. Возможны два сценария, память растет вместе с трафиком, либо давно и постепенно утекает. В первом случае нормально, что она не возвращается к исходным значениям после ухода трафика, так устроен аллокатор. Так или иначе стоит позвать дежурных апхоста, чтобы подебагали утечку, либо катнули зеродиф и отпустили память. Локацию закрывать не надо, будить только в случае утечки.

#### portoinst_oom

Должен срабатывать только после срабатывания memory_anon_unevict_limit_usage_perc, как на него реагировать описано выше. Если срабатывает без него - очень странно и надо расследовать. В рабочее время - призовите дежурного апхоста. Ночью и в выходные, если 1-2 хоста - в препейр их, если проблема массовая - будите дежурного. Закрывать локацию стоит, если там прям 5 оомов в секунду.

#### logs_volume_usage_perc, root_volume_usage_perc, work_dir_volume_usage_perc

Сторадж забился. Разложить по хостам, проверить не рецидив ли SPPROBLEM-103 и SPPROBLEM-391. Если да, починить на затронутых хостах: `sudo project_quota check /ssd/db/iss3/volumes/$(portoctl vlist | grep /ssd/db/iss3/volumes/ISS-AGENT_ | grep production-app-host | tail -n1 | cut -d"/" -f6)/logs`. Если произошло в рабочее время и резко, скорее всего кто-то что-то делает грязными руками, зовите дежурного апхоста. Если проблема массова - зовите дежурных апхоста. Ночью будить не надо, днем в выходной можно и позвонить. Если забился work_dir_volume_usage_perc, там уже за 90% и проблема массовая, уже страшно, можно и ночью позвонить.

#### cpu_usage_90

Использование цпу в 90 квантили. Увы, довольно шумная штука, особенно во вла, где хосты иногда и по 500% юзаджа выдают, хотя отлично в этот момент работают. При прогрузках точно может стрелять, внезапно без трафика скорее нет. Если горит алерт, то плохо 10% хостов, значит проблема уже точно массовая. Если горит алерт сам по себе - можно забить до утра, не трогать локацию, позвать дежурных апхоста в рабочее время (в выходной просто написать в телеге). Если в сочетании с цпу эксидедами, крит фейлами, то проблема скорее есть и надо вызвонить дежурного апхоста. Если видны показы тыкв или падение качества, то надо закрыть локацию.

#### cores

Что-то коркнулось. Если катится релиз и корки с каждого хоста по одной - скорее всего шатдаун. Занести дежурному апхоста. Если было пару корок с нескольких хостов - нет повода для паники - терпит до утра, сообщите в личку дежурному. Если много корок, но с одного хоста, скорее всего RTC проблема, занести им, попытаться погасить хост (это не всегда получается). Если корок много, с множества хостов и они стабильно стреляют - вызванивайте дежурного апхоста.

На хосте: `dmesg -T | grep app_host | less +G` и найти по времени подходящую корку.

#### io_throttled, io_throttled_ssd

Что-то насилует диск. Апхосту для работы это вообще не критично, так что скорее всего это соседи + логи. Если одиночные хосты, то погасить и эвакуировать. Если проблема массовая - пишите дежурному. Будить никого не надо, локацию закрывать тоже.

#### net_utilization

Внезапно кончается сетка. В нормальной ситуации, должно быть следствием наплыва трафика, либо релиза. Источник трафика надо понять - тут дежурный веба поможет. Если это релиз маппингов, то откатить, релиз бинаря веба мы и сами откатим, главное занести дежурному. Если стреляет внезапно - как обычно. 1-2 хоста эвакуировать, проблема массова - писать дежурному. Если там уже под 90% или видны крит фейлы и любые другие продуктовые алерты - будить дежурного, локацию закрыть.



### Продуктовые

#### SELF_CS_CriticalDependencyErrors

Подробнее в разделе "Алерт на критические фейлы"

#### SELF_CS_CpuExceedErrors

Срабатывает автодеградация по CPU. Для балансера выглядит как 502. Если стреляет на прогрузке - это норма, часть хостов имеют так себе соседей и им тяжко. Если срабатывает внезапно, нужно разложить по хостам и понять масштаб проблемы. Если хостов 1-2 и там виден большой цпу юзадж - в перпейр их и эвакуировать. Если проблема массова - звать/будить дежурного апхоста. Локацию закрывать не надо, не означает напрямую, что пользователи страдают.

