# Стабильный сервис 

Стабильным можно назвать сервис, который кроме того, что доступен 99+% времени, всегда ведет себя предсказуемо, имеет стабильную инфраструктурную архитектуру,постоянно неизменный цикл разработки, оснащен системой мониторинга и алертига, а также позволяет снизить ущерб выполнением регламентных действий в аварийной ситуации.

На этой странице приведены критерии, рекомендуемые для повышения надежности вашего сервиса.

## Релизы

 - Настроен релизный цикл - не надо руками подкладывать файлки на серверах.
 - Существует тестинг и престейбл, тестовый контур полностью независим и не ходит в боевое окружение
 - Деплой полокационный, с подтверждением деплоя в локацию - потерять локацию не так страшно.
 - Релизный процесс незаметен для конечных пользователей: 
    - Не приходится снимать локацию руками
    - На мониторингах нет флапов
    - Нет деградации сервиса
 - Существует единая схема быстрого отката изменений на кластере. 
    - Можно быстро понять куда откатываться, кластер готов к откату и нет необходимости заново готовить данные и терять на этом драгоценное время.
    - Откат это привычная и относительно безболезненная операция, в идеальном слуачае автоматизированная чтобы минимизировать риск ручной ошибки. 
    - Во время отката весь кластер замирает и минимизируется риск коллизий. 
    - Нет автоматики которая противоречит единой схеме.
 - Данные и бинари должны быть совместимы в обе стороны (новые данные <-> старый код; старые данные <-> новый код).
 - Совместимость данных и релизов разных версий проверяется автоматическими тестами. Например, с помощью имитации релиза или отката. В идеале должна быть проверка возможности отката при нескольких релизах.
 - Большой сервис выкатывается частями, а не монолитом. При этом, должна быть проверка совместимости версий различных частей.
 - В больших сервисах стоит разделить выкатку быстрых данных и бинарей. Данные и бинари необходимо тестировать.
 - Если используется практика релизов через флаги, ручная их правка должна быть запрещена. На изменение флагов должны быть тесты.
 - Все события и релизы передаются в infra/timeline и настроен пресет

### Релизный цикл

 - #### Testing

**Testing** - В этой инсталляции вы тестируете поведение своего приложения до релиза и проверяете его работоспособность перед тем как его увидят пользователи. Отказоустойчивость здесь не критична, можно ограничиться даже одним инстансом на компонент, но параметры инстансов рекомендуется делать аналогичными тем, что работают в продакшен-инсталляции.

 - #### Prestable

**Prestable** - инсталляция обычно используется для проверки работы приложения на некоторой части живых пользователей или на бета-тестерах, перед раскаткой на всю аудиторию. Это может быть как уменьшенная копия продакшена, так и отдельный компонент, на который отводится какой-то процент трафика.

Так как престейбл-приложение будет видно пользователям, на него начинают распространяться требования по надежности:
    
1. Документация, ответственные и алгоритм починки
2. Запас мощности
3. Возможность быстро снять трафик в случае проблем
4. Возможность переживать отказ оборудования

- #### Stable

**Stable** - это инсталяция, которая отвечает пользователям. На приложения в этой инсталляции в полной мере действуют все требования обеспечения надежности сервиса.

## Мониторинг

 - У сервиса выделены основные функциональности, на эти функциональности и пользовательские сценарии настроена система мониторинга и нотификации.
 - Для всех функциональностей есть disaster графики и соотвествующие им алерты, переданные в дежурную смену.
 - Задан вес вертикали (горизонтали) и всех ее функциональностей для расчёта метрики YDT.
 - У инстансов сервиса есть логи и организована их ротация по времени/месту.
 - Есть дашборд на котором есть все основные срезы сервиса с диагностическими графиками и дизастер-алертами: Мониторинги ошибок,  Мониторинг качественных и количественных показателей, Полокационные срезы, Алерты сигнализирующие о негативном влиянии на пользователей.
 - Диагностическая панель передана в дежурную смену.
 - Команда знает работах которые могут повлиять на сервис.
 - Команда знает про релизы когда что и куда катилось.
 - Мониторинг регулярно валидируются: 
    - Раз в полгода анализируется общая алертная панель.
    - В рамках разбора инцидентов ретроспективно актуализируются некорректно работающие алерты.

## Работа с инцидентами

 - Ответсвенные:
    - У вашего production-сервиса должны быть ответственные - люди, которые будут получать алерты от мониторингов и предпринимать оперативные действия по устранению проблем вашего сервиса.
    - Ответственные за сервис и их телефоны должны быть указаны в вики сервиса, чтобы их легко можно было найти.
 - Дежурства:
    - Организованы дежурства в команде сервиса. График дежурства передан в дежурную смену.
    - Дежурный сервиса способен решать типовые проблемы по инструкции.
    - Описан процесс эскалации для нетипичных проблем.
 - Существуют каналы для экстренной координации пример описания сервиса для дежсмены.
 - Работа над инцидентами ведется в очереди SPI.
 - Команда использует протоколы работы с инцидентами.
 - Ведется работа по выделению проблем. Количество новых SPProblem > N.
 - Разработка/эксплуатация/менеджмент сервиса знает своих клиентов и сервисы от которых зависит.

## Документация

 - У сервиса есть документация.
 - У сервиса есть иструкция починки типовых проблем.

## Тестирование

 - Нагрузочное тестирование:
    - Регулярные прогрузки.
    - Корректно настроен таргет. Суммарный трафик должен быть ниже таргета.
    - 70% успешных прогрузок локаций выше таргета (график в stat).
    - Сервис выдерживает -1 ДЦ.
    - Есть регулярные учения по закрытию ДЦ.
 - У сервиса есть автотесты.
 - У сервиса есть фаззинг(fuzzing) тесты.

## Балансировка

 - У сервиса есть инструмент управления нагрузкой L7, с возможностью изолировать локацию от пользователей в случае инфраструктурных проблем или плохого релиза.
 - Если ваш проект использует L7-балансер, то этот балансер не должен быть коммунальным. Так вы не будете зависеть от нагрузки, создаваемой соседями по балансеру и сможете, при необходимости, добавить дополнительные инстансы балансера.
 - Инстансы L7 балансера нужно выставить в тех же датацентрах, что и инстансы приложений, это один из шагов избавления от кросс ДЦ хождений при прохождении запроса.

