# Постановка задачи
## Какие задачи мы решаем?
1. Параллельный запуск N мини-пайплайнов вида "preprocess -> train -> apply -> metric_eval"
2. Оптимизация использования ресурсов для запуска N мини-пайплайнов. Например, кросс-кеширование между этими запусками
3. Stacking моделей: обучение первой модели, ее применение на каком-то логе и обучение другой модели поверх уже выученной
4. Абстрактно: создание асинхронного обучатора моделей, способного в рамках одного запуска работать с моделями разной скорости обучения, скорости применения, стабильности

## Какие свойства должны быть у решения задачи?
3. Настраиваемая политика ретраев: кастомный код для обработки тех или иных ошибок (а не только число тупых ретраев)
4. Возможность корректного завершения работы пайплайна по кнопке (не sigkill всех процессов, а сигнал, который можно обработать)
5. Асинхронная обработка моделей, отсутствие bottleneck'ов. Даже для одной и той же модели дисперсия скорости обучения в Нирване может быть огромной. Причины разные: от "зашедулили на старую тачку" до "агрессивные соседи, уничтожающие диск и сеть". Модели должны обрабатываться по мере завершения, вот такие вот stragglers не должны становиться bottleneck'ами
6. Обработка неретрабельных падений моделей: не отстреливать весь пайплайн
7. Жить целиком и полностью в репозитории, никаких нетестируемых сущностей во внешних сервисах. Все живет в репозитории, весь пайплайн целиком можно задеплоить по кнопке
8. Полноценный режим validate (аналог в старом ml-engine - ml-emulate-task). У всего пайплайна целиком обязан быть режим validate, в котором он по-максимуму прогоняет весь тот же код и отлавливает ошибки. Режим emulate должен запускаться локально и отрабатывать за секунды, выводя пользователю всю необходимую для отладки информацию
9. Независимое и управляемое кеширование. Если для какой-то сущности необходим кеш, его надо делать вручную и его надо делать by-value. Автоматическое кеширование на основе json'ов, как это сделано в Нирване, на наших аппетитах выливаетсы в неуправляемую помойку ресурсов, непонятно, что можно удалять, что нельзя
10. Покрытие CI тестами
11. Локальный запуск любого блока
11. Создание библиотеки блоков, которые можно соединить вместе и получить асинхронный пайплайн
12. **Абстрагирование от асинхронности**. Несмотря на то, что код работает асинхронно, для составления пайплайна из базовых блоков пользователю нужно писать **только** синхронный код. Предполагается, что пользователь сможет по своим нуждам быстро менять что-то в своих пайплайнах. Быстро разрабатывать и менять асинхронный код очень сложно.

## Пример задачи, которая уже решена
Задача: обучить N онлайновых нейронных сетей, проэвалить их на двух видах логов (train log и matrixnet log), поверх предсказаний из train запустить metric eval, поверх логов для матрикснета запустить матрикснет, сагрегировать метрики модели и матрикснета для каждой модели в один отчет.

Выглядит это так. Есть 5 асинхронных процессоров-акторов
* **PyTorchTrainer**: обучение онлайновых нейронных сетей
* **TrainApplier**: применение обученной торчовой модели на лог, на котором модель училась, со сдвигом в будущее
* **CatboostApplier**: применение обученной торчовой модели на лог, на котором будет учиться катбуст, со сдвигом в будущее
* **MetricEvalCalcer**: посчитать метрики торчовой модели на train логе
* **CatboostTrainer**: выучить катбуст с моделью-фактором

Выглядит это как вот такой граф:
```
                              |-----------------------------|       |------------------|
                       /----> |   PyTorchApplier[TrainLog]  | ----> | MetricEvalCalcer |  
                      /       |-----------------------------|       |------------------|
                     /
|----------------|  /          
| PyTorchTrainer | -
|----------------|  \
                     \
                      \       |-----------------------------|       |------------------|
                       \----> | PyTorchApplier[CatboostLog] | ----> | CatBoostTrainer  |
                              |-----------------------------|       |------------------|
```

Сначала на вход PyTorchTrainer подается весь набор моделей, который хочется выучить. Он запускает N независимых графов. Затем, как только какой-то из графов заканчивает работу, его результаты тут же подаются на вход двум PyTorchApplier'ам.

PyTorchApplier устроен следующим образом: он за один момент времени владеет только одной операцией применения модели. Ему на вход приходит первая модель, он запускает применение и ждет, пока применение не закончится. Во время применения модели ему асинхронно на вход поступают другие обучившиеся модели - он их складывает в ящичек. Как только применение предыдущих моделей закончилось, он берет все модели из ящичка и разом их применяет. Также он реализован так, что все модели применяются к одной и той же табличке для экономии диска на YT.

MetricEvalCalcer и CatBoostTrainer - как только получают на вход новые примененные модели, тут же запускают независимые metric_eval'ы и катбусты соответственно.

По большому счету, в данном пайплайне только у PyTorchApplier есть какая-то нетривиальная логика по кешированию, все остальные блоки устроены довольно просто.

# Реализация
Для реализации асинхронной обработки выучившихся моделей, применяшек и т.д. напрашивается модель акторов. Каждый актор делает какую-то одну большую вещь, например, обучение модели или применение модели. Эта модель действительно хорошо подходит, но у нее есть несколько недостатков:

1. Главный недостаток - обработка только одного сообщения за раз и отсутствие асинхронности внутри одного актора (я считаю, что это неразрывно связанные требования). Рассмотрим пример с применением модели. Сейчас при переборах параметров мы часто варим N независимых таблиц. Это очень сильно бьет по квоте диска и выливается в общие проблемы для всех в отделе. Одновременное применение N моделей в одну табличку решает эту проблему, но нарушает базовый принцип актора
2. Возможность спавнить других акторов в ответ на какое-то сообщение. Я считаю, что при экспериментировании с обучением моделей структуру можно продумать и заранее, без динамизма. Более того, возможность спавнить акторов внутри акторов нарушает принцип "абстрагировать от асинхронности"
3. Режим validate. Режим validate предполагает, что можно вообще всю систему запускать в двух режимах. Допустим, хотя бы один из акторов не поддерживает такой режим, в этом случае все сломается. Значит, режим валидации необходимо вшивать в самую базовую абстракцию, в сам базовый актор
4. Модель акторов (а также, если я правильно понял, большая часть реализаций этой модели) продвигают идею "все есть актор". То есть, при составлении пайплайна из уже имеющихся блоков надо будет писать другие акторы -> писать и дебажить асинхронный код -> еще одно нарушение принципа "абстрагировать от асинхронности". Пользователь должен уметь составлять свой пайплайн из акторов при помощи **только** синхронного кода
5. У запуска пайплайна для оффлайн эксперимента есть четко заданное начало и четко заданный конец: все модели обработаны. Классические микросервисы запускаются в режиме run_forever. У нас же совершенно другой кейс: рантайм четко знает, когда вся работа завершена и можно убивать всех акторов и завершать работу системы

Реализация будет несколько модифицированной моделью акторов. Общая суть останется такой же:
* Весь пайплайн строится из некоторых объектов с одинаковым интерфейсом
* Эти объекты асинхронно обмениваются друг с другом информацией
* Эти объекты ничего не знают про существование друг друга

Добавится лишь список требований конкретно к библиотеке пайплайнов:
* Полностью синхронный API. Если пользователю таки захотелось написать код на асинхронном API, то это должно быть что-то из ряда вон 
* Группирование сообщений для обработки
* Корректное завершение по кнопке
* Режим валидации - first-class citizen


## Построение нужной реализации
### Базовый рантайм
Разберемся с базовым рантаймом, мы ведь хотим асинхронной работы акторов с синхронным API. Лучшим кандидатом является библиотека [asyncio](https://docs.python.org/3/library/asyncio.html) и корутины, потому что:
1. Корутины работают в одном потоке - значит, любой синхронный код органично встраивается в корутинный код
2. При желании, у корутин есть полноценное API для запуска какого-то **синхронного кода** в потоке или в подпроцессе

В совокупности эти пункты означают, что достаточно разработать базовые классы акторов, работающие на корутинах, и отдать пользователю подклассы с **синхронным API**. Эти функции будут запускаться в подпроцессах, обеспечивая честный параллелизм, к примеру, запуск N параллельных моделек или N map-операций без блокирования всего рантайма. То есть, **даже при реализации** базовых блоков можно обойтись без асинхронного кода (не всегда это можно сделать, но в большинстве кейсов можно)

Поскольку в аркадии большая часть инфраструктурного кода написана на python2 и никто не собирается даже не то чтобы переписывать, а просто хотя бы разбираться в python3, то специально для вас существует бекпорт asyncio - trollius, [лежит в аркадии](https://a.yandex-team.ru/arc/trunk/arcadia/contrib/python/trollius).

### Рантайм пайплайна
Вспомним требования:
1. Известный старт, известный конец
2. Корректное завершение по кнопке
3. Группирование сообщений для обработки
4. Не даем API для создания других акторов внутри актора **в рамках текущего рантайма**.
5. По-максимуму пишем всю асинхронщину за пользователя

Из последнего пункта следует, что мы не должны давать пользователю изнутри одного актора обращаться к другим акторам, в частности, дергать их методы для пересылки сообщений. Таким требованиям может удовлетворять только декларативное задание всех акторов и взаимодействий между ними. Проще всего это сделать с помощью [графа зависимостей](https://a.yandex-team.ru/arc/trunk/arcadia/ads/nirvana/automl/lib/batch_processor/execution.py?rev=5322612#L31).

В граф можно засунуть либо изолированный процессор, либо связку процессоров и **функцию-преобразователь**. Функция преобразователь - это мост, преобразующий выход одного процессора во вход другого. Полностью синхронное API.

Далее можно запустить функцию [run_batch_processors_graph](https://a.yandex-team.ru/arc/trunk/arcadia/ads/nirvana/automl/lib/batch_processor/execution.py?rev=5322612#L53).

В графе можно добавлять произвольное число входов в процессор и произвольное число выходов из него (подписчиков). Реализуется это через вызовы функции [add_connected_processors](https://a.yandex-team.ru/arc/trunk/arcadia/ads/nirvana/automl/lib/batch_processor/execution.py?rev=5322612#L35) с одним и тем же инстансом ```AbstractBatchProcessor``` в качестве source или destination. Дублирующиеся ребра добавлять нельзя.

### API BatchProcessor
Окей, мы разобрались с рантаймом и тем, как строить из готовых батч процессоров пайплайны. Большинству **пользователей** этого будет достаточно, описание API - исключительно для разработчиков дополнительных процессоров.

#### Validate режим
Сразу разберемся с режимом валидации: каждый актор наследуется от класса с примерно следующим содержанием:
```python
class ValidateCallable:
    def __init__(self):
        self._validate_mode = False

    def set_validate_mode(self, mode: bool) -> None:
        raise NotImplementedError
    
    @property
    def validate_mode(self) -> bool:
        return self._validate_mode
```
Полная реализация [тут](https://a.yandex-team.ru/arc/trunk/arcadia/ads/nirvana/automl/lib/util/validator.py), содержит набор костылей для всяких частных случаев типа "а что если мы возьмем frozen dataclass, наследуемый от ValidateCallable".

#### API пересылки сообщений

Мы хотим, чтобы актор мог обрабатывать несколько сообщений за раз. Соответственно, у него будет метод, принимающий сразу пачку задач:
```python
import trollius
from typing import Set

class AbstractBatchProcessor:
    @trollius.coroutine
    def feed_new(self, *job_descriptors) -> None:
        pass
```

```*job_descriptors``` - это инстансы каких-то классов. Каждый инстанс описывает одну задачу (или одно сообщение в терминах акторов). ```AbstractBatchProcessor``` сам по себе не накладывает каких-либо ограничений на реализацию этих инстансов, но вообще хороший тон - задать конкретный тип этих инстансов, чтобы ваш ```BatchProcessor``` принимал строго типизированные дескрипторы задач.

Далее, нам нужен метод для получения готовых на данный момент результатов. Результат ```AbstractBatchProcessor``` - это инстанс [BatchProcessorResultHandle](https://a.yandex-team.ru/arc/trunk/arcadia/ads/nirvana/automl/lib/batch_processor/interface.py?rev=5322612#L15). Содержит всего два поля: ```descriptor``` и ```future```, содержащая результат. Гарантируется, что Future находится в состоянии completed и у нее корректно будут работать методы exception(), cancelled() и result().

Получить можно методом ```get_ready```:
```python
import trollius
from typing import Set

class AbstractBatchProcessor:
    @trollius.coroutine
    def get_ready(self) -> Set[BatchProcessorResultHandle]:
        pass
```

Данные методы позволяют реализовать примерно любой стиль обработки задач. Хочется - можно агрегировать сообщения до потери пульса и обрабатывать раз в сутки, хочется - можно немедленно запускать изолированный обработчик задачи (это будет максимально похоже на актор), можно обрабатывать пачками один за другим.

#### API убийства

Чтобы прибить ```AbstractBatchProcessor```, нужно вызвать метод [kill()](https://a.yandex-team.ru/arc/trunk/arcadia/ads/nirvana/automl/lib/batch_processor/interface.py?rev=5322612#L75)

#### API остановки

Чтобы остановить прием новых джобов и, таким образом, перевести процессор в режим "дорабатывания чего осталось", надо вызвать [stop_receiving_new_jobs()](https://a.yandex-team.ru/arc/trunk/arcadia/ads/nirvana/automl/lib/batch_processor/interface.py?rev=5322612#L85).

**ВАЖНО**: сейчас этот метод используется в рантайме для управления исполнением графа. Очевидно, что рантайм можно написать и без этого метода. Достаточно лишь:
1. Знать, что в какой-то момент времени ни у одного процессора не осталось джобов
2. Уметь проверять, что никакие данные прямо сейчас не пересылаются.

Т.е. достаточно только метода ```has_unfinished_jobs```. Но:
1. Некоторым процессорам, наверное, захочется подождать всего
2. Мне было лень

### Как исполняется граф

Сначала граф декларативно строится пользователем. Граф зависимостей - это лишь взаимосвязи consumer'ов и producer'ов. Затем пользователь запускает его, скармливая ему ```feed_dict```. ```feed_dict``` - это словарь вида ```{batch_processor_instance -> [job_descriptors]}```. На старте рантайм берет целиком списки из ```feed_dict``` и скармливает их соответствующим batch_processor'ам. Дальше он начинает yield-ить результаты из них и пересылать дальше согласно их связям.

Исполнение прекращается, когда все процессоры находятся в состоянии ```proc.stopped_receiving_new_jobs() and not proc.has_unfinished_jobs()```.

Если вылетает исключение, пересылка сообщений прекращается, для всех процессоров вызывается метод [kill()](https://a.yandex-team.ru/arc/trunk/arcadia/ads/nirvana/automl/lib/batch_processor/interface.py?rev=5322612#L75).

## Как перевести граф в Нирвану

Требуются три вещи:
1. Написать абстрактную сетевую оболочку для batch processor, чтобы сервер умел автоматически генерироваться из инстанса класса
2. Обеспечить API для сериализации/десериализации дескрипторов задач и результатов
3. При реализации надо написать соответствующий staticmethod с vh.lazy в каждом классе. К сожалению, из-за наличия всяких токенов автоматически генерировать этот метод с помощью метаклассов, скорее всего, не выйдет. Но можно автоматически сгенерировать точку входа с запуском сервера и т.п., чтобы упростить жизнь пользователю.
4. Заимплементировать streaming выходы в Valhalla

## Базовые реализации ```AbstractBatchProcessor```

Дабы дать пользователю чуть более удобное API для наследования, сделаны базовые реализации для следующих схем:
* [SeparateBatchProcessor](https://a.yandex-team.ru/arc/trunk/arcadia/ads/nirvana/automl/lib/batch_processor/separate.py?rev=5322612#L14): независимое исполнение (почти как actor)
* [SequentialBatchProcessor](https://a.yandex-team.ru/arc/trunk/arcadia/ads/nirvana/automl/lib/batch_processor/sequential.py?rev=5322612#L30): исполнение пачками. Как только исполнение текущей пачки закончилось - начинается исполнение всего, что накопилось до этого

# Пример того, как пользователь будет собирать пайплайн

https://a.yandex-team.ru/arc/trunk/arcadia/junk/alxmopo3ov/torch_pipeline/trainer.py

Пайплайн читает из конфига торча все эвал конфиги, для каждого создает отдельную джойн табличку, джойнит и считает метрики. Метрики складывает по специальному пути