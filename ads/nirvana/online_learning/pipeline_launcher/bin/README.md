# Обучение модели

## Создание таска
Чтобы запустить обучение, нужно составить json с полным описанием модели, логов и пр. (подробнее в task_json_description.md), 
либо же папку с json-ами. Папку создавать удобно, если вы делаете перебор параметров для некоторой модели. Пример создания папки
лежит в examples/create_parameter_selection.

Чтобы было проще, возьмите my_first_task.json из examples и переопределите нужные параметры

## Запуск 
Обучение модели делится на две стадии: обучение на исторических данных и обучение в реалтаймовом режиме на свежих логах

### Обучение на исторических данных
Здесь создается один большой граф, в котором быстро учится онлайн модель. На sandbox отвозятся дампы dmlc для каждого часа
(дампы dmlc нужны для применения модели к логу)

### Обучение в реалтайме
Здесь каждый час будет создаваться новый граф, отвечающий за обработку одного часа логов. После того, как граф отработает (т.е. модель выучится), 
для свежего дампа dmlc будет сварен dump.txt (формат линейных моделей, который нужен движку БК), а также посчитаются метрики в дашборде

Общая схема запуска такая: 
1. Создается один граф обучения на исторических данных, который берет все доступные на данный момент логи
2. Далее начинает работать дообучение в реалтайме для всех логов, которые появятся после

Дообучение в реалтайме нужно только для production моделей, которые будут ездить в движок. Если нужно сделать пробный запуск, 
то надо указать флаг --offline_emulation True - тогда произойдет только обучение на исторических данных. При этом у вас будут
сварены все часовые дампы, таким образом, можно будет применить модель к логу и обучить матрикснет (или посчитать метрики для перебора параметров).

Команда для запуска:
./pipeline_launcher --sandbox_token <<ваш sandbox token>> --offline_emulation <<True|False>> --task <<путь либо до json, либо до папки с json-ами>>

### Применение модели к логу для матрикснета
Чтобы применить онлайн линейную модель, есть библиотека ads/nirvana/online_learning/spiral_offline_apply
Примеры запуска применялки лежит в examples/launch_spiral_apply

В принципе, вам здесь потребуется тюнить только поле shift - это сдвиг в часах для применения модели.
В продакшене логи для обучение, как и сами модели, будут ездить с задержкой - ожидаемое время задержки нужно указать в поле shift.
Например, для JoinedEFH: в среднем 8 часов отставание самого лога + в среднем полчаса обучение модели = 9 часов задержки, shift = 9

shift - это float, т.е. если нужна задержка в полчаса (например, для bs-chevent-log), нужно указать shift = 0.5

