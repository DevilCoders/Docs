# Как пользоваться применялкой.

## Общий интерфейс команды

screen -L ./spiral_offline_apply --apply_conf <<path_to_apply_json_conf>> --mode <<mode>>

### Mode
* apply - применить модели к логам
* factoreval - взять директорию с примененными табличками и запустить factoreval
* all - сначала применить, потом запустить factoreval

## Описание json-файла для применения модели
Пример можно найти в ads/nirvana/online_learning/spiral_offline_apply/bin/example.json

    // Описание json
    {
      "tasks": [
        Список локальных путей к таскам моделей. Здесь можно указывать как отдельные json'ы, так и директории со списками тасков.
      ],
      "filter_unfinished": true/false. Если true, то берет только те таски, чьи графы в нирване полностью отработали
      "shifts": [0, 1, ...] - список shift'ов. Можно указывать float - например, чтобы сделать сдвиг в 1.5 часа. указываем shift 1.5
      "pools": [
        Список пулов. Число потоков при применении = число пулов * 10. Рекомендуется указывать хотя бы 2-3 пула.
        Можно создавать фиктивные пуле в research, пример: ["alxmopo3ov", "alxmopo4ov", "alxmopo100500ov"]
      ],
      "mapper_memory_limit": 137438953472 Лимит по памяти в операциях. Если падает по OOM - лучше увиличить.
      "log_mask": маска логов, к которым мы будем применяться, для get_logs_regexp_time
      "start_date": start_date в get_logs_regexp_time
      "end_date": end_date в get_logs_regexp_time
      "result_yt_dir_name": Директория в YT, куда складываются таблички с примененными моделями
      "batch_size": 30 - сколько моделей помещается в одну операцию. Если число моделей > batch_size, то каждый час будет обрабатываться несколько раз
      "interrupt_on_fail": true/false - если true, то в случае любого Exception'а при применении просто выводим его в stderr и скипаем
      "table_interval": "d" - Тип интервала для таблички. Используется, чтобы эффективно пофильтровать таблички для каждой модели еще до применения. Примеры:
        * EFHWClicked05NS - "d"
        * EFHClicked05NS - "d"
        * bs-chevent/1h - "h"
    
        Если указать здесь null, то каждый час каждой модели будет пытаться примениться ко всем достапным логам и на месте
        грепать нужное время. Это неэффективно.
      "get_from_sandbox": true/false, если true - будет пытаться отгрузить дампы с sandbox
      "get_from_yt": true/false, если true - будет пытаться отгрузить дампы с YT.
    
      // Далее идут поля для factoreval
    
      "result_metrics_path": Локальный путь к файлу, куда сохраняются метрики
      "weight_field": Поле для взвешивание в factoreval. Для EFHWClicked05NS "HitWeight", для EFHClicked05NS - null
      "factoreval_group_key": Ключ для групповых loss (ll-max, ll-pair). По дефолту HitLogID.
      "factoreval_slices": [
        Список слайсов для factoreval. По умолчанию:
        ["hour_id"], (почасовая статистика)
        ["ProductType"]
      ]
    }

## Виды применений: get_from_sandbox и get_from_yt

Сейчас реализована следующая логика: поскольку применение через get_from_yt в несколько раз быстрее, чем get_from_sandbox, то
библиотека сначала старается выудить дампы из YT, а если ей это не удалось (ну или если get_from_yt=false), то она достает
дампы с sandbox.

## Управление памятью: batch_size и mapper_memory_limit

Чтобы особо не заморачиваться, советую трогать параметры batch_size и mapper_memory_limit только в случае необходимости.
Общее правило: увеличивая batch_size, не забываем увеличивать mapper_memory_limit

## Перезапуск в случае падений

В библиотеке реализована следующая логика: если указать в result_yt_dir_name директорию, которая уже существует, то
библиотека попытается найти там уже примененные таблички по специальной маске имени и будет запускать применение
только для тех дат, для которые она не нашла табличек.

Проще говоря - если что-то упало, то можно перезапустить и оно начнет работу с того места, на котором остановилось.