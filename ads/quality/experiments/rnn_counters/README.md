# RNN-счетчики
Много сил потратили на ручное производство счетчиков по различным ключам для разработки факторов. Отдельной категорией выступают счетчики по ключу (пользователь, что-нибудь) или просто по ключу (пользователь). Именно такие счетчики могут помочь нашему прогнозу замерить количество и качество взаимодействия пользователя с объектами наших рекомендаций.
Отсюда появилась идея обучать счетчики с помощью нейросетей.
А именно: у нас будет в каком-то виде рекуррентная нейросеть, которой в инпуты будут подаваться те события, которые мы используем для счетчиков в виде векторов.
Пример вектора события для логов показов и кликов рекламы: `[0, is_click, is_show]`, `[time_from_last_event, 0, 0]`, то есть тут отдельными событиями выступает то, что прошло какое-то время с последнего события и отдельными событиями поступают сами клики и показы по рекламе.
Через нейросеть проходит весь поток событий по данному ключу. Например, вторым ключом помимо пользователя мы можем выбрать ключом домен рекламодателя и тогда для каждого пользователя мы будем хранить n состояний нейросетей по разным доменам и обновлять их по мере прихода новых событий по соответствующему домену.
В момент предсказания для объекта X мы будем брать состояние нашей сети по ключу UserID, Key(X), доступное на данный момент, пропускать его вместе с фичами, доступными только в момент предсказания еще через пару dense-слоёв и получать предсказание нашего таргета. В моём случае Key(X) это было извлечение домена рекламодателя, а таргетами был клики на показанные рекламные объявления.
В качестве RNN я в своих экспериментах использовал LSTM, но для продакшена наверное лучше брать GRU, потому что там скорее всего лучшее соотношение profit/units, потому что одни и те же выходы используются и для состояния и для аутпута.
Можно такую сеть также попробовать упростить, чтобы еще больше приблизиться к обычным счетчикам с устареванием, зафиксировав вид функции forget gate как устаревание от времени и подбирая только скорости этого устаревания и, возможно, убрав нелинейности в разных местах.

Я в своих экспериментах пытался подавать в сеть показы и клики по доменам рекламодателей и предсказывать вероятность клика по рекламе. Получилась такая схема
![scheme](https://jing.yandex-team.ru/files/mstebelev/Untitled%20Diagram%20%281%29.png "Схема сети")

## Эксперименты
Брались данные по 1% пользователей за месяц, из них делалась выборка программой из [соседней папки](make_pool). Основная идея в том, что по паре "UserID,Domain" мы группируем события и подготавливаем данные к тому, чтобы их как можно проще было сконвертировать в np.array, которые мы подаём в tensorflow.
После этого учили вышеописанную модель [этим скриптом](train/model_async.py). Основные проблемы при обучении рекуррентных сетей в tensorflow в том, что бывают длинные последовательности и из-за них становятся большие тензоры для всего батча. Так что для этого там применялся такой трюк, который мне подсказал staff:esgv, что мы берем большой батч (например, в 10 раз больше того, какой мы хотим), сортируем его по размеру последовательности и уже в таком виде нарезаем на 10 минибатчей. За счет этого у нас скорее всего будет только один из 10 батчей большого размера и обучение будет в среднем быстрее.
Также я использовал data parallelism, при котором операции с переменными на каждом worker-е реплицируются в parameter server и оттуда уже в остальные worker-ы. Это ускорило сходимость, хотя и не кратно числу процессов.

Я использовал CPU, потому что хоть GPU и учило чуть быстрее, cpu проще получить в нирване. Только надо не забыть правильно настроить OMP. Я использовал `{"KMP_SETTINGS": "true", "KMP_BLOCKTIME": "0",  "OMP_NUM_THREADS": "32", "KMP_AFFINITY": "granularity=fine,verbose,compact,1,0"}`. В результате на тех данных моделька училась единицы дней, сделав единицы проходов по корпусу.
Какие результаты получились:
1) Наличие RNN действительно полезно по сравнению с использованием только `realtime_features` (мгновенных фичей, доступных во время запроса).
2) Добавление всяких новых фичей во входные векторы RNN действительно помогают уменьшить лосс.
3) Время лучше подавать отдельным событием, в котором проставлено только прошедшее время, чем дополнительным элементом к событиям.
4) На eval-feature получилось, что новые rnn-фичи дают дополнительный прирост, но старые счетчики, входные данные которых были доступны нейросети не вытеснились (всё равно дают определенный прирост). К сожалению, там есть разница в методика, как расчитывались старые счетчики и новая RNN, так что вполне возможно, что дело было в этом. Во-вторых, были выучены две RNN, одна на таргет binary classification, вторая на таргет query softmax (пыталась угадать на какой баннер из рекламного хита был клик, если известно, что клик был). Обе модели давали прирост, больше прироста давала модель с binary classification (скорее всего потому что таргет для eval feature был именно такой), но вторая давала к ней аддитивный прирост.
5) пробовал horovod, но оказалось, что в силу своего устройства, он работает со скоростью самого медленного батча среди одновременных и работает это примерно с той же скоростью, как если не параллелить.


Проблемы и что там еще можно поделать:
наличие ключей и вытеснение. Сейчас по каждому ключу хранится отдельное состояние нейросети и если ключей становится много, то пользовательский профиль распухает. В случае со счетчиками мы оставляли просто n последних. Но поскольку одна нейросеть должна заменить все счетчики, то может оказаться, что, например, все рекламные клики потеряются, потому что их вытеснят показы. Так что надо как-то умнее это делать. Другой вариант состоит в том, что состояние сети хранится не по каждому вторичному ключу, а только по пользователю целиком. И во входы нейросети подаются эмбединги объектов, по которым было событие. Получится такая dssm-like архитектура, которая тоже может заработать. Также даже в концепции состояний по ключу всё равно можно в инпуты подавать эмбеддинги каких-то объектов, например, места показа объявления. Вполне возможно, что это может сильно помочь.

## Ссылки
[тикет](https://st.yandex-team.ru/BSDEV-71523)
