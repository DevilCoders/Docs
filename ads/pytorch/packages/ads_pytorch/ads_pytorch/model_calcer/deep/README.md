# Почему две реализации?

Основная причина - передача CUDA тензоров между процессами это ОЧЕНЬ больно:
1. Проблема с временем жизни тензора - необходимо сначала удалить его на потребляющем процессе, и потом уже на хостовом, иначе он может навечно зависнуть в памяти
2. Проблема с тем, что тензор нельзя передать дальше чем на 1 процесс. proc1 -> proc2 можно, а вот proc1 -> proc2 -> proc3 уже нет
3. Проблема со стримами - PyTorch сам умеет что-то с ними делать и не всегда явное использование стримов и их синхронизация работают ожидаемо
4. Проблема с синхронизацией стримов, даже если заставить их правильно работать - большое число процессов требуют большого числа синхронизаций, иначе обучение будет некорректно. Синхронизация - дорогая операция.

Для работы с GPU реализован воркер, в котором в каждом процессе живут и модель, и оптимайзер. Такая схема оптимальна для GPU, так как мы все равно шедулим всю работу на другие девайсы асинхронно, но не подходит для CPU, так как там необходима многопоточность при апдейтах (и без копирований, это важно)

Поэтому, для CPU была оставлена уже отлаженная ранее схема с отдельными воркерами и апдейтерами, а под GPU написан наиболее простой воркер, позволяющий делать multi-gpu обучение с (возможно) шардированной на GPU-шки моделькой.

Текущий GPU воркер хорошо подходит под модели легкой и средней тяжести. Для чего-то совсем жесткого вроде BERT лучше использовать проверенные временем all-reduce style обучаторы типа хоровода. Мы считаем, что не надо переизобретать велосипед, поэтому в будущем мы просто добавим поддержку horovod-worker, заново all-reduce схему мы делать не будем.
 