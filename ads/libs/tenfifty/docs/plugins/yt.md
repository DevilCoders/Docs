# YT
Плагин YT содержит действия, которые позволяют использовать таблицы и логи с Yt в качестве артефактов.

Для загрузки данных, полученных в результате вычислений, воспользуйтесь [плагином storage](storage.md).


## Действие GetDatasetFromYt (`get_dataset`): получить таблицы    {#get_dataset}
Представляет таблицу или список таблиц как артефакт класса Dataset. Список таблиц обрабатывается, как будто они конкатенированы в одну таблицу в указанном порядке.

**input:** отсутствует.

**output:** один Dataset.

**parameters:**

* `tables` (список строк, обязательный) — список путей на Yt, по которым лежат нужные таблицы. <!--- Параметры path, start_date и end_date не являются публичными -->
* `wait_for` (целое неотрицательное число) — максимальное время ожидания таблиц в секундах. Если 0 (значение по умолчанию) - то ожидания не будет.

Пример:

```yaml
get_dataset:
    action: get_dataset
    output: dataset
    parameters:
      tables:
        - //home/ads/tenfifty/examples/simple_pool

      wait_for: 86400
```

### Детали реализации   {#get_dataset_implementation}

{% list tabs %}

- Nirvana

    Для каждого указанного пути создаётся инстанс кубика [Library/util/text/Get MR Table](https://nirvana.yandex-team.ru/browse?selected=1777979). Их выходы сводятся в один endpoint-список.

- Tape

    Список путей сохраняется на Yt в файл JSON (правильность путей и существование таблиц не проверяются). Такой файл JSON является одним из двух возможных представлений артефакта Dataset на Yt в tape backend (второе представление — просто таблица).

{% endlist %}


## Действие GetLog (`get_log`): получить лог    {#get_log}
Представляет директорию на Yt, содержащую лог, как артефакт класса Log. Log во многих случаях можно использовать как список Dataset'ов (`ListOf(Dataset)`), хотя они не полностью эквивалентны.

**input:** отсутствует.

**output:** один Log.

**parameters:**

* `path` (строка) — путь к директории на Yt, где лежит лог. Не должен использоваться вместе с `mask`.
* `mask` (строка) — путь к таблицам, составляющим лог, с подстановками в формате [time.strftime в Python](https://docs.python.org/2/library/time.html#time.strftime). Если присутствует `path`, то `mask` выставляется автоматически в зависимости от `unit`: `"{path}/%Y-%m-%d"` при `unit == "1d"` и `"{path}/%Y-%m-%dT%H:%M:%S"` при `unit == "1h"`. Если `unit == "log"`, то нужно указать `path`, а не `mask`.
  * Обязательно должен быть указан либо `path`, либо `mask`.
* `unit` (строка, по умолчанию `1d`) — указывает, как партицирован лог. Должен быть строкой `1h` (лог партицирован по часам), или `1d` (лог партицирован по дням).
* `final_unit` (строка, по умолчанию равен значению `unit`) — указывает желаемое партицирование лога для обработки (либо так же, как он партицирован физически, что указано в `unit`, либо более крупными кусками). Должен быть строкой `1h`, `1d` или `log` (т.е. вообще не партицировать, обрабатывать как один Dataset). Промежуток времени должен быть не меньше, чем в `unit`.
  * Даже если `unit == "log"`, на выходе получается артефакт Log, то есть ListOf(Dataset), состоящий из одного датасета.
* `start_date` и `end_date` (строки, обязательные) — дата (в формате `%Y-%m-%d`) или дата и время (в формате `%Y-%m-%dT%H:%M:%S`) начала и конца лога. Момент `end_date` **не входит** в лог (по аналогии с `range` в Python). Если `unit == "1d"`, промежуток должен составлять целое число дней, а если `unit == "1h"`, — целое число часов.
* `wait_for` (целое неотрицательное число) — максимальное время ожидания логов в секундах. Если 0 - то ожидания не будет (по умолчанию - 24 часа).

Пример использования:

```yaml
action: get_log
  output: log
  parameters:
    path: //home/ads/tenfifty/examples/logs/log_sequential_tlm/1d
    start_date: 2021-10-09
    end_date: 2021-10-31 # not included
    unit: 1d
```

### Детали реализации       {#get_log_implementation}
GetLog — композитное действие, которое разворачивается в несколько [GetDatasetFromYt](#get_dataset). Список получающихся Dataset'ов представляется как артефакт класса Log.


## Действие MergeTables (`merge_tables`): объединить Dataset'ы      {#merge_tables}
Принимает ListOf(Dataset) и создаёт выходной Dataset, который работает как последовательная конкатенация таблиц из входных датасетов в указанном порядке.

Если на входе Log, то все его таблицы точно так же сводятся в один выходной Dataset.

**input:** список Dataset'ов или Log.

**output:** один Dataset.

**parameters:** отсутствуют.

### Детали реализации       {#merge_tables_implementation}

{% list tabs %}

- Nirvana

    Никакого дополнительного кубика не создаётся, просто таблицы из нескольких входных endpoint'ов сводятся в один список.

- Tape

    Объединённый список путей сохраняется на Yt в файл JSON. Такой файл JSON является одним из двух возможных представлений артефакта Dataset на Yt в tape backend (второе представление — просто таблица).

{% endlist %}
