# Библиотека parallel_offline. Параллельный оффлайн МаркетаФормат `MatchedData` и класс `MatchedData`.
[Описание на вики](https://wiki.yandex-team.ru/users/mbochk/Kubiki-offlajjna-parallelnogo-poiska)

Библиотека объединяет все скрипты, используемые в параллельном оффлайне маркета.

Поддержано сразу 2 оффлайна: оффлайн результатов серпа яндекса `serp` через скрепер и оффлайн ответа маркетного репорта `backend` через даас.


### Корзины запросов 
Данные отправляются не равномерно, а так, чтобы в толоке было размечено достаточно примеров по различным срезам. 
Логику отдельного среза, для которого нужна независимая разметка на релевантность определяют "корзины", далее `baskets`.

Также каждой корзине соответствует список "Метрик", которые на ней считаются.

Логику корзин реализует класс `OfflineBasketAbstract`, остальные корзины реализованы как наследники этого класса, и лишь переопределяют набор метрик и способ составления корзины.

### Метрики
Метрика -- это функция, которая превращает данные в одно число.

По коду, метрикой называется класс в файле offline_metrics.py, который поддерживает методы `get_series` и `get_value`,
а также имеет аттрибут имени `name` и необязательный аттрибут `data_type` (`=raw` если таковой отсутствует).
`data_type` определяет "слайс" данных, который будет использоваться в метрике.

Метод `get_series` используется при стат. тестировании, его результаты хранятся внутри класса `MetricStatData`.

Метрик много, и они могут быть параметрические, типичный случай -- когда метрика просто фильтрует данные из слайса и считает сумму/среднее.



### Слайсы данных
При подсчете метрик часто требуется как-то сгруппировать данные, например посчитать pfound. 
Чтобы не возить несколько вариантов одних данных в нирване, реализованы "Слайсы" данных, которые вычисляются из основного формата данных.

Также, для того же pfound, логично не рассчитывать слайс каждый раз заново для каждой метрики, а предрасчитать все нужные слайсы внутри каждой корзины (см. класс `OfflineBasketAbstract`). 

Договоренность: слайсов мало и они не параметрические, но они относительно универсальные.


### Описание скриптов в логическом порядке
* parse_parallel_daas.py, parse_serps.py --- парсим ответ скрепера для `serp` или дааса для `backend`.
Результат: tsv-данные по колдунщикам и список урлов для простукивания основного поиска.
* join_daas.py --- добавляем результат простукивания основного поиска.
* join_testids.py --- объединяем результаты со всех тестидов и создаем корзины. 
Результат: tsv-данные по корзинам и список запрос для толоки. 
* join_toloka.py --- объединяем данные с разметко по релевантности.
* calc_offline_metrics.py --- рассчитываем метрики.
* calc_offline_dashboard.py --- форматируем метрики для отправки на дашборд

Для серпового оффлайна есть сокращенная версия:
* calc_count_metrics.py --- расчет только по корзине `CountBasket`.

### Описание остальных модулей
* mock_daas.py, mock_toloka.py --- Mock-классы, симулирующие работу толоки или дааса от основрого поиска, используются в интегральных тестах.
* offline_basket.py, offline_metrics.py, offline_slices.py --- определяют всю логику, связанную с понятиями "корзин", "метрик" и "слайсов".
* parse_serps_testing.py --- скрипт для юнит-тестирования парсинга скрепера.