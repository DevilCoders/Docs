# Чеклист добавления новых сущностей архивации

Обозначим через ```EntityName``` плейсхолдер для сущности.
В примерах ниже будет использоваться сущность ```EntityHistory```.

  1. Описать конфигурацию сущности в классе ```{EntityName}Config``` пакета ```java.ru.market.archive.config```. На выходе должен определяться бин конфигурации сущности [JobConfiguration](src/java/ru/yandex/market/archive/JobConfiguration.java).
  Например, как в классе [EntityHistoryConfig](src/java/ru/yandex/market/archive/config/EntityHistoryConfig.java).
     1. Как правило, необходимо унаследоваться от класса [CommonEntityConfig](src/java/ru/yandex/market/archive/config/CommonEntityConfig.java) (для конфигурирования по "простому" сценарию). Для сложных конфигураций следует ориентироваться на логику архиватора.
     2. Определить столбцы сущности в источнике данных, которой является вьюха миграции ```v_migrate_{enity_name}``` (о ней позднее).
     Столбцы определяются методом ```columns()```. Расшифровка каждого свойства столбца в javadoc для класса [SourceColumn.Builder](src/java/ru/yandex/market/archive/schema/SourceColumn.java).
        1. для каждого столбца задается ```name``` (имя столбца в вьюхе миграции)
        2. для каждого столбца задается тип столбца в YT-таблице методом ```type``` (по умолчанию, если не задать, будет тип ```string```)
        3. обязательно должен быть задан столбец по которому будет секционирована таблица сущности в архиве (метод ```partitionBy```)
        4. обязательно должен быть задан столбец (сплит-столбец) по которому будет выполняться разбиение выборки (очень желательно, на равные или почти равные части) при выгрузке в несколько потоков (метод ```splitBy```)
        5. опционально маркируются столбцы, которые будут наряду с сплит-столбцом определять т.н. ключ в выборке для верификации (метод ```verifyKey```)
        6. опционально некоторые CLOB-столбцы потребуется отметить как требующих специальной обработки для CLOB-значений (метод для маркировки - ```clob```)
     3. Определить метод получения бина ```JobConfiguration``` для сущности в виде ```{entityName}JobConfig()``` с телом ```return getSimpleConfig(<ENTITY_MIGRATE_VIEW_OWNER>, "ENTITY_NAME")```.
      Такой ```SimpleConfig``` означает, что для миграции сущности создана вьюха ```v_migrate_{entity_name}``` в схеме перечисленной в классе [SourceOwner](src/java/ru/yandex/market/archive/schema/SourceOwner.java).
      Вьюха миграции должна экспонировать все столбцы таблиц, которые должны архивироваться в YT-таблицу.
     4. Определить [политику хранения](src/java/ru/yandex/market/archive/RetentionPolicy.java) сущности, переопределив по необходимости либо непосредственно метод ```getRetentionPolicy()```,
     либо Age-методы для определения возрастов политик хранения. Документировать сроки хранения сущности в [матрице сущности](https://wiki.yandex-team.ru/MBI/NewDesign/barchdfs/entitymatrix/).
     5. Опционально, переопределить лимиты для количества запусков той или иной [задачи архиватора](src/java/ru/yandex/market/archive/task/TaskType.java) в рамках одной сессии TMS-джобы задачи. Переопределение на уровне метода ```limits()```.
  2. В конфигурационном файле [JobsConfig](src/java/ru/yandex/market/archive/config/JobsConfig.java) определить бины:
     1. непосредственно для джобы миграции сущности ```migrate{EntityName}Executor``` используя в качестве значения для параметра ```jobConfiguration``` название config-бина по имени метода из п.1.3.
     2. (устарело?) TMS-триггер для джобы ```migrate{EntityName}ExecutorTrigger``` с указанием через свойства бина названия джобы миграции, расписания запуска джобы и понятного описания джобы
  3. Создать вьюху миграции с экспонированием столбцов для архивации. В вьюхе следует денормализовать данные, если логическая сущность представлена несколькими таблицами. В YT-таблицах используется эффективное сжатие денормализованных данных.
  Но конечно везде должна быть мера и чувство прекрасного. Вьюха миграции должна иметь того же владельца, что и таблицы ее составляющие.
  4. В [drop_mbi_data-скрипте](../mbi-db/src/sql/barc_tms/drop_mbi_data_pkg.sql) добавить, если удаление для сущности не вписывается в обобщенную процедуру ```drop_date_partition```, кастомную процедуру удаления.
  Как правило, для сущности состоящей из нескольких таблиц требуется кастомная процедура удаления. Также кастомная процедура потребуется, если сущность не партиционирована физически. Название кастомной процедуры - ```drop_{entity_name}```.
  В этом же скрипте прописать гранты для доступа к данным сущности и выполнения операций связанных с удалением.
  5. Для некоторых сущностей невозможно удалять партиции в таблицах-источниках в момент удаления данных. Это, например, может быть связано с тем, что для логического партиционирования
  используется другой столбец нежели столбец по которому физически определено партиционирование. Например, для сущности ```CLICKS``` используется столбец ```TRANTIME``` для партиционирования на YT,
  но для физического партиционирования в Oracle-базе используется столбец ```EVENTTIME```. В таких случаях требуется очищать партиции специальной джобой для которой требуется список таблиц для очистки партиций.
  Такой список нееобходимо задать через метод ```cleanupTables``` в классе с описанием сущности. В кастомной процедуре удаления в таком случае достаточно просто сделать удаления по логическому столбцу партиционирования.

# Чеклист при изменении схемы таблиц лежащих в основе сущности

При изменении схемы допустимы только следующие действия над таблицами сущности:

  1. Добавление новых столбцов в таблицы
  2. Удаление столбцов в источнике (в YT-таблицах столбцы остаются и в последующем просто заполняются нулями)
  3. Изменения типа данных архивируемых столбцов совместимых с текущей схемой таблиц в YT
  4. Любые манипуляции со столбцами не представленных в архивных таблицах
  5. Добавление новой таблицы во вьюху миграции
  6. Удаление таблицы из вьюхи миграции без нарушения остальных условий

Недопустимыми действиями являются:
  1. Расширение типа данных архивируемого столбца до несовместимого с текущим типом данных в YT-схеме сущности
  2. Удаление столбца партиционирования

## Общие действия при изменении схемы

При любом изменении схемы потребуется (после всех других действий) используя REST API удалить параметры ```STOP_MIGRATE``` и ```SOURCE_SCHEMA``` для сущности.

## Манипуляции со столбцами, не участвующими в архивации

В данном случае ничего не нужно делать в архиваторе.
Релиз не требуется.

## Удаление столбца архивации

Потребуется релиз ```mbi-db```.
В вьюхе миграции экспонировать столбец с значениями NULL.

Недопустимо удаление столбца партиционирования.
При удалении сплит-столбца необходимо определить другой сплит-столбец, что потребует релиза ```mbi-data-archiver```.

## Добавление нового столбца архивации

Потребуется полноценный релиз как ```mbi-db```, так и ```mbi-data-archiver```.

В классе конфигурации сущности ```{EntityName}Config``` добавить новый столбец. Например, для ```ENTITY_HISTORY``` классом конфигурации является [EntityHistoryConfig](src/java/ru/yandex/market/archive/config/EntityHistoryConfig.java).
В вьюхе миграции ```v_migrate_{entity_name}``` экспонировать новый столбец.

## Изменение типа данных столбца

Тип данных должен покрываться типом данных используемым для столбца в схеме YT-таблицы.
В этом случае достаточно удалить параметры через REST API (см. выше условия общие для всех).

В ином случае, изменение типа данных невозможно и потребуется экспонировать на уровне вьюхи миграции столбец под другим именем и следовать чеклисту по добавлению нового столбца.

## Добавление новой таблицы в сущность

При добавлении нового столбца требуется следовать чеклисту по добавлению нового столбца.

Если добавление новой таблицы не приводит к добавлению нового столбца в вьюху миграции, то необходимо:

Релиз ```mbi-db```.

При добавлении новой таблицы:

   1. Учесть новую таблицу в вьюхе миграции ```v_migrate_{entity_name}```.
   2. В процедуре удаления ```drop_{entity_name}``` из пакета [drop_mbi_data-скрипте](../mbi-db/src/sql/barc_tms/drop_mbi_data_pkg.sql)
      1. учесть удаление по новой таблице
      2. добавить гранты для доступа к новой таблицы из схемы ```barc_tms``` в этом же sql-скрипте

## Удаление таблицы из сущности

Если одновременно с этим удаляются столбцы из вьюхи миграции, то нужно выполнить чеклист по удалению столбца архивации.

Релиз ```mbi-db```.

При удалении новой таблицы:

   1. Убрать таблицу из вьюхи миграции ```v_migrate_{entity_name}```.
   2. В процедуре удаления ```drop_{entity_name}``` из пакета [drop_mbi_data-скрипте](../mbi-db/src/sql/barc_tms/drop_mbi_data_pkg.sql)
      1. исключить действия по таблице исключаемой из сущности
      2. возможно убрать гранты (для ```barc_tms```) для доступа к исключаемой таблице из сущности (в этом же sql-скрипте)

# Памятка разработчику для проверки сервиса локально

Проверку работы сервиса с архивацией в YT можно осуществлять локально из IDE.

Важно помнить, что архиватор находится в промежуточном состоянии,т.е. архивация по некоторым сущностям продолжается в Hadoop.
В ближайшие месяцы архиватор полностью перейдет на YT. Но пока некоторые сущности продолжают архивировать в Hadoop.

Список сущностей архивируемых в YT можно увидеть по наличию для них классов конфигураций в пакете java ```ru.yandex.market.archive.config```.

Сущность архивируется либо в YT, либо в Hadoop. Другого не дано. Т.е. архивация в YT взаимоисключает архивацию в Hadoop.

Архитектуру архивации в YT можно найти на [вики](https://wiki.yandex-team.ru/users/snoop/barc2yt/).

Для локального запуска даже не нужны датасорсы.

Действия по запуску архиватора в YT локально:

   1. Получить YT- и YQL-токены. См. [YT - Getting feet wet](https://wiki.yandex-team.ru/users/snoop/YT-Getting-feet-wet/).
   Там же есть ссылки на полезные ресурсы, если что-то неясно при работе с YT.
   2. Создать Application launcher в IntelliJ IDEA следующего содержания:
      - **Main Class** - `ru.yandex.common.util.application.XmlAppContextMain`
      - **Working directory** - путь к модулю
      - **Use classpath of module** - `mbi-data-archiver`
      - **Environment variables**
         - `TNS_ADMIN` - путь к папке с `tnsnames.ora`
         - `YT_TOKEN` - значение токена для YT (см. п.1)
         - `YQL_TOKEN` - значение токена для YQL (см. п.1)
         - `ETCD_USERNAME=datasources_read_all`
         - `ETCD_PASSWORD` - токен для etcd
      - **VM options**
      ```
      -Doracle.net.tns_admin=$TNS_ADMIN
      -Denvironment=development
      -Dspring.profiles.active=development
      -Dfile.encoding=UTF8
      -Dorg.apache.commons.logging.LogFactory=org.apache.commons.logging.impl.LogFactoryImpl
      -Xms256m
      -Xmx512m
      -XX:+UseParallelGC
      ```
   3. Launch application

После запуска будет доступна TMS-консоль для запуска TMS-джобов включая джобы миграции.
Также станет доступен REST API по заданному http-порту в настройках приложения.

Чеклист проверки основных процедур архиватора:

   1. Убедиться, что задан интервал миграции для сущности, а в базе есть данные для миграции
      - проверить либо запросом в таблицу ```barc_tms.import_interval```
      - либо используя REST API (например для сущности ```ENTITY_HISTORY``` http-запрос ```http :3880/barc/ENTITY_HISTORY/intervals```
   2. Запустить через TMS-консоль соотв-щую сущности джобу миграции ```tms-run migrateEntityHistoryExecutor```
   3. Джоба последовательно будет проходить интервал пока не найдет данные для миграции.
   Как только джоба найдёт данные для миграции, то в ```barc_tms.task_event_log```
   для сущности появится запись с ```event_type=START``` и ```entity_date``` из интервала миграции.
   4. На основном кластере ожидать появления таблицы в директории для сущности для даты ```entity_date```,
   а также проверки лога ```barc_tms.task_event_log``` на запись ```DONE```
   5. После успешной миграции данных в очереди задач ```barc_tms.task_queue``` появятся задачи:
      - на удаление ```DELETE```
      - на репликацию данных на резервный кластер ```REPLICATE```
   6. Для проверки удаления необходимо запустить джобу ```deleteExecutor``` и по окончанию
      - проверить лог ```barc_tms.task_event_log```
      - убедиться что данные удалены за интересуемый интервал
   7. Для проверки репликации необходимо запустить джобу ```replicateExecutor``` и по окончанию
      - проверить лог ```barc_tms.task_event_log```
      - убедиться что данные реплицированы на резервный кластер за интересуемый интервал

Настройки которые влияют на работу задач:

   1. [Политика хранения](src/java/ru/yandex/market/archive/RetentionPolicy.java), а также property-файл
   2. [Параметры задач](src/java/ru/yandex/market/archive/param/JobParam.java), а также таблица ```barc_tms.job_param```
   3. Интервалы миграции в таблице ```barc_tms.import_interval```

Дополнительно, по необходимости, проверить следующие процедуры:

   1. Очистка архива - задача ```archiveCleanupExecutor```
   2. Укрупнение данных - задача ```mergeExecutor```
   3. Актуализация схемы при добавлении новых столбцов - задача ```schemaUpgradeExecutor```

##### Пример VM Options для локального запуска из IDEA:
```$xslt
-Denvironment=local
-Dbean.file=classpath:bean.xml
-Dconfigs.path=/Users/r-posokhin/arc/arcadia/market/mbi/mbi/mbi-data-archiver/src/main/properties.d
-Dlog4j2.configurationFile=/Users/r-posokhin/arc/arcadia/market/mbi/mbi/mbi-data-archiver/src/main/conf/log4j2.xml
-Dlog4j2.contextSelector=org.apache.logging.log4j.core.selector.ClassLoaderContextSelector
-Dlog.dir=/Users/r-posokhin/IdeaProjects/mbi/logs/mbi-data-archiver
-Doracle.net.tns_admin=/Users/r-posokhin
```
