# Работа с Spark
Для реализации спарк тасок, необходимо наследоваться от класса `market.monetize.stapler.v1.tasks.spark.SparkTask`
В момент исполнения кода таски в методе `run()` будет доступно свойство `self.spark` хранящее текущую сессию спарка для исполнения кода.
В методе `call` можно посмотреть подробнее. Метод `run` выполняется в контексте конструкции `with spark_session() as spark`

Для работы со `spark` тасками, требуется передавать обязательный аргумент `spark_dir_path`, указывающий на расположение драйвера `spyt` кластера

Подробнее про `spyt`
- https://wiki.yandex-team.ru/spyt/

## Старт/Стоп spyt кластера
В stapler предусмотрены классы для запуска и остановки спарк кластера. Рекомендуем использовать их.
В этом случае запуск и остановка кластера для спарк задач будет происходить в одном графе и этот процесс проще контралировать.

[spark.py](../tasks/spark.py)
- RunSparkCluster
- StopSparkCluster


    Так же для отладки или тестирования можно использовать заранее созданный кластер и передавать путь до драйвера в спарк таск
