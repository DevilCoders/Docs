# Введение
Данная статья приследует следующие цели:
1. Предоставить более детальное техническое описание серии работ по модификации БД RackTables, причин и последствий SPI-31105
2. Зафиксировать полученный в ходе этих работ опыт

Краткий обзор без погружения в технические подробности:
1. Для перехода на использование mysync было произведено обновление MySQL с 5.6 на 5.7.33
2. Чтобы не затягивать переход на MySQL 5.7.33 SQL Mode был установлен в пустое значение (из-за отличий в его составе и поведении между версиями MySQL)
3. В ходе работ по переходу на SQL Strict Mode (возвращению значения SQL Mode в значение по умолчанию) по пока не до конца установленным причинам произошёл отказ в работоспособности RT продолжительностью около 3 часов - SPI-31105
4. После восстановления работоспособности сервиса потребовалось продолжительное восстановление состояния кластера MySQL

# Термины и определения
В RackTables существует несколько тестовых контуров упоминаемых в тексте:
1. Staging environment - локальный код и локальные копии БД, снятых с активных локальных реплик
2. MySQL test cluster (iva-test-mysql01, sas-test-mysql01) - MySQL кластер состоящий из пары узлов работающих в режиме master->slave, обновление данных на которых происходит раз в день посредством восстановления из резервной копии.

Чтобы не злоупотреблять англицизмами, по ходу текста будут использоваться следующие понятия:
1. Тестовое окружение - Staging environment
2. Тестовый кластер - MySQL test cluster

# SQL Mode и Racktables
SQL Mode - это набор опций, определяющих поведение SQL-сервера при обработке запросов в спорных ситуациях.

До обновления MySQL до версии 5.7.33, RackTables выступающий в роли клиента производил модификацию SQL Mode в рамках собственных сессий, а именно отключал опцию NO_ZERO_DATE, оставляя остальные опции установленные сервером.

По умолчанию в MySQL 5.7.33 переменная SQL Mode, влияющая на поведение выполнение операций, установлена в значение
```
+-------------------------------------------------------------------------------------------------------------------------------------------+
| @@sql_mode                                                                                                                                |
+-------------------------------------------------------------------------------------------------------------------------------------------+
| ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION |
+-------------------------------------------------------------------------------------------------------------------------------------------+
```
Эксплуатируемые на тот момент код RackTables и структура БД не были готовы к работе в таком режиме. В качестве временной меры, чтобы не оттягивать переход на использование mysync, при обновлении MySQL значение этой переменной было установленно в пустое значение на уровне сервера.

Наиболее важной опцией является "STRICT_TRANS_TABLES". Она влияет на поведение в случаях, когда данные переданные в запросе по каким-либо причинам не могут быть записаны в базу. Чаще всего при её отсутствии, передача некоректных данных приводит не к ошибке при выполнении запроса, а к предупреждению, которое на стороне клиента никак не обрабатывается. При этом сами данные записанные в базу отличаются от данных переданных клиентом.

В качестве нескольких примеров проблем, которые возникли из-за её отсутствия можно привести следующие:
* NOCDEV-5242 - попытки добавить аллокации IP с некоректным типом вместо ошибок приводили к установке типа в пустое значение.
* NOCDEV-6035 - записываемые сообщения обрезались до допустимой длины с частичной потерей значения
* NOCDEVDUTY-604 - из-за наличия недопустимых символов не соответствующих utf8 значение записывалось пустым
* NOCREQUESTS-29440 - группы для пользователя записываются в строку через запятую, из-за большого количества групп у пользователя и недостаточной длинны значение обрезалось
* NOCDEV-6232 - из-за длины обрезается значение session_id, из-за чего аутентификация происходит не через кеш
* NOCDEVDUTY-576 - наличие недопустимых символов для utf8 поле записывалось пустым

Первой выявленной проблемой стали некорректные аллокации (NOCDEV-5242), что послужило отправной точкой для активностей по включению строгого режима SQL (установки SQL Mode в значение по умолчанию). В качестве временного исключения было решено дополнительно отключать опцию ONLY_FULL_GROUP_BY в дополнении к NO_ZERO_DATE на стороне клиента и рассмотреть возможность их включения в будущем.

После внесения изменений в значение SQL Mode на серверной и клиентской стороне ожидаемо начали проявляться неизвестные до этого момента проблемы, поскольку теперь они приводили к ошибкам записи в базу, а не просто игнорировались. Большая часть проблем решалась достаточно легко - локальными изменениями длины или типа конкретной колонки. Однако, NOCDEVDUTY-576 требовала изменения кодировки с utf8 на utf8mb4 для поддержки 4х байтных unicode символов. Из-за совокупности потенциальных проблем связанных с расхождением кодировок между сервером, клиентом, базой, таблицей и самими колонками было принято решение о полном переходе на utf8mb4 и как следствие конвертацией всех текстовых полей в данную кодировку.

# Подготовка к переходу на utf8mb4
## Обкатка процедуры изменения в тестовой среде
Для минимизации рисков предполагаемые операции по конвертации БД в utf8mb4 обкатывались в тестовой среде в итеративном режиме. Набор SQL-запросов для конвертации прогонялся на только что созданном образе среды (с исходным состоянием базы). Если набор запросов приводил к сбою, то на отдельном тестовом образе обкатывались необходимые изменения процедуры, вносились изменения в набор запросов и полный запуск повторялся на новом образе. В ходе тестирования удалось выявить набор не очевидных потенциальных проблем, которые могут возникнуть при конвертации. Финальный прогон набора SQL-запросов так же прошёл успешно, но этот факт ещё будет упоминут отдельно.

## Связанные индексы
В случае, если две и более таблиц связаны индексами по текстовому полю, то изменение кодировки одной из таблиц приведёт к ошибке и не будет выполнено, поскольку связывающий индекс не может отличаться между таблицами. Для конвертации в таком случае необходимо сначала сбросить соответствующие индексы, сконвертировать таблицы, а затем вернуть индексы обратно. Чтобы сохранить консистентность данных, перед началом этого процесса необходимо взять WRITE LOCK на все участвующие таблицы, чтобы в них не производились изменения, которые могут расчитывать на автоматическое удаление записей по связанным индексам.

Простейший пример выглядит вот так:
```
LOCK TABLES racktables.Yandex_staff_users_v2 WRITE, racktables.Yandex_staff_groups_members WRITE;
ALTER TABLE Yandex_staff_groups_members DROP FOREIGN KEY `Yandex_staff_dpt_members_ibfk_4`;
ALTER TABLE racktables.Yandex_staff_users_v2 CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;
ALTER TABLE racktables.Yandex_staff_groups_members CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;
ALTER TABLE Yandex_staff_groups_members ADD CONSTRAINT `Yandex_staff_dpt_members_ibfk_4` FOREIGN KEY (`login`) REFERENCES `Yandex_staff_users_v2` (`login`) ON DELETE CASCADE;
UNLOCK TABLES;
```

## NO_ZERO_IN_DATE и NO_ZERO_DATE
Часть таблиц одновременно имеют как текстовые поля, так и поля содержащие метки времени. Некоторые из полей с метками времени имеют значение по умолчанию равное "нулю". Например,
```
CREATE TABLE `Yandex_BBAuthCache` (
  `session_id` char(255) COLLATE utf8_unicode_ci NOT NULL,
  `username` varchar(64) COLLATE utf8_unicode_ci NOT NULL,
  `display_name` varchar(128) COLLATE utf8_unicode_ci DEFAULT NULL,
  `last_success` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP,
  `last_retry` timestamp NOT NULL DEFAULT '0000-00-00 00:00:00',
  PRIMARY KEY (`session_id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
```

Выполнение изменения кодировки такой таблицы с utf8 на utf8mb4 с SQL Mode содержащим NO_ZERO_DATE выполнится с ошибкой, поскольку конечная структуру будет противоречить требованию NO_ZERO_DATE. Чтобы избежать модификации поля last_retry, но изменить кодировку было принято решение изменять SQL Mode в рамках сессии производящей изменения в значение, используемое клиентом RT:
```
SET NAMES "utf8mb4", @@SQL_MODE = REPLACE(REPLACE(@@SQL_MODE, "NO_ZERO_DATE", ""), "ONLY_FULL_GROUP_BY", "");
```

## TagStorage.entity_realm
Одной из старых особенностей структуры БД было задублированное значение 'bot' в столбце entity_realm
```
CREATE TABLE `TagStorage` (
  `entity_realm` enum('file','ipv4net','ipv4rspool','ipv4vs','ipvs','ipv6net','location','object','rack','user','bot','vst','vlandomain','bot') COLLATE utf8_unicode_ci NOT NULL DEFAULT 'object',
```
В случае SQL Mode установленного в пустое значение конвертация данной таблицы не вызывает ошибок, однако для выполнения конвертации с правильным SQL Mode необходимо сначала модифицировать данный столбец, устранив дублирование возможного значения.

## CachedPAV и PortAllowedVLAN
Самый большой кластер таблиц, имеющих перекрёсные ссылки по индексам являются таблицы: CachedPVM, CachedPAV, CachedPNV, PortVLANMode, PortAllowedVLAN, PortNativeVLAN.

Для их конвертации необходимо взять WRITE LOCK на все таблицы разом, удалить связанные индексы, сконвертировать их и вернуть индексы обратно. При этом конвертация таблиц CachedPAV и PortAllowedVLAN, а так же добавление обратно связанных индексов на тестовом стенде получилось оценить как процедуру занимающую примерно 2 часа
```
ALTER TABLE racktables.PortAllowedVLAN CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci^M
--------------
Query OK, 39735951 rows affected (26 min 24.67 sec)
Records: 39735951  Duplicates: 0  Warnings: 0
--------------
ALTER TABLE racktables.CachedPAV ADD CONSTRAINT `CachedPAV-FK-object-port` FOREIGN KEY (`object_id`, `port_name`) REFERENCES `CachedPVM` (`object_id`, `port_name`) ON DELETE CASCADE
--------------
Query OK, 40624128 rows affected (33 min 33.70 sec)
Records: 40624128  Duplicates: 0  Warnings: 0
--------------
ALTER TABLE racktables.CachedPAV ADD CONSTRAINT `CachedPAV-FK-object-port` FOREIGN KEY (`object_id`, `port_name`) REFERENCES `CachedPVM` (`object_id`, `port_name`) ON DELETE CASCADE
--------------
Query OK, 40624128 rows affected (33 min 33.70 sec)
Records: 40624128  Duplicates: 0  Warnings: 0
--------------
ALTER TABLE racktables.PortAllowedVLAN ADD CONSTRAINT `PortAllowedVLAN-FK-object-port` FOREIGN KEY (`object_id`, `port_name`) REFERENCES `PortVLANMode` (`object_id`, `port_name`) ON DELETE CASCADE
--------------
Query OK, 39735951 rows affected (32 min 51.20 sec)
Records: 39735951  Duplicates: 0  Warnings: 0
```
В связи с этим было принято решение не производить конвертацию данной группы таблиц в рамках первого подхода и проработать менее блокирующую процедуру позднее. Такое же решение было принято относительно таблиц связанных с netmap, поскольку конвертация некоторых таблиц так же превышало минуту.

## Выбор времени проведения работ
Поскольку время конвертации оставшихся таблиц составляло от нескольких миллисекунд до нескольких десятков секунд в ходе выполнения работ ожидалась деградация работы РТ как на запись, так и на чтение (поскольку репликам тоже необходимо выполнить блокирующие изменения). Чтобы минимизировать влияние и проявления данной деградации, а так же снизить время применения измения, было принято решение проводить работы во время наименьшей нагрузки, то есть поздно вечером, а именно с 21 до 23 по МСК.

# Работы по конвертации кодировки 21.10.2021
## Хронология событий
Хронология событий описана в SPI-31105.

## Аварийная остановка выполнения SQL-запросов для модификации БД
В финальном прогоне изменений в тестовой среде скрипт завершился полностью успешно, однако во время работ остановился не выполнив изменения в нескольких таблицах. Причиной этому послужили следующие факторы:
1. Набор SQL-запросов содержал ошибку в порядке применения изменений для таблицы TagStorage
2. В тестовой среде не был полностью завершён переход на SQL Strict Mode
3. Тестовая среда случайным образом определяет на каком хосте будет выполняться окружение
4. Перед финальной проверкой не был проверен SQL Mode конкретного окружения

То есть в ходе тестирования удалось выявить необходимость модификации таблицы TagStorage в окружении с не пустым SQL Mode, из-за чего в скрипт были добавлены необходимые изменения, но порядок модификаций в скрипт был добавлен неправильным и выявить эту ошибку в ходе тестирования не удалось из-за выполнения финального прогона на хосте с пустым SQL Mode.

## Сбой репликации
Ещё до аварийной остановки скрипта начали появляться ошибки на репликах. Эти ошибки были связаны с невозможностью добавления/изменения строк в таблицах из-за несовпадения длин текстовых столбцов.
```
Column XXX of table 'YYY' cannot be converted from type 'char(1020(bytes))' to type 'char(765(bytes) utf8)
```
Что является следствием того, что на большинстве реплик не были применены ALTER TABLE, которые применились на мастере и данные уже вносятся в новой кодировке, а на репликах структура всё ещё старая. Для восстановления репликации была выставленна опция slave_type_conversions="ALL_LOSSY", чтобы вносимые изменения попытались примениться в неправильную структуру хотя бы с потерей данных, что в большинстве случаев, на самом деле, приводило бы просто к конвертации utf8mb4 в utf8 без потерь.

Единственной репликой, полностью применившей изменения, был noc-myt, который выступал в роли запасного мастера.

## Критическое замедление времени выполнения SQL-запросов
Поскольку первая попытка завершить конвертацию таблиц не увенчалась успехом (из-за слишком продолжительного времени выполнения даже уже на сконвертированных таблицах), а так же масштабных проблемах с работоспособностью системы (из-за слишком большого времени выполнения запросов), было принято решение сосредоточиться на диагностике проблемы с выполнением запросов.

В ходе диагностики первым предположением было, что какие-то из индексов всё ещё пересчитываются и необходимо дождаться их пересчёта, о чём свидетельствовали статусы запросов, большая часть которых говорила о построении индексов. Однако, предположение оказалось ошибочным: в дальнейшем время выполнения запросов не снижалось, хотя некоторое уменьшение количества запросов пересчитывающих индексы все же происходило, что не позволило сразу отбросить ошибочное предположение о причинах замедления. Более пристальное наблюдение за запросами уходящими в пересчёт индексов показало, что эти запросы имеют сходства, а именно: они производят JOIN таблиц, которые уже сконвертировались и тех что ещё не сконвертировались по текстовым полям, которые имеют разные кодировки, из-за чего для выполнения таких запросов БД не может воспользоваться существующими индексами и либо производит полное сканирование таблиц, либо строит временные индексы, которыми пользуется только в рамках конкретного запроса.

Другими словами система находится в замкнутом цикле - чтобы сконвертировать таблицы, необходимо дождаться выполнения запросов, а запросы выполняются очень долго, потому что необходимо сконвертировать таблицы. Чтобы произвести конвертацию таблиц до конца было принято решение полностью снять нагрузку с мастера РТ. Однако, снятие нагрузки РТ с хоста не гарантирует полностью снятия нагрузки с MySQL. Часть запросов с RO (из-за проблем с локальными репликами) могут перенаправляться в доступные базы, в том числе - в MySQL-мастер. Такие запросы сбрасывались вручную, чтобы уступить место в очереди запросам на изменения кодировок у оставшихся таблиц.

## Отказ от отката базы
Исходный план отката изменений, в виде отката базы к снятому до старта работ снепшоту обсуждался во время восстановительных работ, но совокупность следующих факторов:
1. Отсутствие возможности быстро откатить реплики к исходному состоянию
2. Наличие уже выполненных изменений на мастере РТ
3. Слишком продолжительное время восстановления реплик
4. Невозможность обслуживать весь поток запросов только хостами noc-sas и noc-myt

показала, что для применения данного подхода система полностью не готова и требует дополнительных доработок.

## Состояние реплик после завершения восстановительных работ
Выполненные изменения в ходе выполнения запланированных и восстановительных работ можно разделить на 2 основные части:
1. Изменения произведённые в автоматическом режиме скриптом
2. Изменения применённые в ручном режиме для восстановления работоспособности системы

А состояние 6 существовавших на момент проведения работ реплик может быть описано следующим образом:
* noc-sas.yndx.net выступал в роли мастера - применились изменения из 1 и 2
* noc-myt.yndx.net выступал в роли основной реплики с возможностью переключения на него мастера - применились изменения из 1 и 2
* man1-rt1.yndx.net - 1 не применился полностью, 2 применился частично
* myt-mysql.net.yandex.net - 1 не применился, 2 применился частично
* sas-mysql.net.yandex.nett - 1 применился почти полностью, 2 применился полностью
* vla-mysql.net.yandex.net - 1 не применился, 2 применился частично

Так же, после проведения работ были созданы новые узлы, образом для которых послужил sas-mysql.net.yandex.net:
* man-mysql1.net.yandex.net - 1 применился почти полностью, 2 применился полностью
* man-mysql2.net.yandex.net - 1 применился почти полностью, 2 применился полностью
* vla-mysql1.net.yandex.net - 1 применился почти полностью, 2 применился полностью
* vla-mysql2.net.yandex.net - 1 применился почти полностью, 2 применился полностью

Так же существуют реплики тестовой среды, точное состояние с которых не сохранилось, но они так же имели отличные от мастера и друг друга состояния.

При этом единственной репликацией на которой не включалась опция slave_type_conversions="ALL_LOSSY" является noc-myt, поэтому гарантировать полную корректность данных можно только на мастере (noc-sas) и noc-myt.

## Расхождение структур, транзакции и состояние кластера mysync
После восстановительных работ состояние mysync показывало, что кластер в корректном состоянии, поскольку он отслеживает применённость транзакций на репликах по GTID_EXECUTION_SET. Множество применённых транзакций на репликах совпадало между друг другом и мастером, что может свидетельствовать о факте, что реплики применили транзакции по модификации структуру сделав "ничего". И данный факт требует дальнейшего расследования причин такого поведения.

# Восстановление реплик и завершение конвертаций

## Обкатка восстановительных мероприятий в тестовой среде
В качестве подопытных образцов для отработки процедуры приведения таблиц в корректное состояния были выбраны реплики из тестовой среды. В ходе испытаний была выработана следующая методика:
1. С БД полностью снимается вся нагрузка
2. Настройки MySQL приводятся к корректному виду: SQL Mode устанавливается в значение по умолчанию, slave_type_conversions устанавливается в занчение "ALL_NON_LOSSY".
    Последняя опция необходима для корректного выполнения репликации в случае, когда часть таблиц на мастере ещё не сконвертирована, а на реплике уже сконвертирована. Но в  отличии от ещё не восстановленных реплик конвертации уже гарантированно будут происходить без потерь, поскольку длина символа в utf8mb4 больше.
3. БД запускается без поддержки входящих соединений по сети, а сокет-файл переименовывается, что гарантирует отсутствие любых запросов не связанных с восстановительными работами
4. Отключается репликация и журналирование локальных изменений
    ```
    STOP SLAVE;
    SET session sql_log_bin=0;
    SET @@GLOBAL.GTID_MODE=ON_PERMISSIVE;
    SET GTID_NEXT=ANONYMOUS;
    ```
5. На БД выполняется полная конвертация таблиц исправленным скриптом, включающая конвертацию CachedPAV, PortAllowedVLAN и таблиц netmap.
6. На БД включается репликация и состояние догоняет актуальное состояние мастера.
    ```
    SET @@GLOBAL.GTID_MODE=ON;
    SET GTID_NEXT=AUTO;
    START SLAVE;
    ```
7. Сокет-файл переименовывается обратно и БД перезапускается с поддержкой входящих сетевых соединений
8. По необходимости на БД возвращается нагрузка

## noc-myt - единственная правильная реплика
Поскольку единственные реплики гарантированно имеющие корректное состояние - это noc-sas и noc-myt, было принято решение не производить вышеописанную процедуру с каждой из реплик, а произвести её с одном из узлов без нагрузки с предварительным восстановлением его состояния из noc-myt посредством my-resetup. noc-myt был выбран в качестве исходного состояния по причине того, что снятие полного бэкапа так же может приводить к блокировке таблиц и использование мастера (noc-sas) в этом случае не желательно. В качестве такого узла был выбран vla-mysql2, на котором была произведена операция полного восстановления состояния с использованием в качестве источника noc-myt (примерно 1 час) и проведена описанная ранее процедура по конвертации оставшихся таблиц (примерно 2 часа). В результате данных мероприятий была получена "эталонная" реплика, с которой можно производить восстановление остальных реплик по укороченной процедуре:
1. В БД полностью снимается нагрузка
2. Настройки MySQL приводятся к корректному виду
3. БД останавливается и посредством my-resetup выполняется полное восстановление с уже восстановленных реплик с выбором наилучшего варианта с учётом геолокации.
4. Возвращается нагрузка на БД

По данной схеме были восстановлены все реплики, кроме noc-myt и noc-sas. Состояние на noc-myt было произведено по исходной процедуре с переключением нагрузки на myt-mysql.

## noc-myt - реплика с невыполненными на мастере транзакциями
В ходе восстановления реплик начало проявляться неожиданное поведение со стороны mysync, а именно - вывод из активных узлов исправленных реплик. Причиной тому послужило наличие на noc-myt транзакций, которые были применены после переключения мастера noc-myt -> noc-sas и которые соответственно не применялись на мастере (noc-sas). Пример вывода mysync, который можно использовать для проверки зрения и внимательности:
```
# mysync info -s
active_nodes:
- noc-sas.yndx.net
cascade_nodes:
  man-mysql1.net.yandex.net: myt-mysql.net.yandex.net
  man-mysql2.net.yandex.net: myt-mysql.net.yandex.net
  vla-mysql1.net.yandex.net: sas-mysql.net.yandex.net
  vla-mysql2.net.yandex.net: sas-mysql.net.yandex.net
ha_nodes:
- man1-rt1.yndx.net
- myt-mysql.net.yandex.net
- noc-myt.yndx.net
- noc-sas.yndx.net
- sas-mysql.net.yandex.net
- vla-mysql.net.yandex.net
health:
  man-mysql1.net.yandex.net: <ping=ok repl=running sync=-- ro=true offline=false lag=0.00
    du=35% cr=no gtid=8a6df418-a291-11e6-b6f0-002590c5179c:1-34340643,8bdc732d-5c98-11eb-b263-9a84c6575dd0:1-735494,a8fa648f-5ca6-11eb-800b-86aed82f625e:1-24940,e74f5225-8308-11eb-95cb-5ab47941d97e:1-192513,f5a16396-d7b0-11e4-86ae-bcaec568b353:1-48259561>
  man-mysql2.net.yandex.net: <ping=ok repl=running sync=-- ro=true offline=false lag=0.00
    du=35% cr=no gtid=8a6df418-a291-11e6-b6f0-002590c5179c:1-34340626,8bdc732d-5c98-11eb-b263-9a84c6575dd0:1-735494,a8fa648f-5ca6-11eb-800b-86aed82f625e:1-24940,e74f5225-8308-11eb-95cb-5ab47941d97e:1-192513,f5a16396-d7b0-11e4-86ae-bcaec568b353:1-48259561>
  man1-rt1.yndx.net: <ping=ok repl=running sync=-s ro=true offline=false lag=0.00
    du=63% cr=no gtid=8a6df418-a291-11e6-b6f0-002590c5179c:1-34340630,8bdc732d-5c98-11eb-b263-9a84c6575dd0:1-735494,a8fa648f-5ca6-11eb-800b-86aed82f625e:1-24940,e74f5225-8308-11eb-95cb-5ab47941d97e:1-192513,f5a16396-d7b0-11e4-86ae-bcaec568b353:1-48259561>
  myt-mysql.net.yandex.net: <ping=ok repl=running sync=-s ro=true offline=false lag=0.00
    du=58% cr=no gtid=8a6df418-a291-11e6-b6f0-002590c5179c:1-34340643,8bdc732d-5c98-11eb-b263-9a84c6575dd0:1-735494,a8fa648f-5ca6-11eb-800b-86aed82f625e:1-24940,e74f5225-8308-11eb-95cb-5ab47941d97e:1-192513,f5a16396-d7b0-11e4-86ae-bcaec568b353:1-48259561>
  noc-myt.yndx.net: <ping=ok repl=running sync=-s ro=true offline=false lag=0.00 du=12%
    cr=no gtid=8a6df418-a291-11e6-b6f0-002590c5179c:1-34340631,8bdc732d-5c98-11eb-b263-9a84c6575dd0:1-735494,a8fa648f-5ca6-11eb-800b-86aed82f625e:1-24940,e74f5225-8308-11eb-95cb-5ab47941d97e:1-192513,f5a16396-d7b0-11e4-86ae-bcaec568b353:1-48259561>
  noc-sas.yndx.net: <ping=ok repl=master sync=m- ro=false offline=false lag=0.00 du=5%
    cr=no gtid=8a6df418-a291-11e6-b6f0-002590c5179c:1-34340621,8bdc732d-5c98-11eb-b263-9a84c6575dd0:1-735494,a8fa648f-5ca6-11eb-800b-86aed82f625e:1-24940,e74f5225-8308-11eb-95cb-5ab47941d97e:1-192513,f5a16396-d7b0-11e4-86ae-bcaec568b353:1-48259551>
  sas-mysql.net.yandex.net: <ping=ok repl=running sync=-s ro=true offline=false lag=0.00
    du=70% cr=no gtid=8a6df418-a291-11e6-b6f0-002590c5179c:1-34340631,8bdc732d-5c98-11eb-b263-9a84c6575dd0:1-735494,a8fa648f-5ca6-11eb-800b-86aed82f625e:1-24940,e74f5225-8308-11eb-95cb-5ab47941d97e:1-192513,f5a16396-d7b0-11e4-86ae-bcaec568b353:1-48259561>
  vla-mysql.net.yandex.net: <ping=ok repl=running sync=-s ro=true offline=false lag=0.00
    du=32% cr=no gtid=8a6df418-a291-11e6-b6f0-002590c5179c:1-34340626,8bdc732d-5c98-11eb-b263-9a84c6575dd0:1-735494,a8fa648f-5ca6-11eb-800b-86aed82f625e:1-24940,e74f5225-8308-11eb-95cb-5ab47941d97e:1-192513,f5a16396-d7b0-11e4-86ae-bcaec568b353:1-48259561>
  vla-mysql1.net.yandex.net: <ping=ok repl=running sync=-- ro=true offline=false lag=0.00
    du=36% cr=no gtid=8a6df418-a291-11e6-b6f0-002590c5179c:1-34340623,8bdc732d-5c98-11eb-b263-9a84c6575dd0:1-735494,a8fa648f-5ca6-11eb-800b-86aed82f625e:1-24940,e74f5225-8308-11eb-95cb-5ab47941d97e:1-192513,f5a16396-d7b0-11e4-86ae-bcaec568b353:1-48259561>
  vla-mysql2.net.yandex.net: <ping=ok repl=running sync=-- ro=true offline=false lag=0.00
    du=36% cr=no gtid=8a6df418-a291-11e6-b6f0-002590c5179c:1-34340608,8bdc732d-5c98-11eb-b263-9a84c6575dd0:1-735494,a8fa648f-5ca6-11eb-800b-86aed82f625e:1-24940,e74f5225-8308-11eb-95cb-5ab47941d97e:1-192513,f5a16396-d7b0-11e4-86ae-bcaec568b353:1-48259561>
last_switch: <done *=>noc-sas.yndx.net manual by noc-sas.yndx.net at 2021-10-14 18:32:15.827659276
  +0300 MSK>
manager: man-mysql2.net.yandex.net
master: noc-sas.yndx.net
```
Различия в GTID 8a6df418-a291-11e6-b6f0-002590c5179c обусловленно задержкой репликации, а более важное отличие находится здесь:
```
noc-sas      : f5a16396-d7b0-11e4-86ae-bcaec568b353:1-48259551
все остальные: f5a16396-d7b0-11e4-86ae-bcaec568b353:1-48259561
```
Чтобы mysync не производил каких-то действий над БД - он был переведён в режим maintenance (mysync maintenance on), а вся автоматика по переключению БД для узлов РТ - отключена и управлялась вручную.

Сами дополнительные транзакции не представляли из себя особой пользы, поскольку все производили изменения в таблице с кешем для аутентификации пользователей. А причиной их появления скорее всего является отсутствие настройки read_only=ON в параметрах запуска БД на noc-myt, некорректным значением данной переменной после переключения мастера, а так же некорректными значениями в файлах mysql_master на узлах где выбор БД был намерянно не автоматизирован. Все эти проблемы были устранены, но наличие этих транзакций в gtid_executed_set у всех кроме noc-sas не позволяло переключить mysql-мастера с noc-sas на noc-myt средствами mysync, поскольку последний не входит в active nodes из-за наличия этих дополнительных транзакций.

## Переключение мастера noc-sas -> noc-myt
После того, как единственной не сконвертированной репликой остался мастер (noc-sas) основным планом было переключить mysql-мастер с noc-sas на noc-myt довыполнив недостающие транзакции на noc-sas при помощи включения взаимной репликации с отключением RW. Данный план был опробован на тестовом кластере и подавал большие надежды, и даже мог сработать, но как показала практика - был не доработан. В рамках включения взаимной репликации было необходимо добавить опцию MASTER_AUTO_POSITION=1 в состав команды SWITCH MASTER TO. Из-за её отсутствия, репликация на noc-sas началась с самых ранних журналов имевшихся на noc-myt и могла происходить дольше чем запланированное окно отключения RW для RT. В связи с этим был применён обходной путь по ручной перенастройке кластера на всех узлах и включению noc-myt в качестве мастера. Переключение мастера произшло в рамках установленного окна. Однако, отсутствие MASTER_AUTO_POSITION=1 дало не желательный эффект в виде продолжительной задержки на репликах и попытками mysync перевести часть mysql-узлов в offline режим, из-за высокой задержки по сравнению с мастером. Но данное поведение удалось своевременно локализовать, переведя mysync в maintenance режим до момента полного восстановления состояния mysql-кластера.

## Восстановление репликации на noc-sas
После переключения мастера на noc-myt осталось сконвертировать noc-sas по основной процедуре, однако в ходе переключения мастера на него прокралась лишняя транзакция затрагивающая таблицу Yandex_MacrosSectionLink, в которой на мастере(noc-myt) уже были применены противоречащие изменения, которые невозможно было бы докатить на noc-myt при помощи взаимной репликации. По этой причинине было принято решение об откате этой транзакции на noc-sas:
```
STOP SLAVE;
RESET MASTER;
SET @@global.gtid_purged="8a6df418-a291-11e6-b6f0-002590c5179c:1-36522841,8bdc732d-5c98-11eb-b263-9a84c6575dd0:1-735494,a8fa648f-5ca6-11eb-800b-86aed82f625e:1-24940,e74f5225-8308-11eb-95cb-5ab47941d97e:1-192513,f5a16396-d7b0-11e4-86ae-bcaec568b353:1-48285771";
START SLAVE;
```
плюс манипуляции над содержимым без записи в журнал репликации, приводящие состояние изменённых в рамках транзакции записей в соответствие с мастером. После проделанных манипуляций noc-sas появился в списке активных узлов mysync, но было решено временно не возвращать на него нагрузку, чтобы понаблюдать за поведением репликации без использования опций slave_type_conversions.

# Текущее состояние, выводы и TODO
На текущий момент на всех узлах MySQL значение SQL Mode установленно в значение по умолчанию, все таблицы сконвертированы в utf8mb4 и состояние кластера mysync восстановлено. Репликация на noc-sas работает без дополнительных опций и узел готов к принятию нагрузки. Запланированные шаги для завершения манипуляций с БД RT связанных с изменениями в SQL Mode:
1. ~~Вернуть в работу узел mysql на noc-sas~~ NOCRFCS-10237
2. ~~Убрать опцию slave_type_conversions из настроек MySQL на всех узлах~~ NOCRFCS-10237
3. ~~Произвести необходимые изменения БД для исправления NOCDEV-6232, предварительно протестировав данные изменения в тестовой среде и заодно
проверив существующие теории невыполнения ALTER TABLE на репликах во время конвертаций.~~ NOCRFCS-10237
4. Привести комментарии в коде, отражающие струкутуру БД, к акутальному состоянию NOCDEV-6371
5. Рассмотреть необходимость и возможность включения опций "ONLY_FULL_GROUP_BY" и "NO_ZERO_DATE" на уровне клиента.

В качестве полученного опыта и планов позволящих снизить риски простоя или время простоя РТ следуюет отметить следующее:
* Время выполнения работ с 21 до 23 по мнению команды было выбрано правильно. Отказ сервиса в рабочее время мог привести к более продолжительной
диагностике и восстановлению работоспособности, из-за гораздо большего потока обращений со стороны пользователей, а так же повлечь остановку
большего количества операций связанных с работоспособностью сервиса.
* Изменения связанные с модификацией структуры БД следует проверять на тестовом кластере выполняя следующие условия:
	1. Обязательная сверка глобальных переменных продуктовых и тестовых узлов
	2. Обяззательная проверка корректного выполения репликации
	3. Желательно производить тестирование с эмуляцией нагрузки

    Что говорит о необходимости дальнейшей поддержки и развития тестового кластера и тестового окружения, а так же инструментария для работы с ними.
* Необходимо доработать или полностью сменить схему выбора узла MySQL узлом RT с целью упрощения управления нагрузкой на узлы MySQL - NOCDEV-6365
* Необходимо доработать инструменты и процедуру отката БД RT для снижения времени восстановления в будущем - NOCDEV-6370

## Update
Перед выполнением NOCRFCS-10237, в рамках NOCDEV-6232 были проведены тесты позволившие воспроизвести проблему с невыполнением модификаций таблиц на репликах и выявить корневую причину, являющейся совокупностью следующих факторов:
* Выполнение модификаций структуры без выбора БД
* Наличие опций replicate-do-db на всех репликах, кроме noc-myt
* Наличие опций binlog-do-db на noc-myt (повлияло только на реплики тестового окружения)

В связи с этим были добавлены задачи:
* NOCDEV-6367
* NOCDEV-6369