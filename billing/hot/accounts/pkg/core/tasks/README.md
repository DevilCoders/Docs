### Общее
* Таски работают на основе очереди в SQS.
  [README для SQS](../../../sqs/README.md)
* Сообщения на выполнение отправляются из нашего кода или из нирваны (или вручную).
* Процессор поллит очередь и распределяет сообщения на выполнение конкретным обработчикам.
* Регулярные запуски деляются через нирвану
  [README для нирваны](../../../nirvana/jobs/README.md)


### Код
Переиспользуемая часть реализована в billingo:
* `billing/library/go/billingo/pkg/queue` - работа с очередями и сообщениями SQS
* `billing/library/go/billingo/pkg/task` - объект инкапсулирующий логику конкретного таска и провайдер для набора тасок
* `billing/library/go/billingo/pkg/taskapp` - приложение процессор - поллит очереди и запускает обработчики сообщений в пуле воркеров


SQS часть лежит в `billing/hot/accounts/sqs`


Специфичная для аккаунтера логика тасок реализована в `billing/hot/accounts/pkg/core/tasks`


Нирванная часть лежит в `billing/hot/accounts/nirvana/tasks`

### Добавление нового таска
1. В пакете `billing/hot/accounts/pkg/core/tasks` добавляем для таска или логически объединенной группы тасок новый файл
   (например, `billing/hot/accounts/pkg/core/tasks/example.go`)

1. Выбираем имя таски - должно быть уникально в рамках микросервиса.
   Оно прописывается в атрибут сообщения и по нему процессор распределяет сообщения конкретным обработчикам

1. Пишем для таска структуру пэйлода - просто структура с тэгами для полей.
   Формат имени `{имя_таска}Payload`
   ```go
   type ExampleTaskPayload struct {
       Param string `json:"param"`
   }
   ```

1. Решаем через какую очередь будет работать таск.
   * Можно для него создать отдельную очередь.
     Разумно если сообщений будет много и они приоритетны.
     Тогда у очереди будет отдельный поллер.
     Ее сообщения будут поступать на процессинг с некоторой гарантированной частотой
     и скорость их разбора будет ограничена только пулом воркеров.
     Также разумно если очереди нужны свои значения атрибутов.

   * Использовать уже созданную. Несколько тасок можно лить в одну очередь.
     Т.к. SQS выдает сообщения в негарантированном порядке, то нет гарантии
     что в каждый полл из очереди поступят сообщения для каждого типа таска

1. **ОПЦИОНАЛЬНО** Создаем очередь

1. Пишем реализацию интерфейса `task.Task`
   Рекомендуется заэмбедить базовую структуру `task.BaseTask`.
   В ней реализована дефолтная логика для простановвки сообщения в очередь и обработка ошибок
   ```go
    type ExampleTask struct {
      task.BaseTask
      // все нужное для работы таска (конфиги, коннекшены к бэкендам... - кладем в структуру таска
      config    *core.Config
    }

    func (p *partitionsMaintenanceTask) GetName() string {
       return "partitions_maintenance:job"
    }

    func (p *partitionsMaintenanceTask) GetQueueName() string {
       return "shared"
    }

    func (p *partitionsMaintenanceTask) NewPayload() any {
       return &ExampleTaskPayload{}
    }

    func (p *partitionsMaintenanceTask) Process(ctx context.Context, msg *queue.Message) error {
       // сюда пишем кастомную логику обработки сообщения
    }
   ```
   Формат имени `{имя_таска}ProcessHandler`
   Распарсить пэйлоад можно служебной функцией `task.ParsePayload`.
   Возвращаемая ошибка по-умолчанию будет просто залогирована (см пункт про ErrorsHandler)

1. **ОПЦИОНАЛЬНО** Пишем обработчик ошибок.
   Для этого в структуре таска надо переопределить метод `HandleError`
   На вход функция получит ошибку возвращенную ProcessHandler'ом и сообщение ее породившее.
   Вернуть true, если несмотря на ошибку сообщение надо удалить и больше не обрабатывать.
   Дефолтный обработчик ошибки возвращает false - сообщение не будет удалено и будет снова обработано.
   При кастомном обработчике ошибок рекомендуется эмбеддить не `task.BaseTask`, а только `task.DefaultTaskEnqueue`
   ```go
   type ExampleTask struct {
      task.DefaultTaskEnqueue
      // все нужное для работы таска (конфиги, коннекшены к бэкендам... - кладем в структуру таска
      config    *core.Config
    }
   ```

1. **ОПЦИОНАЛЬНО** Пишем обработчик отправки сообщения.
   Для этого в структуре джобы надо переопределить метод `Enqueue`
   Формирует по пэйлоаду инпут метода отправки сообщения SQS `sqs.SendMessageInput`
   При этом надо учитывать, что в возвращенном данным обработчиком инпут
   потом еще будут перезаписаны урл очереди и некоторые обязательные атрибуты (`JobName`)
   Дефолтный обработчик просто парсит пйэлоад в JSON и пихает его в тело сообщения.
   При кастомном обработчике ошибок рекомендуется эмбеддить не `task.BaseTask`, а только `task.DefaultTaskErrorHandler`

1. Пишем функцию инициализатор объекта таска `func New{имя_таска}Task() task.Task`
   В ней создаем новый объект джобы в параметрах функции должно быть все что нужно таску для работы
   ```go
   func NewExampleTask(config *core.Config) task.Task {
       return &ExampleTask{
           config: config,
       }
   }
   ``

1. Добавляем таск в провайдер `billing/hot/accounts/pkg/core/tasks/provider.go`
   Из провайдера приложение будет получать все объекты тасок. По имени из сообщения брать нужную таску и использовать ее обработчик.
   ```go
   func NewAccountsTaskProvider(ctx context.Context, config *core.Config) (*task.Provider, error) {
       tasks := []task.Task{
           NewExampleTask(config),
       }
       return task.NewProvider(ctx, tasks...)
   }
   ```

1. Если добавляли новую очередь, то ее надо добавить в конфиг поллинга `billing/hot/accounts/configs/tasks`
   * `pollInterval` - период в секундах, с которым поллер ходит в sqs в данную очередь.
   * `messageVisibilityTimeout` - период в секундах с которым процессор будет ходить в sqs, чтобы продлевать что обрабатываемое сообщение скрыто (пока оно скрыто его никто не может считать)
     Не стоит ставить маленьким.
   * `maxBatchSize` - максимальное кол-во сообщений которое поллер может считать за раз.
     Не может быть больше 10.
     Если сообщения мало - считает меньше 10.

   ```yaml
   example_queue:
    pollInterval: 10
    messageVisibilityTimeout: 30
    maxBatchSize: 10
   ```

### Отправка сообщения для очереди
1. Можно делать из любого места кода
   ```go
   t := jobs.NewExampleTask()
   payload := tasks.ExampleTaskPayload{
       Param: "value"
   }
   if err := t.Enqueue(ctx, ctx.SQS, &payload); err != nil {
       return err
   }
   ```

1. Можно сделать из нашего бинаря
   ```go
   make enqueue -- --name "example:job" '{"param":"value"}'
   ```

1. Можно через коммандную строку.
   Но это не рекомендуется, т.к. надо не забыть проставить все служебные атрибуты
   (пока только JobName, но в будущем еще добавится id для трейсинга и возможно что-то еще).
   ```
   aws --endpoint http://sqs.yandex.net:8771 sqs send-message \
   --queue-url "http://sqs.yandex.net:8771/newbilling_accounter-dev/example_queue" \
   --message-body '{"param": "ololo"}' \
   --message-attribute '{"JobName":{"DataType":"String", "StringValue":"example:job"}}'
   ```

1. Настроить регулярную отправку в нирване.
   Инструкция здесь `billing/hot/accounts/nirvana/tasks/README.md`

### Разделение процессоров
Если захотим запускать процессинг только части тасок, то для нее надо инициализировать отдельный task.Provider,
заполнять его только нужными тасками и в отдельном ентрипоинте запускать TaskProcessor с этим провайдером
Ограничения:
1. Таски, льющиеся в одну очередь, нельзя разделить в разные процессоры.
   Т.к. при этом процессор будет поллить все сообщения, для необрабатываемых тасок сообщения будут считываеться,
   но потом возвращаться в очередь с ошибкой. После нескольких таких попыток сообщение уйдет в deadletter.

1. Если процессор поллит очередь, то он должен обрабатывать все таски данной очереди. Причина та же что и в 1.

Поэтому планируя разделение процессинга тасок по инстансам надо учитывать в какую очередь они льются.
